{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "col_names = ['letter_selector_temp', 'n_records']\n",
    "ls_df_list = []\n",
    "for ls_nchar in range(1, 17):\n",
    "    wg_df['letter_selector_temp'] = wg_df['letter_group_ranked'].str[:ls_nchar + 1]    \n",
    "    ls_df = wg_df[col_names].groupby(col_names[:-1]).agg(ls_count = ('n_records', 'sum')).reset_index()    \n",
    "    ls_df_list.append(ls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tot_ls_df = pd.concat(objs=ls_df_list,axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tot_ls_df = tot_ls_df.drop_duplicates(subset = ['letter_selector_temp', 'ls_count'])\n",
    "\n",
    "tot_ls_df = tot_ls_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tot_ls_df['ls_index'] = tot_ls_df['letter_selector_temp'].map(get_ls_index)\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_search_space_list = []\n",
    "for ls_row_id, ls_row in tot_ls_df.iloc[:None].iterrows():    \n",
    "    if ls_row_id % 1000 == 0:\n",
    "        print(ls_row_id)    \n",
    "    \n",
    "    # get letter selector id information    \n",
    "    ls_id_index = np.array(ls_row['ls_index'])    \n",
    "\n",
    "    ##\n",
    "    # BUILD A COLUMN SELECTOR\n",
    "    ##\n",
    "    # make sure that only values GTE 0 are selected so that the right number of\n",
    "    # columns are return.\n",
    "    #curr_ls_id = ls_id_index[ls_id_index >= 0]\n",
    "    \n",
    "    ##\n",
    "    # SUBSET THE wchar_matrix by column selector\n",
    "    ##    \n",
    "    outcome_indices = np.all(wchar_matrix[:, ls_id_index] >= 1, axis=1)\n",
    "    #print(outcome_indices.sum())\n",
    "    \n",
    "    # this is the sub-matrix from which to query\n",
    "    #ls_wchar_matrix = wchar_matrix[outcome_indices, :]\n",
    "        \n",
    "    # this is the list of word group ids that correspond to the word group ids\n",
    "    # in the ls_wchar_matrix\n",
    "    #temp_wg_id_list = word_group_id_list[outcome_indices]\n",
    "    # place into a dictionary to go from wg_id to wg_index. What is the index\n",
    "    # of wg_id 675?\n",
    "    # wg_id_dict = {wg_id:wg_index for wg_index, wg_id in enumerate(temp_wg_id_list)}\n",
    "\n",
    "    # this is the number of word groups that meet certain criteria. \n",
    "    # for example, words that feature the letters: 'bro'    \n",
    "    #n_search_space = temp_wg_id_list.shape[0]\n",
    "    n_search_space_list.append(outcome_indices.sum())\n",
    "\n",
    "tot_ls_df['n_search_space'] = n_search_space_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4eff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tot_ls_df.to_csv(path_or_buf='search_space_count.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# try the above with cupy!\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "wchar_matrix_cp = cp.asarray(a=wchar_matrix)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "n_search_space_list = []\n",
    "for ls_row_id, ls_row in tot_ls_df.iloc[:None].iterrows():    \n",
    "    if ls_row_id % 1000 == 0:\n",
    "        print(ls_row_id)    \n",
    "    \n",
    "    # get letter selector id information    \n",
    "    ls_id_index = cp.asarray(ls_row['ls_index'])    \n",
    "\n",
    "    ##\n",
    "    # BUILD A COLUMN SELECTOR\n",
    "    ##\n",
    "    # make sure that only values GTE 0 are selected so that the right number of\n",
    "    # columns are return.\n",
    "    #curr_ls_id = ls_id_index[ls_id_index >= 0]\n",
    "    \n",
    "    ##\n",
    "    # SUBSET THE wchar_matrix by column selector\n",
    "    ##    \n",
    "    outcome_indices = cp.all(wchar_matrix_cp[:, ls_id_index] >= 1, axis=1)\n",
    "    #print(outcome_indices.sum())\n",
    "    \n",
    "    # this is the sub-matrix from which to query\n",
    "    #ls_wchar_matrix = wchar_matrix[outcome_indices, :]\n",
    "        \n",
    "    # this is the list of word group ids that correspond to the word group ids\n",
    "    # in the ls_wchar_matrix\n",
    "    #temp_wg_id_list = word_group_id_list[outcome_indices]\n",
    "    # place into a dictionary to go from wg_id to wg_index. What is the index\n",
    "    # of wg_id 675?\n",
    "    # wg_id_dict = {wg_id:wg_index for wg_index, wg_id in enumerate(temp_wg_id_list)}\n",
    "\n",
    "    # this is the number of word groups that meet certain criteria. \n",
    "    # for example, words that feature the letters: 'bro'    \n",
    "    #n_search_space = temp_wg_id_list.shape[0]\n",
    "    n_search_space_list.append(outcome_indices.sum())\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
