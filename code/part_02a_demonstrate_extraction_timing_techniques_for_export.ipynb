{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "from itertools import product\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "from time import perf_counter_ns\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, word_group_id_list, word_id_list, wchar_matrix = load_input_data(db_path = db_path, db_name = db_name, in_file_path = in_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the different matrix splitting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 6 different matrix extraction techniques:\n",
    "# Option 1: No sub-matrices\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "# See split_matrix() for a more elaborate description. \n",
    "# test_matrix_extraction_option() invokes the split_matrix() function 7 times to demonstrate the\n",
    "# differences in timing and split_matrix() function output. \n",
    "# The table below showcases which objects are populated by different matrix extraction options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Is object populated by matrix extraction technique?|\n",
    "|----------------------------------------------------|  \n",
    "\n",
    "\n",
    "| Object                      | 0 | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "|----------------------------:|---|---|---|---|---|---|---|\n",
    "| n_char_matrix_dict          | Y | N | Y | N | N | N | N |\n",
    "| single_letter_matrix_dict   | Y | N | N | Y | Y | N | N |\n",
    "| letter_selector_matrix_dict | Y | N | N | N | N | Y | N |\n",
    "| nc_ls_matrix_dict           | Y | N | N | N | N | N | Y |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_matrix_extraction_option(wg_df = wg_df,\n",
    "                                  letter_dict = letter_dict,\n",
    "                                  word_group_id_list = word_group_id_list,\n",
    "                                  wchar_matrix = wchar_matrix,\n",
    "                                  n_subset_letters = n_subset_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrolling through this output, it looks options 1-5 take about 10 seconds while\n",
    "# options 0 and 6 take about 60 seconds. We'll address that later through some profiling and\n",
    "# using snakeviz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaving the matrix extracton blank defaults to option 0: prepare all outputs\n",
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict= split_matrix(\n",
    "    letter_dict = letter_dict,\n",
    "    word_group_id_list = word_group_id_list,\n",
    "        wg_df = wg_df,\n",
    "    wchar_matrix = wchar_matrix, \n",
    "    n_subset_letters = n_subset_letters    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the search space for each matrix extraction option.\n",
    "# The search space is how many candidates have to be evaluated\n",
    "# when finding parent/child word relationships. \n",
    "# The smaller the search space for a given word, the faster the\n",
    "# parent/chiled relationship determination. \n",
    "# compute_lookups() calculates this using the number of rows in each of the different matrices and sub-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_lu_df = compute_lookups(wg_df=wg_df,\n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    single_letter_matrix_dict = single_letter_matrix_dict,\n",
    "                    letter_selector_matrix_dict = letter_selector_matrix_dict,\n",
    "                    nc_ls_matrix_dict = nc_ls_matrix_dict,\n",
    "                          db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# demonstrate the different matrix extraction options using the word 'achiever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_word = 'achiever'\n",
    "\n",
    "wg_id = word_df.loc[word_df['lcase'] == demo_word, 'word_group_id'].iloc[0]\n",
    "\n",
    "demo_wg_df = wg_df.loc[wg_df['word_group_id'] == wg_id, : ]\n",
    "\n",
    "# option 1 - Full matrix\n",
    "# No additional data needed\n",
    "\n",
    "# option 2 -  Number of characters\n",
    "n_char = demo_wg_df['n_chars'].iloc[0]\n",
    "\n",
    "# option 3 - First letter\n",
    "first_letter_id = demo_wg_df['first_letter_id'].iloc[0]\n",
    "\n",
    "# option 4 - Least common letter\n",
    "single_letter_id = demo_wg_df['single_letter_id'].iloc[0]\n",
    "\n",
    "# option 5 - Multiple least common letters\n",
    "letter_selector_id = demo_wg_df['letter_selector_id'].iloc[0]\n",
    "\n",
    "# option 6 - Number of characters and multiple least common letters\n",
    "nc_ls_id = demo_wg_df['nc_ls_id'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demontrate that the different matrix extraction options return identical results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the full matrix: option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# demo the full matrix selection\n",
    "output = get_values_full_matrix(wg_id = wg_id, \n",
    "                    wchar_matrix = wchar_matrix,\n",
    "                   word_group_id_list = word_group_id_list)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the matrices split by word-length: option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo the n char selection\n",
    "output = get_values_n_char(wg_id = wg_id,\n",
    "                      n_char = n_char,\n",
    "                      n_char_matrix_dict = n_char_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the matrices split by the first letter: option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter_id = first_letter_id,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the matrices split by the single least common letter: option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter_id = single_letter_id,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the matrices split by the letter selector: option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo with the letter selector\n",
    "output = get_values_letter_selector(wg_id = wg_id,\n",
    "                      letter_selector_id = letter_selector_id,\n",
    "                      letter_selector_matrix_dict = letter_selector_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select on the matrices split by word-length and the letter selector: option 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo with the n_char letter selector\n",
    "output = get_values_n_char_letter_selector(wg_id = wg_id,\n",
    "                           nc_ls_id = nc_ls_id,                           \n",
    "                           nc_ls_matrix_dict=nc_ls_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've tested with one word, let's time many evaluations to get a sense of how quickly \n",
    "# the different matrix extraction options work\n",
    "# use the timeit() function to evaluate how long, on average, a single operation\n",
    "# takes to complete\n",
    "# we do this by writing python code encapsulated in quotes which is then sent to the function\n",
    "# we can store the quoted code in a dictionary and then enumerate. \n",
    "# we'll run each code chunk 100 times and then compute the average\n",
    "\n",
    "n_trials = 100\n",
    "\n",
    "code_snippet_dict = {\n",
    "    'Matrix Selection Option 1: Selecting by full matrix':\n",
    "\"\"\"get_values_full_matrix(wg_id = wg_id, wchar_matrix = wchar_matrix, word_group_id_list = word_group_id_list)\"\"\",\n",
    "    'Matrix Selection Option 2: Selecting by word length':\n",
    "\"\"\"get_values_n_char(wg_id = wg_id, n_char = n_char, n_char_matrix_dict = n_char_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 3: Selecting by first letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter_id = first_letter_id, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",    \n",
    "    'Matrix Selection Option 4: Selecting by single least common letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter_id = single_letter_id, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 5: Selecting by letter selector':\n",
    "\"\"\"get_values_letter_selector(wg_id = wg_id, letter_selector_id = letter_selector_id, letter_selector_matrix_dict = letter_selector_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 6: Selecting by word length and letter selector':\n",
    "\"\"\"get_values_n_char_letter_selector(wg_id = wg_id, nc_ls_id = nc_ls_id, nc_ls_matrix_dict=nc_ls_matrix_dict)\"\"\"\n",
    "}\n",
    "\n",
    "timing_list = []\n",
    "for csd, cs in code_snippet_dict.items():    \n",
    "\n",
    "    # here we time the code execution\n",
    "    total_time = timeit.timeit(cs, number=n_trials, globals=globals())\n",
    "    timing_list.append([csd, total_time])\n",
    "\n",
    "    # total time    \n",
    "    total_time_formatted = '{:,}'.format(round(total_time, 2))    \n",
    "\n",
    "    # average time\n",
    "    avg_time = total_time / n_trials\n",
    "    avg_time_formatted = '{:,}'.format(round(avg_time, 2)) \n",
    "        \n",
    "    print(csd)\n",
    "    # average number of seconds per trial\n",
    "    print('Total time:', total_time_formatted, 'seconds. Average time:', avg_time_formatted, 'seconds.')\n",
    "\n",
    "    # add a line break to make it easier to read\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esimate total number of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many parent/child relationships are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# estimate_total_pairs() estimates the total number of from/to word pairs\n",
    "# the reason for estimating the upper bound is that it is both just interesting \n",
    "# to know but it also means that we can use the estimated values to allocate an \n",
    "# object in memory as opposed to incrementally appending to a list - this is faster\n",
    "# the object in memory is a NumPy Array that will store integers: from word group id | to word group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_anagrams, agg_pos_df = estimate_total_pairs(wg_df = wg_df, letter_selector_matrix_dict = letter_selector_matrix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this to disk for future reference\n",
    "write_data_to_sqlite(df = agg_pos_df, table_name = 'n_possible_anagrams', db_path = db_path, db_name = db_name,\n",
    "                         if_exists_option='replace',\n",
    "                         index_option=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the ratios in differences in timing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# matrix extraction option 6 - the combination of the word length and letter selector - is the fastest\n",
    "# but how much faster is it compared to option 5 or option 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these numbers are orders of magnitude different and therefore hard to interpret.\n",
    "# let's rescale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use product() to compute the cartersian product of the list of timings\n",
    "# from the timing list, we can compute the ratio of one timing to another\n",
    "# we can then build a dataframe and cross-tab\n",
    "\n",
    "expanded_timing_list = []\n",
    "for me_source, me_target in product(timing_list, repeat=2):    \n",
    "    # let's unpack this\n",
    "    me_source_option, me_source_timing = me_source\n",
    "    me_target_option, me_target_timing = me_target\n",
    "\n",
    "    me_source_option = me_source_option[17:25]\n",
    "    me_target_option = me_target_option[17:25]\n",
    "    me_source_target_timing_ratio = me_source_timing / me_target_timing\n",
    "    \n",
    "    # add to the list\n",
    "    expanded_timing_list.append([me_source_option, me_target_option, me_source_timing, me_target_timing, me_source_target_timing_ratio])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['source', 'target', 'source_timing', 'target_timing', 'timing_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_df = pd.DataFrame(data = expanded_timing_list, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the pd.pivot_table() function to display the ratios\n",
    "# we computed the product so all cells will be filled\n",
    "# but we only need to look at the top-diagonal\n",
    "# from left to right: we can see how much faster option 5 is than option 1\n",
    "# or how much faster option 4 is than option 3\n",
    "timing_table = timing_df.pivot_table(index = ['source'], columns = ['target'],\n",
    "                           values =['timing_ratio']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wow. So, based on this analysis of the different \n",
    "# matrix extraction options using the word 'achiever':\n",
    "# option 5 and 6 are the fastest, each over 100 times faster than option 1\n",
    "# option 4 - just using the single least common letter - is 10X faster than option 1\n",
    "# and 6X faster than option 3 - using the starting the letter of the word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
