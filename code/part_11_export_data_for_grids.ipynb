{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babb.mike@outlook.com\n",
    "# Find anagrams\n",
    "## Get the parent / child words of the top 5 word groups by character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from collections import Counter\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom\n",
    "import _run_constants as rc\n",
    "from part_00_file_db_utils import query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD COUNTS BY WORD GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join in word_group_id\n",
    "sql = 'select * from word_counts;'\n",
    "word_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn this into the word_group_df\n",
    "wg_df = word_df.drop_duplicates(subset=['word_group_id']).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank\n",
    "wg_df['n_from_rank'] = wg_df[['n_chars', 'n_from_words']].groupby(['n_chars']).rank(method = 'first', ascending=False)\n",
    "wg_df['n_to_rank'] = wg_df[['n_chars', 'n_to_words']].groupby(['n_chars']).rank(method = 'first',ascending=False)\n",
    "\n",
    "# melt to get the word count\n",
    "wc_df = pd.melt(frame = wg_df, id_vars = ['word_id', 'word_group_id', 'lcase', 'n_chars'],\n",
    "                  value_vars = ['n_from_words','n_to_words'],\n",
    "                  var_name = 'direction', value_name = 'n_words')\n",
    "\t\t\t\t  \n",
    "\t\t\t\t  \n",
    "recode_dict = {'n_from_words':'from',\n",
    "               'n_to_words':'to'}\n",
    "\n",
    "wc_df['direction'] = wc_df['direction'].map(recode_dict)\t\t\t   \n",
    "\t\t\t\t  \n",
    "# melt to get the ranks\n",
    "rank_df = pd.melt(frame = wg_df, id_vars = ['word_id', 'word_group_id', 'lcase', 'n_chars'],\n",
    "                  value_vars = ['n_from_rank','n_to_rank'],\n",
    "                  var_name = 'direction', value_name = 'word_rank')\t\t\t  \n",
    "\t\t\t\t  \n",
    "recode_dict = {'n_from_rank':'from',\n",
    "               'n_to_rank':'to'}\n",
    "\n",
    "rank_df['direction'] = rank_df['direction'].map(recode_dict)\t\t   \n",
    "\t\t\t\t  \t\t\t\t  \n",
    "# overwrite the wg_df by joining\n",
    "wg_df = pd.merge(left = wc_df, right = rank_df)\t\t\t\t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 5\n",
    "curr_wg_df = wg_df.loc[wg_df['word_rank'] <= 5, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_group_id_counter = Counter(word_df['word_group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df['word_group_size'] = curr_wg_df['word_group_id'].map(word_group_id_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df = curr_wg_df.sort_values(by = ['n_chars', 'lcase'])\n",
    "temp_output_df = curr_wg_df[['lcase', 'n_chars', 'direction', 'n_words', 'word_rank', 'word_group_size']]\n",
    "\n",
    "temp_output_df.columns = ['word', 'number of characters','direction', 'number of words', 'word rank', 'word group size']\n",
    "temp_output_df.to_json('../webpage/word_groups.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the from word id df\n",
    "sql = 'select word_group_id, word_id, lcase, n_chars from words;'\n",
    "fw_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)\n",
    "fw_df.columns = ['from_word_group_id', 'from_word_id', 'from_word', 'from_n_chars']\n",
    "\n",
    "# the to word id df\n",
    "sql = 'select word_group_id, word_id, lcase, n_chars from words;'\n",
    "tw_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)\n",
    "tw_df.columns = ['to_word_group_id', 'to_word_id', 'to_word', 'to_n_chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path\n",
    "word_list_output_path = '../webpage/wordlists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_words(df:pd.DataFrame, r_direction:str, curr_word:str):\n",
    "    if r_direction == 'from':\n",
    "        r_direction_opp = 'to'\n",
    "    else:\n",
    "        r_direction_opp = 'from'\n",
    "    # the output file and name\n",
    "    output_file_name = f'{r_direction}_{curr_word}.txt'\n",
    "    ofpn = os.path.join(word_list_output_path, output_file_name)\n",
    "    \n",
    "    with open(file = ofpn, mode = 'w') as my_file:\n",
    "        if df.empty:            \n",
    "            my_file.write(f\"## THERE ARE NO {r_direction} WORDS FOR {curr_word} ## \\n\")\n",
    "        else:\n",
    "\n",
    "            # number of characters to iterate through\n",
    "            nchar_list = sorted(df[f'{r_direction_opp}_n_chars'].unique().tolist(), reverse=True)\n",
    "        \n",
    "            for nc in nchar_list:\n",
    "                my_file.write(f\"##########\\n\")\n",
    "                my_file.write(f\"## WORDS OF LENGTH {nc} ## \\n\")\n",
    "                my_file.write(f\"##########\\n\")\n",
    "                # subset by \n",
    "                temp_df = df.loc[df[f'{r_direction_opp}_n_chars' ]==nc, [f'{r_direction_opp}_word']].copy()\n",
    "                temp_df = temp_df.drop_duplicates().sort_values(by = f'{r_direction_opp}_word')\n",
    "                for fw in temp_df[f'{r_direction_opp}_word'].tolist():\n",
    "                    my_file.write(fw + '  \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_words_json(df:pd.DataFrame, r_direction:str, curr_word:str):\n",
    "    \n",
    "    \n",
    "    # the output file and name\n",
    "    output_file_name = f'{curr_word}.json'\n",
    "    ofpn = os.path.join(word_list_output_path, r_direction, output_file_name)\n",
    "    \n",
    "    with open(file = ofpn, mode = 'w') as my_file:\n",
    "        \n",
    "        if df.empty:            \n",
    "            output_dict = {'word':curr_word,\n",
    "                       'number_of_words':0,\n",
    "                       'relatedWords':[]}        \n",
    "            json.dump(obj = output_dict, fp =  my_file, indent=4)            \n",
    "        else:\n",
    "            df[f'{r_direction}_n_chars'] = df[f'{r_direction}_word'].str.len()\n",
    "            col_names = [f'{r_direction}_n_chars', f'{r_direction}_word']            \n",
    "            temp_df = df.sort_values(by=col_names, ascending=[False, True])\n",
    "            word_list = temp_df[f'{r_direction}_word'].tolist()\n",
    "            #if curr_word in word_list:\n",
    "            #    word_list.remove(curr_word)\n",
    "\n",
    "            output_dict = {'word':curr_word,\n",
    "                           'number_of_words':temp_df.shape[0],\n",
    "                           'relatedWords':word_list}        \n",
    "            json.dump(obj = output_dict, fp =  my_file, indent=4)            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['word_group_id', 'lcase']\n",
    "temp_word_df = word_df[col_names].sort_values(by = col_names).drop_duplicates(subset = 'word_group_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of words!\n",
    "word_group_dict = {wg_id:word for wg_id, word in zip(temp_word_df['word_group_id'],\n",
    "                                                     temp_word_df['lcase'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_list_of_parent_words(word_group_id:int, db_path:str, db_name:str):\n",
    "\n",
    "    # build the list of parent words\n",
    "    sql = f'select from_word_group_id, to_word_group_id from anagram_groups where to_word_group_id = {word_group_id};'\n",
    "    \n",
    "    pwg_df = query_db(sql = sql, db_path=db_path, db_name=db_name)    \n",
    "\n",
    "    # now, get the word list\n",
    "    sql = 'select word_id as from_word_id, word_group_id as from_word_group_id, lcase as from_word from words;'\n",
    "    word_df = query_db(sql = sql, db_path=db_path, db_name=db_name)\n",
    "    pw_df = pd.merge(left = word_df, right = pwg_df)       \n",
    "    \n",
    "    # let's add information to highlight the focal word\n",
    "    col_names = ['from_word_group_id', 'from_word_id', 'from_word']\n",
    "    \n",
    "    id_df = pw_df.loc[pw_df['from_word_group_id'] == word_group_id, col_names].copy()\n",
    "\n",
    "    id_df.columns = ['to_word_group_id', 'to_word_id', 'to_word']\n",
    "    pw_df = pd.merge(left = pw_df, right = id_df)\n",
    "\n",
    "    col_names = ['from_word_id', 'to_word_id',\n",
    "                 'from_word_group_id','to_word_group_id',\n",
    "                 'from_word', 'to_word']\n",
    "    \n",
    "    pw_df = pw_df[col_names].drop_duplicates(subset=['from_word_id', 'from_word_group_id', 'from_word'])\n",
    "    \n",
    "    return pw_df\n",
    "\n",
    "def build_list_of_child_words(word_group_id:int, db_path:str, db_name:str):\n",
    "\n",
    "    # build the list of parent words\n",
    "    sql = f'select from_word_group_id, to_word_group_id from anagram_groups where from_word_group_id = {word_group_id};'\n",
    "    \n",
    "    cwg_df = query_db(sql = sql, db_path=db_path, db_name=db_name)\n",
    "\n",
    "    # now, get the word list\n",
    "    sql = 'select word_id as to_word_id, word_group_id as to_word_group_id, lcase as to_word from words;'\n",
    "    word_df = query_db(sql = sql, db_path=db_path, db_name=db_name)\n",
    "\n",
    "    cw_df = pd.merge(left = word_df, right = cwg_df)\n",
    "        \n",
    "    # let's add information to highlight the focal word\n",
    "    col_names = ['to_word_group_id', 'to_word_id', 'to_word']\n",
    "\n",
    "    id_df = cw_df.loc[cw_df['to_word_group_id'] == word_group_id, col_names].copy()\n",
    "    \n",
    "    id_df.columns = ['from_word_group_id', 'from_word_id', 'from_word']\n",
    "    cw_df = pd.merge(left = cw_df, right = id_df)\n",
    "    \n",
    "    col_names = ['from_word_id', 'to_word_id',\n",
    "                 'from_word_group_id','to_word_group_id',\n",
    "                 'from_word', 'to_word']\n",
    "    \n",
    "    cw_df = cw_df[col_names].drop_duplicates(subset=['to_word_id', 'to_word_group_id', 'to_word'])\n",
    "    \n",
    "\n",
    "    return cw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_id = 60945\n",
    "pw_df = build_list_of_parent_words(word_group_id=wg_id, db_path=rc.db_path, db_name=rc.db_name)\n",
    "cw_df = build_list_of_child_words(word_group_id=wg_id, db_path=rc.db_path, db_name=rc.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counters\n",
    "to_word_counter = Counter()\n",
    "from_word_counter = Counter()\n",
    "#test_wg_df = curr_wg_df.iloc]\n",
    "for i_c, row in curr_wg_df.iterrows():\n",
    "    \n",
    "\n",
    "    # the current word\n",
    "    curr_word_group_id = row['word_group_id']\n",
    "    curr_word = word_group_dict[curr_word_group_id]    \n",
    "    print(curr_word)\n",
    "\n",
    "    if row['direction'] == 'to':\n",
    "        print('#### TO WORDS')        \n",
    "        \n",
    "        cw_df = build_list_of_child_words(word_group_id=curr_word_group_id,\n",
    "                                          db_path = rc.db_path, db_name = rc.db_name)        \n",
    "        \n",
    "        # save it\n",
    "        save_words_json(df = cw_df, r_direction='to', curr_word=curr_word)\n",
    "        \n",
    "        # distinct from words\n",
    "        #from_word_counter.update(wg_df['from_word_id'])\n",
    "\n",
    "    if row['direction'] == 'from':\n",
    "        print('#### FROM WORDS')\n",
    "        \n",
    "        pw_df = build_list_of_parent_words(word_group_id=curr_word_group_id,\n",
    "                                          db_path = rc.db_path, db_name = rc.db_name)        \n",
    "        \n",
    "                \n",
    "        # save it\n",
    "        save_words_json(df = pw_df, r_direction='from', curr_word=curr_word)\n",
    "        \n",
    "\n",
    "        # distinct to words\n",
    "        #to_word_counter.update(wg_df['to_word_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the letters in the top five words by word length can be found in:\n",
    "print(len(from_word_counter)) \n",
    "# which is:\n",
    "print(len(from_word_counter) / word_df.shape[0])\n",
    "# of words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the letters in the top five words by word length can be rearraged to spell:\n",
    "print(len(to_word_counter))\n",
    "# which is:\n",
    "print(len(to_word_counter) / word_df.shape[0])\n",
    "# of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what letters are represented?\n",
    "from_letter_counter = Counter()\n",
    "to_letter_counter = Counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ir, row in curr_wg_df.iterrows():\n",
    "    if row['direction'] == 'from':\n",
    "        from_letter_counter.update(row['lcase'])\n",
    "    if row['direction'] == 'to':\n",
    "        to_letter_counter.update(row['lcase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_letter_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ascii_lowercase).difference(from_letter_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ascii_lowercase).difference(to_letter_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_letter_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
