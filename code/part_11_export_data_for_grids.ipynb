{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babb.mike@outlook.com\n",
    "# Find anagrams\n",
    "## Get the parent / child words of the top 5 word groups by character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from collections import Counter\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom\n",
    "import _run_constants as rc\n",
    "from part_00_file_db_utils import query_db\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD COUNTS BY WORD GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join in word_group_id\n",
    "sql = 'select * from word_counts;'\n",
    "word_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn this into the word_group_df\n",
    "col_names = ['word_group_id', 'lcase']\n",
    "wg_df = word_df.sort_values(by = col_names).drop_duplicates(subset = 'word_group_id').copy()\n",
    "\n",
    "# dictionary of words!\n",
    "word_group_dict = {wg_id:word for wg_id, word in zip(wg_df['word_group_id'],\n",
    "                                                     wg_df['lcase'])}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the top five words by from/to status by character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks for words\n",
    "wg_df['n_from_rank'] = wg_df[['n_chars', 'n_from_words']].groupby(['n_chars']).rank(method = 'first', ascending=False)\n",
    "wg_df['n_to_rank'] = wg_df[['n_chars', 'n_to_words']].groupby(['n_chars']).rank(method = 'first',ascending=False)\n",
    "\n",
    "# melt to get the word count\n",
    "wc_df = pd.melt(frame = wg_df, id_vars = ['word_id', 'word_group_id', 'lcase', 'n_chars'],\n",
    "                  value_vars = ['n_from_words','n_to_words'],\n",
    "                  var_name = 'direction', value_name = 'n_words')\n",
    "\t\t\t\t  \n",
    "# word count\t\t\t\t  \n",
    "recode_dict = {'n_from_words':'from',\n",
    "               'n_to_words':'to'}\n",
    "\n",
    "wc_df['direction'] = wc_df['direction'].map(recode_dict)\t\t\t   \n",
    "\t\t\t\t  \n",
    "# melt to get the ranks\n",
    "rank_df = pd.melt(frame = wg_df, id_vars = ['word_id', 'word_group_id', 'lcase', 'n_chars'],\n",
    "                  value_vars = ['n_from_rank','n_to_rank'],\n",
    "                  var_name = 'direction', value_name = 'word_rank')\t\t\t  \n",
    "\t\t\t\t  \n",
    "recode_dict = {'n_from_rank':'from',\n",
    "               'n_to_rank':'to'}\n",
    "\n",
    "rank_df['direction'] = rank_df['direction'].map(recode_dict)\t\t   \n",
    "\t\t\t\t  \t\t\t\t  \n",
    "# overwrite the wg_df by joining\n",
    "wg_df = pd.merge(left = wc_df, right = rank_df)\t\t\t\t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 5\n",
    "curr_wg_df = wg_df.loc[wg_df['word_rank'] <= 5, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many words are in each word group\n",
    "word_group_id_counter = Counter(word_df['word_group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df['word_group_size'] = curr_wg_df['word_group_id'].map(word_group_id_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort, select columns, and save to disk\n",
    "# this is the data that populates the grid\n",
    "curr_wg_df['word_rank'] = curr_wg_df['word_rank'].round(0).astype(int)\n",
    "\n",
    "curr_wg_df = curr_wg_df.sort_values(by = ['n_chars', 'lcase'])\n",
    "temp_output_df = curr_wg_df[['lcase', 'n_chars', 'direction', 'n_words', 'word_rank', 'word_group_size']]\n",
    "\n",
    "temp_output_df.columns = ['word', 'number of characters','direction', 'number of words', 'word rank', 'word group size']\n",
    "temp_output_df.to_json('../webpage/word_groups.json',orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate the list of words for each word group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the from word id df\n",
    "sql = 'select word_group_id, word_id, lcase, n_chars from words;'\n",
    "fw_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)\n",
    "fw_df.columns = ['from_word_group_id', 'from_word_id', 'from_word', 'from_n_chars']\n",
    "\n",
    "# create the to word id df\n",
    "sql = 'select word_group_id, word_id, lcase, n_chars from words;'\n",
    "tw_df = query_db(sql = sql, db_path=rc.db_path, db_name=rc.db_name)\n",
    "tw_df.columns = ['to_word_group_id', 'to_word_id', 'to_word', 'to_n_chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path to save the generated word lists\n",
    "word_list_output_path = '../webpage/wordlists'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_list_of_parent_words(word_group_id: int, db_path: str, db_name: str):\n",
    "\n",
    "    # build the list of parent words\n",
    "    sql = f'select from_word_group_id, to_word_group_id from anagram_groups where to_word_group_id = {word_group_id};'\n",
    "\n",
    "    pwg_df = query_db(sql=sql, db_path=db_path, db_name=db_name)\n",
    "\n",
    "    # now, get the word list\n",
    "    sql = 'select word_id as from_word_id, word_group_id as from_word_group_id, lcase as from_word from words;'\n",
    "    word_df = query_db(sql=sql, db_path=db_path, db_name=db_name)\n",
    "    pw_df = pd.merge(left=word_df, right=pwg_df)\n",
    "\n",
    "    # let's add information to highlight the focal word\n",
    "    # select\n",
    "    col_names = ['from_word_group_id', 'from_word_id', 'from_word']\n",
    "\n",
    "    # get a single row - the focal word\n",
    "    id_df = pw_df.loc[pw_df['from_word_group_id']\n",
    "                      == word_group_id, col_names].copy()\n",
    "\n",
    "    # rename\n",
    "    id_df.columns = ['to_word_group_id', 'to_word_id', 'to_word']\n",
    "    # merge\n",
    "    pw_df = pd.merge(left=pw_df, right=id_df)\n",
    "\n",
    "    # reorder\n",
    "    col_names = ['from_word_id', 'to_word_id',\n",
    "                 'from_word_group_id', 'to_word_group_id',\n",
    "                 'from_word', 'to_word']\n",
    "\n",
    "    # drop duplicates, if any\n",
    "    pw_df = pw_df[col_names].drop_duplicates(\n",
    "        subset=['from_word_id', 'from_word_group_id', 'from_word'])\n",
    "\n",
    "    return pw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_list_of_child_words(word_group_id: int, db_path: str, db_name: str):\n",
    "\n",
    "    # build the list of parent words\n",
    "    sql = f'select from_word_group_id, to_word_group_id from anagram_groups where from_word_group_id = {word_group_id};'\n",
    "\n",
    "    cwg_df = query_db(sql=sql, db_path=db_path, db_name=db_name)\n",
    "\n",
    "    # now, get the word list\n",
    "    sql = 'select word_id as to_word_id, word_group_id as to_word_group_id, lcase as to_word from words;'\n",
    "    word_df = query_db(sql=sql, db_path=db_path, db_name=db_name)\n",
    "\n",
    "    cw_df = pd.merge(left=word_df, right=cwg_df)\n",
    "\n",
    "    # let's add information to highlight the focal word\n",
    "    col_names = ['to_word_group_id', 'to_word_id', 'to_word']\n",
    "\n",
    "    id_df = cw_df.loc[cw_df['to_word_group_id']\n",
    "                      == word_group_id, col_names].copy()\n",
    "\n",
    "    id_df.columns = ['from_word_group_id', 'from_word_id', 'from_word']\n",
    "    cw_df = pd.merge(left=cw_df, right=id_df)\n",
    "\n",
    "    col_names = ['from_word_id', 'to_word_id',\n",
    "                 'from_word_group_id', 'to_word_group_id',\n",
    "                 'from_word', 'to_word']\n",
    "\n",
    "    cw_df = cw_df[col_names].drop_duplicates(\n",
    "        subset=['to_word_id', 'to_word_group_id', 'to_word'])\n",
    "\n",
    "    return cw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = 'formaldehydesulphoxylate'\n",
    "wg_id = word_df.loc[word_df['lcase'] == test_word, 'word_group_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df = build_list_of_parent_words(word_group_id=wg_id, db_path=rc.db_path, db_name=rc.db_name)\n",
    "print(pw_df.shape)\n",
    "cw_df = build_list_of_child_words(word_group_id=wg_id, db_path=rc.db_path, db_name=rc.db_name)\n",
    "print(cw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counters\n",
    "to_word_counter = Counter()\n",
    "from_word_counter = Counter()\n",
    "for i_c, row in curr_wg_df.iterrows():\n",
    "    \n",
    "    # the current word\n",
    "    curr_word_group_id = row['word_group_id']\n",
    "    curr_word = word_group_dict[curr_word_group_id]        \n",
    "\n",
    "    if row['direction'] == 'from':\n",
    "        print('####', curr_word, 'FROM WORDS')\n",
    "        \n",
    "        pw_df = build_list_of_parent_words(word_group_id=curr_word_group_id,\n",
    "                                          db_path = rc.db_path, db_name = rc.db_name)               \n",
    "                \n",
    "        # save it\n",
    "        format_and_save_words_json(df = pw_df, r_direction='from',\n",
    "                                   curr_word=curr_word, output_path=word_list_output_path)\n",
    "        \n",
    "\n",
    "        # distinct to words\n",
    "        to_word_counter.update(pw_df['to_word_id'])\n",
    "\n",
    "\n",
    "    if row['direction'] == 'to':\n",
    "        print('####', curr_word, 'TO WORDS')        \n",
    "        \n",
    "        cw_df = build_list_of_child_words(word_group_id=curr_word_group_id,\n",
    "                                          db_path = rc.db_path, db_name = rc.db_name)        \n",
    "        \n",
    "        # save it\n",
    "        format_and_save_words_json(df = cw_df, r_direction='to',\n",
    "                                   curr_word=curr_word, output_path=word_list_output_path)\n",
    "        \n",
    "        # distinct from words\n",
    "        from_word_counter.update(cw_df['from_word_id'])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the letters in the top five from words by word length can be found in:\n",
    "print(len(from_word_counter)) \n",
    "# which is:\n",
    "print(len(from_word_counter) / word_df.shape[0])\n",
    "# of words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the letters in the top five words by word length can be rearraged to spell:\n",
    "print(len(to_word_counter))\n",
    "# which is:\n",
    "print(len(to_word_counter) / word_df.shape[0])\n",
    "# of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what letters are represented?\n",
    "from_letter_counter = Counter()\n",
    "to_letter_counter = Counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ir, row in curr_wg_df.iterrows():\n",
    "    if row['direction'] == 'from':\n",
    "        from_letter_counter.update(row['lcase'])\n",
    "    if row['direction'] == 'to':\n",
    "        to_letter_counter.update(row['lcase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_letter_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ascii_lowercase).difference(from_letter_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ascii_lowercase).difference(to_letter_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_letter_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
