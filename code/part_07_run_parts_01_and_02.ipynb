{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babb.mike@outlook.com\n",
    "# Find anagrams\n",
    "## Part 7: Run part 01, part 02, and part 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import csv\n",
    "import os\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part_00_process_functions import build_db_conn, query_db\n",
    "import _run_constants as rc\n",
    "from part_01_structure_data import run_part_01\n",
    "from part_02_demonstrate_extraction_timing_techniques import run_part_02\n",
    "from part_03_generate_and_store_anagrams import run_part_03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_part_01(\n",
    "        in_file_path=rc.in_file_path,\n",
    "        in_file_name=rc.in_file_name,\n",
    "        base_output_file_path=rc.base_output_file_path,\n",
    "        db_name=rc.db_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 02a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_part_02(db_path=rc.db_path, db_name=rc.db_name,\n",
    "           data_output_file_path=rc.data_output_file_path,\n",
    "           n_subset_letters=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 02b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 1.55 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 1.34 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n",
      "...enumerating 16,101 records...\n",
      "...1,000 records enumerated...\n",
      "...2,000 records enumerated...\n",
      "...3,000 records enumerated...\n",
      "...4,000 records enumerated...\n",
      "...5,000 records enumerated...\n",
      "...6,000 records enumerated...\n",
      "...7,000 records enumerated...\n",
      "...8,000 records enumerated...\n",
      "...9,000 records enumerated...\n",
      "...10,000 records enumerated...\n",
      "...11,000 records enumerated...\n",
      "...12,000 records enumerated...\n",
      "...13,000 records enumerated...\n",
      "...14,000 records enumerated...\n",
      "...15,000 records enumerated...\n",
      "...16,000 records enumerated...\n",
      "...2,387 sub-matrices created...\n",
      "Total extraction time: 9.33 seconds.\n",
      "...query execution took: 0.0 seconds...\n",
      "...finding parent anagrams for 215,842 words...\n",
      "...found parent anagrams for 10,000 words...\n",
      "...found parent anagrams for 20,000 words...\n",
      "...found parent anagrams for 30,000 words...\n",
      "...found parent anagrams for 40,000 words...\n",
      "...found parent anagrams for 50,000 words...\n",
      "...found parent anagrams for 60,000 words...\n",
      "...found parent anagrams for 70,000 words...\n",
      "...found parent anagrams for 80,000 words...\n",
      "...found parent anagrams for 90,000 words...\n",
      "...found parent anagrams for 100,000 words...\n",
      "...found parent anagrams for 110,000 words...\n",
      "...found parent anagrams for 120,000 words...\n",
      "...found parent anagrams for 130,000 words...\n",
      "...found parent anagrams for 140,000 words...\n",
      "...found parent anagrams for 150,000 words...\n",
      "...found parent anagrams for 160,000 words...\n",
      "...found parent anagrams for 170,000 words...\n",
      "...found parent anagrams for 180,000 words...\n",
      "...found parent anagrams for 190,000 words...\n",
      "...found parent anagrams for 200,000 words...\n",
      "...found parent anagrams for 210,000 words...\n",
      "...found parent anagrams for 215,842 words...\n",
      "...finding parent anagrams for 215,842 words took 178.15 seconds | 2.97 minutes...\n",
      "...truncating output list...\n",
      "...populating the count of to-words...\n",
      "...total anagram pairs: 73,179,245\n",
      "...now writing: words_me_05\n",
      "...anagram discovery time: 178.15 seconds | 2.97 minutes\n",
      "...total processing time: 201.84 seconds | 3.36 minutes\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# process control flags\n",
    "####\n",
    "\n",
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 5\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "# Testing options\n",
    "# NoneL to include all letters\n",
    "# ['q', 'x'] or a different set of letters to test a specific letter\n",
    "# 'SAMPLE' to take a 10% sample by word length group\n",
    "# letter_subset_list = ['x']\n",
    "# letter_subset_list = 'SAMPLE'\n",
    "letter_subset_list = None\n",
    "\n",
    "run_part_03(matrix_extraction_option=matrix_extraction_option, n_subset_letters=n_subset_letters, letter_subset_list=letter_subset_list,\n",
    "       write_data=write_data, db_path=rc.db_path, db_name=rc.db_name, in_file_path=rc.in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
