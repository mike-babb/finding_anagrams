{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fa58d5-75a5-41ea-8943-ebae8f18d273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from time import perf_counter_ns\n",
    "import time\n",
    "\n",
    "# external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# custom libraries\n",
    "from _run_constants import *\n",
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fca8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_func             :    CPU:    65.900 us   +/-  9.852 (min:    54.400 / max:    85.600) us     GPU-0:   199.754 us   +/-  9.331 (min:   192.256 / max:   226.304) us\n"
     ]
    }
   ],
   "source": [
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def my_func(a):\n",
    "    return cp.sqrt(cp.sum(a**2, axis=-1))\n",
    "\n",
    "a = cp.random.random((256, 1024))\n",
    "print(benchmark(my_func, (a,), n_repeat=20))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead0a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6768640279769897 0.0006055999983800575\n"
     ]
    }
   ],
   "source": [
    "# initialize some gpu stats\n",
    "start_gpu = cp.cuda.Event()\n",
    "end_gpu = cp.cuda.Event()\n",
    "\n",
    "start_gpu.record()\n",
    "start_cpu = time.perf_counter()\n",
    "out = my_func(a)\n",
    "end_cpu = time.perf_counter()\n",
    "end_gpu.record()\n",
    "end_gpu.synchronize()\n",
    "t_gpu = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\n",
    "t_cpu = end_cpu - start_cpu\n",
    "print(t_gpu, t_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbee031",
   "metadata": {},
   "source": [
    "# LOAD INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247235e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 0.5 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 0.49 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, \\\n",
    "    word_group_id_list, word_id_list, wchar_matrix = load_input_data(\n",
    "        db_path=rc.DB_PATH, db_name=rc.DB_NAME,\n",
    "        in_file_path=rc.IN_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff2e4d",
   "metadata": {},
   "source": [
    "# let's process 1000 rows using a single lookup using the full matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b36966",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_anagrams = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25610500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,000,000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{n_possible_anagrams :,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f806b2",
   "metadata": {},
   "source": [
    "# Using the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb82534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "truncating list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(367646, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1000 rows\n",
    "n_samples = 1000\n",
    "sample_wg_id = wg_df['word_group_id'].sample(n = n_samples, random_state = 42).to_numpy()\n",
    "\n",
    "# establish counters for record keeping\n",
    "output_list = np.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "row_count = 0\n",
    "anagram_pair_count = 0\n",
    "intermediate_to_word_count = collections.Counter()\n",
    "\n",
    "for wg_id in sample_wg_id:\n",
    "    # identify parent words\n",
    "    outcome = wchar_matrix - wchar_matrix[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = np.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    n_from_words = outcome_indices.sum()\n",
    "\n",
    "    if n_from_words >= 1:\n",
    "        # extract anagrams based on index values    \n",
    "        outcome_word_id_list = word_group_id_list[outcome_indices]    \n",
    "\n",
    "        # we have matches\n",
    "        # the focal word\n",
    "        curr_output_list = np.zeros(shape=(n_from_words, 2), dtype=int)\n",
    "\n",
    "        # update the output list with the word_id_list - these are from/parent words\n",
    "        curr_output_list[:, 0] = outcome_word_id_list\n",
    "\n",
    "        # update with the word_id - this is the to/child word\n",
    "        curr_output_list[:, 1] = wg_id\n",
    "\n",
    "        # enumerate the from/parent wordsds\n",
    "        new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "        output_list[anagram_pair_count:new_anagram_pair_count,\n",
    "                    :] = curr_output_list\n",
    "\n",
    "        # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "        intermediate_to_word_count.update(outcome_word_id_list.tolist())\n",
    "\n",
    "        # set the anagram pair count\n",
    "        anagram_pair_count = new_anagram_pair_count\n",
    "    \n",
    "    row_count += 1\n",
    "\n",
    "    if row_count % 100 == 0:\n",
    "        print(row_count)\n",
    "print('truncating list')\n",
    "output_indices = np.all(output_list >= 0, axis=1)\n",
    "output_list = output_list[output_indices,]\n",
    "del output_indices\n",
    "output_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df50a3",
   "metadata": {},
   "source": [
    "# using the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561dc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to cupy objects\n",
    "wchar_matrix_cp = cp.asarray(a = wchar_matrix)\n",
    "word_group_id_list_cp = cp.asarray(a = word_group_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780194d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...query execution took: 0.0 seconds...\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = load_possible_anagrams(db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4085c88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198842245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_possible_anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823231d3-51f8-4a6e-a1bd-e4db346a680d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncating list\n",
      "(367646, 2)\n"
     ]
    }
   ],
   "source": [
    "# establish counters for record keeping\n",
    "# sample 1000 rows\n",
    "n_samples = 1000\n",
    "sample_wg_id = wg_df['word_group_id'].sample(n = n_samples, random_state = 42).to_numpy()\n",
    "# sample_wg_id = wg_df['word_group_id'].to_numpy()\n",
    "sample_wg_id_cp = cp.asarray(a = sample_wg_id)\n",
    "\n",
    "output_list_cp = cp.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "row_count = 0\n",
    "anagram_pair_count = 0\n",
    "intermediate_to_word_count = collections.Counter()\n",
    "\n",
    "for wg_id in sample_wg_id_cp:\n",
    "    outcome = wchar_matrix_cp - wchar_matrix_cp[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices_cp = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    n_from_words = outcome_indices_cp.sum()   \n",
    "            \n",
    "    \n",
    "    if n_from_words >= 1:\n",
    "        # extract anagrams based on index values    \n",
    "        outcome_word_id_list_cp = word_group_id_list_cp[outcome_indices_cp]    \n",
    "\n",
    "        # we have matches\n",
    "        curr_output_list_cp = cp.zeros(shape=(outcome_word_id_list_cp.shape[0], 2), dtype=int)\n",
    "\n",
    "        # update the output list with the word_id_list - these are from/parent words\n",
    "        curr_output_list_cp[:, 0] = outcome_word_id_list_cp\n",
    "\n",
    "        # update with the word_id - this is the to/child word\n",
    "        curr_output_list_cp[:, 1] = wg_id\n",
    "\n",
    "        # enumerate the from/parent wordsds\n",
    "        new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "        # update the total output list\n",
    "        output_list_cp[anagram_pair_count:new_anagram_pair_count,\n",
    "                    :] = curr_output_list_cp\n",
    "\n",
    "        # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "        intermediate_to_word_count.update(outcome_word_id_list_cp.tolist())\n",
    "\n",
    "        # set the anagram pair count\n",
    "        anagram_pair_count = new_anagram_pair_count\n",
    "    \n",
    "    row_count += 1\n",
    "\n",
    "    if row_count % 10000 == 0:\n",
    "        print(row_count)\n",
    "\n",
    "print('truncating list')\n",
    "output_indices_cp = cp.all(output_list_cp >= 0, axis=1)\n",
    "output_list_cp = output_list_cp[output_indices_cp,]\n",
    "del output_indices_cp\n",
    "print(output_list_cp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4412a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248af44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the matrix, gather the values for each split, and then combine\n",
    "n_subset_letters = 3\n",
    "wg_df[\"letter_selector\"] = wg_df[\"letter_group_ranked\"].str[:n_subset_letters]\n",
    "\n",
    "letter_selector_list = wg_df[\"letter_selector\"].unique()\n",
    "letter_selector_list.sort()\n",
    "letter_selector_id_dict = {ls: i_ls for i_ls, ls in enumerate(letter_selector_list)}\n",
    "\n",
    "wg_df[\"letter_selector_id\"] = wg_df[\"letter_selector\"].map(letter_selector_id_dict)\n",
    "# here's the thing: I need to be able to identify on a single matrix the rows that match various conditions.\n",
    "# I can't step through it and create objects at abandon. \n",
    "# so, given our wchar_matrix: what are the rows that match to such and such?\n",
    "# we can add three columns to track this... b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b38675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load letter ranks\n",
    "sql = 'select letter, total_letter_rank from letter_count;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9c281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...query execution took: 0.0 seconds...\n"
     ]
    }
   ],
   "source": [
    "lr_df = query_db(sql = sql, db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c08a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>word_group_count</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>letter_selector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>1</td>\n",
       "      <td>lai</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "      <td>2</td>\n",
       "      <td>ma</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked  word_group_count letter_selector  letter_selector_id  \n",
       "0                   a                 1               a                   0  \n",
       "1                   a                 1               a                   0  \n",
       "2                  la                 2              la                1081  \n",
       "3                 lai                 1             lai                1083  \n",
       "4                  ma                 2              ma                1114  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09152a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dict = {l:r for l, r in zip(lr_df['letter'], lr_df['total_letter_rank'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc8990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgr_id(lgr:str):\n",
    "    outcome = [-1, -1, -1]\n",
    "    for i_cl, cl in enumerate(lgr):        \n",
    "        outcome[i_cl] = letter_dict[cl]\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c7f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>word_group_count</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>letter_selector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>1</td>\n",
       "      <td>lai</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "      <td>2</td>\n",
       "      <td>ma</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked  word_group_count letter_selector  letter_selector_id  \n",
       "0                   a                 1               a                   0  \n",
       "1                   a                 1               a                   0  \n",
       "2                  la                 2              la                1081  \n",
       "3                 lai                 1             lai                1083  \n",
       "4                  ma                 2              ma                1114  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c9ac54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = wg_df['letter_selector'].value_counts().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7cc649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gyh</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yhp</td>\n",
       "      <td>2494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yhm</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hmp</td>\n",
       "      <td>2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yhd</td>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter_selector  count\n",
       "0             gyh   2544\n",
       "1             yhp   2494\n",
       "2             yhm   2438\n",
       "3             hmp   2180\n",
       "4             yhd   2091"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d46577b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df['ls_id_vector'] = ls_df['letter_selector'].map(get_lgr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7db74a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>count</th>\n",
       "      <th>ls_id_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gyh</td>\n",
       "      <td>2544</td>\n",
       "      <td>[6, 24, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yhp</td>\n",
       "      <td>2494</td>\n",
       "      <td>[24, 7, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yhm</td>\n",
       "      <td>2438</td>\n",
       "      <td>[24, 7, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hmp</td>\n",
       "      <td>2180</td>\n",
       "      <td>[7, 12, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yhd</td>\n",
       "      <td>2091</td>\n",
       "      <td>[24, 7, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter_selector  count ls_id_vector\n",
       "0             gyh   2544   [6, 24, 7]\n",
       "1             yhp   2494  [24, 7, 15]\n",
       "2             yhm   2438  [24, 7, 12]\n",
       "3             hmp   2180  [7, 12, 15]\n",
       "4             yhd   2091   [24, 7, 3]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbbccea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_id_cp = cp.asarray(a = ls_df['ls_id_vector'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1bad5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2387, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_id_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51012680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 24,  7],\n",
       "       [24,  7, 15],\n",
       "       [24,  7, 12],\n",
       "       ...,\n",
       "       [25, 10,  4],\n",
       "       [25,  4, -1],\n",
       "       [25,  0,  4]], shape=(2387, 3))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_id_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dfe9ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls_id_index in range(0, 1):\n",
    "    curr_ls_id_cp = ls_id_cp[ls_id_index, :]\n",
    "    outcome = curr_ls_id_cp >= 0\n",
    "    col_selector = curr_ls_id_cp[outcome]\n",
    "    outcome_indices_cp = cp.all(wchar_matrix_cp[:, col_selector] >= 1, axis=1)\n",
    "    ls_wchar_matrix_cp = wchar_matrix_cp[outcome_indices_cp, :]\n",
    "    ls_wchar_matrix_cp.shape\n",
    "    for ii in range(0, ls_wchar_matrix_cp.shape[0]):\n",
    "        outcome = ls_wchar_matrix_cp - ls_wchar_matrix_cp[ii, :]\n",
    "        outcome_check = cp.all(outcome > 0, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b32a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3130, 26)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1016c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5051846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>lgr_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[0, -1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>[11, 0, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lai</td>\n",
       "      <td>[11, 0, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ma</td>\n",
       "      <td>[12, 0, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nai</td>\n",
       "      <td>[13, 0, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter_selector       lgr_id\n",
       "0               a  [0, -1, -1]\n",
       "2              la  [11, 0, -1]\n",
       "3             lai   [11, 0, 8]\n",
       "4              ma  [12, 0, -1]\n",
       "5             nai   [13, 0, 8]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af742910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7580de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cefac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f08eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ed2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['lgr_id'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    " outcome = wchar_matrix_cp - wchar_matrix_cp[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices_cp = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    n_from_words = outcome_indices_cp.sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build that rank tuple, and attach to the wg_df\n",
    "def get_rank(lgr:str):\n",
    "    outcome = [-1, -1, -1]\n",
    "    for i_cl, cl in enumerate(lgr):\n",
    "        outcome[i_cl] = lr_dict[cl]\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['that_rank'] = wg_df['letter_selector'].map(get_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wchar_matrix = np.zeros(shape = (wg_df.shape[0], wchar_matrix.shape[1] + 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wchar_matrix[:, :wchar_matrix.shape[1]] = wchar_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_ranks = np.array(object = wg_df['that_rank'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da642263",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wchar_matrix[:, -3:] = ls_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf79683",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wchar_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_ranks_cp = cp.asarray(ls_ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646345d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_ranks_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d27620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the submatrix for all rows that feature the letter a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9730ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e8548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccadd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# least common letter 1, least common letter 2, least common letter 3\n",
    "for ls in ls_ranks_cp:\n",
    "    \n",
    "    # get the indices of the single_letter_wchar_matrix that feature the n least common letters\n",
    "    outcome_cp = wchar_matrix_cp[:, -3:] == ls # this generates a true/false array\n",
    "    outcome_indices_cp = word_group_id_list_cp[outcome_cp] # this is the working list of ids\n",
    "   \n",
    "    # subset the wchar_matrix to get the sub-matrix - this contains the N least common letters for a group of words\n",
    "    ls_wchar_matrix_cp = wchar_matrix_cp[outcome_indices,]\n",
    "    # this is the working matrix\n",
    "    # so, let's subset the df\n",
    "\n",
    "    new_word_id = ls_wg_id_list == wg_id\n",
    "    print(type(new_word_id))\n",
    "\n",
    "    # now, perform the comparison\n",
    "    outcome = ls_wchar_matrix - ls_wchar_matrix[new_word_id,]\n",
    "    print(type(outcome))\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    print(type(outcome_indices))\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = ls_wg_id_list[outcome_indices]\n",
    "    print(type(outcome_word_id_list))\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "    print(type(output_list))\n",
    "    \n",
    "    \n",
    "    outcome_word_id_list = get_values_letter_selector_cp(\n",
    "                wg_id=wg_id,\n",
    "                letter_selector_id=row.letter_selector_id,\n",
    "                letter_selector_matrix_dict=letter_selector_matrix_dict,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03929d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311441cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_matrix_cp(\n",
    "    letter_dict: dict,\n",
    "    word_group_id_list: cp.ndarray,\n",
    "    wg_df: pd.DataFrame,\n",
    "    wchar_matrix: cp.ndarray,\n",
    "    n_subset_letters: int,\n",
    "    matrix_extraction_option: int = 0\n",
    "):\n",
    "\n",
    "    # the different matrix extraction options\n",
    "    # Option 0: Return all of the different types of matrix extraction options\n",
    "    # Option 1: Full matrix - no objects are returned\n",
    "    # Option 2: Word-length - returns matrices split by the number of characters\n",
    "    # Option 3: First letter - returns matrices split by each letter\n",
    "    # Option 4: Single-least common letter - return matrices split by each letter\n",
    "    # Option 5: n least common letters - return matrices split by least common letters\n",
    "    # Option 6: word-length and n least common letters - return matrices split by least common letters and word length.\n",
    "\n",
    "    s_time = perf_counter_ns()\n",
    "    \n",
    "\n",
    "    # create the letter selector and determine the max number\n",
    "    # of sub-matrices to makes\n",
    "    wg_df[\"letter_selector\"] = wg_df[\"letter_group_ranked\"].str[:n_subset_letters]\n",
    "    wg_df[\"first_letter_id\"] = wg_df[\"first_letter\"].map(letter_dict)\n",
    "    wg_df[\"single_letter_id\"] = wg_df[\"letter_selector\"].str[0].map(\n",
    "        letter_dict)\n",
    "\n",
    "    # build the letter selector id list and dict\n",
    "    letter_selector_list = wg_df[\"letter_selector\"].unique()\n",
    "    letter_selector_list.sort()\n",
    "    letter_selector_id_dict = {ls: i_ls for i_ls,\n",
    "                               ls in enumerate(letter_selector_list)}\n",
    "\n",
    "    wg_df[\"letter_selector_id\"] = wg_df[\"letter_selector\"].map(\n",
    "        letter_selector_id_dict)\n",
    "\n",
    "    nc_ls_df = wg_df[\n",
    "        [\"n_chars\", \"letter_selector_id\", \"letter_selector\"]\n",
    "    ].drop_duplicates()\n",
    "    nc_ls_df[\"nc_ls_id\"] = range(0, nc_ls_df.shape[0])\n",
    "\n",
    "    wg_df = pd.merge(left=wg_df, right=nc_ls_df)\n",
    "\n",
    "    # only proceed if matrix_extraction_option != 1:\n",
    "    if matrix_extraction_option != 1:\n",
    "\n",
    "        # word length dictionary\n",
    "        # used in matrix extraction option: 2\n",
    "        n_char_matrix_dict = {}\n",
    "\n",
    "        # single letter matrix dict\n",
    "        # used in matrix extraction option: 3 and 4\n",
    "        single_letter_matrix_dict = {}\n",
    "\n",
    "        # letter selector dictionary\n",
    "        # used in matrix extraction option: 5\n",
    "        letter_selector_matrix_dict = {}\n",
    "\n",
    "        # word length and lettor selector dictionary\n",
    "        # used in matrix extraction option: 6\n",
    "        nc_ls_matrix_dict = {}\n",
    "\n",
    "        # create dictionaries to hold sets - these will only exist in the context of this function\n",
    "        n_char_set_dict = {}\n",
    "        single_letter_set_dict = {}\n",
    "        letter_selector_set_dict = {}\n",
    "\n",
    "        # enumerate these combinations only once\n",
    "        # reduce the number of times we have to compute ids and sub-matrices\n",
    "\n",
    "        # we have created some ids, but we don't need to enumerate for all of the\n",
    "        # matrix extraction options.\n",
    "        # but because of the way enumeration and creation of dictionaries is\n",
    "        # setup, we're over-enumerating for options 2 through 5.\n",
    "        # this is trade off between minimizing code, code reuse, and data enumeration\n",
    "        n_records = nc_ls_df.shape[0]\n",
    "\n",
    "        print(\"...enumerating\", \"{:,}\".format(n_records), \"records...\")\n",
    "\n",
    "        loop_count = 0\n",
    "        for row in nc_ls_df.itertuples(index=False):\n",
    "            nc = row.n_chars\n",
    "            ls = row.letter_selector\n",
    "            ls_id = row.letter_selector_id\n",
    "\n",
    "            if matrix_extraction_option in (0, 6):\n",
    "                nc_ls_id = row.nc_ls_id\n",
    "\n",
    "            ####\n",
    "            # MATRIX EXTRACTION OPTION 1: NO SUB-MATRICES ARE CREATED.\n",
    "            ####\n",
    "            # (Block left here for convenience)\n",
    "\n",
    "            ####\n",
    "            # MATRIX EXTRACTION OPTION 2: DICTIONARY BY NUMBER OF CHARACTERS\n",
    "            ####\n",
    "            if nc not in n_char_matrix_dict:\n",
    "                nc_wg_id_list = wg_df.loc[\n",
    "                    (wg_df[\"n_chars\"] >= nc), \"word_group_id\"\n",
    "                ].to_numpy()\n",
    "                nc_wg_id_set = set(nc_wg_id_list)\n",
    "                n_char_set_dict[nc] = nc_wg_id_set\n",
    "\n",
    "                # subset the wchar_matrix to get the sub-matrix\n",
    "                nc_sub_wchar_matrix = wchar_matrix[nc_wg_id_list,]\n",
    "\n",
    "                n_char_matrix_dict[nc] = (nc_wg_id_list, nc_sub_wchar_matrix)\n",
    "\n",
    "            else:\n",
    "                nc_wg_id_list, nc_sub_wchar_matrix = n_char_matrix_dict[nc]\n",
    "                nc_wg_id_set = n_char_set_dict[nc]\n",
    "\n",
    "            ####\n",
    "            # MATRIX EXTRACTION OPTION 3 AND 4: DICTIONARY BY SINGLE-LETTER\n",
    "            ####\n",
    "            ll = ls[0]\n",
    "            ll_id = letter_dict[ll]\n",
    "\n",
    "            # check to see if the sub-matrix with the first letter has already been created\n",
    "            if ll_id not in single_letter_matrix_dict:\n",
    "                # the submatrix has not been created, let's do it.\n",
    "                column_selector = [ll_id]\n",
    "                outcome = wchar_matrix[:, column_selector] > 0\n",
    "                \n",
    "                outcome_indices = cp.all(outcome > 0, axis=1)\n",
    "                \n",
    "                # these indices match with the word_id_list, extract the subset\n",
    "                single_letter_word_group_id_list = word_group_id_list[outcome_indices]\n",
    "\n",
    "                # the set of ids\n",
    "                single_letter_word_group_id_set = set(\n",
    "                    single_letter_word_group_id_list.tolist())\n",
    "                \n",
    "                single_letter_set_dict[ll_id] = single_letter_word_group_id_set\n",
    "\n",
    "                # subset the wchar_matrix to get the sub-matrix\n",
    "                single_letter_wchar_matrix = wchar_matrix[single_letter_word_group_id_list, ]\n",
    "\n",
    "                single_letter_matrix_dict[ll_id] = (\n",
    "                    single_letter_word_group_id_list,\n",
    "                    single_letter_wchar_matrix\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # query the sub-matrices split by individual letter to then get the smaller matrices\n",
    "                (\n",
    "                    single_letter_word_group_id_list,\n",
    "                    single_letter_wchar_matrix,\n",
    "                ) = single_letter_matrix_dict[ll_id]\n",
    "\n",
    "                single_letter_word_group_id_set = single_letter_set_dict[ll_id]\n",
    "\n",
    "            ####\n",
    "            # MATRIX EXTRACTION OPTION 5: DICTIONARY BY LETTER SELECTOR\n",
    "            ####\n",
    "            if ls_id not in letter_selector_matrix_dict:\n",
    "                # build a column selector\n",
    "                column_selector = [letter_dict[curr_letter]\n",
    "                                   for curr_letter in ls]\n",
    "\n",
    "                # get the indices of the single_letter_wchar_matrix that feature the n least common letters\n",
    "                outcome = single_letter_wchar_matrix[:, column_selector] > 0\n",
    "                outcome_indices = cp.all(outcome > 0, axis=1)\n",
    "                \n",
    "                # these are now the ids\n",
    "                ls_wg_id_list = single_letter_word_group_id_list[outcome_indices]\n",
    "\n",
    "                # the set of ids\n",
    "                ls_wg_id_set = set(ls_wg_id_list.tolist())\n",
    "                letter_selector_set_dict[ls_id] = ls_wg_id_set\n",
    "\n",
    "                # subset the wchar_matrix to get the sub-matrix - this contains the N least common letters for a group of words\n",
    "                ls_wchar_matrix = wchar_matrix[ls_wg_id_list,]\n",
    "                letter_selector_matrix_dict[ls_id] = (\n",
    "                    ls_wg_id_list,\n",
    "                    ls_wchar_matrix\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # this is the submatrix by letter selector\n",
    "                ls_wg_id_list, ls_wchar_matrix = letter_selector_matrix_dict[\n",
    "                    ls_id\n",
    "                ]\n",
    "\n",
    "                ls_wg_id_set = letter_selector_set_dict[ls_id]\n",
    "\n",
    "            ####\n",
    "            # MATRIX EXTRACTION OPTION 6: DICTIONARY BY NUMBER OF CHARACTERS AND LETTER SELECTOR\n",
    "            ####\n",
    "\n",
    "            ##\n",
    "            # We need to find the intersection of the word_group_id by number of characters\n",
    "            # and the word_group_id by letter selector. The fastest way to do that\n",
    "            # is to use the set().intersection() method. It blows other methods out of the water.\n",
    "            # But...\n",
    "\n",
    "            # THERE IS A LOT OF OVERHEAD IN THIS PART - THE set() INTERSECTION\n",
    "            # AND THEN CONVERTING THE RESULTING SET TO A NUMPY ARRAY. THIS TAKES\n",
    "            # ABOUT 33% OF THE TOTAL RUNTIME OF THIS FUNCTION\n",
    "            # LEAVING THESE SNIPPETS OF ALTERNATIVES IN FOR REFERENCE AND LEARNING\n",
    "            ##\n",
    "\n",
    "            # 2024 02 05: USE np.intersect1d(): This is very slow\n",
    "            # nc_ls_wg_id_list = np.intersect1d(ar1 = nc_wg_id_list, ar2=ls_wg_id_list, assume_unique=True)\n",
    "\n",
    "            # 2024 02 05: use a pandas join: This is very slow\n",
    "            # df_ls = pd.DataFrame(data = ls_wg_id_list, columns = ['word_group_id'])\n",
    "            # df_nc = pd.DataFrame(data = nc_wg_id_list, columns = ['word_group_id'])\n",
    "            # df_out = pd.merge(left = df_ls, right = df_nc)\n",
    "            # nc_ls_wg_id_set = None\n",
    "            # nc_ls_wg_id_list = df_out['word_group_id'].to_numpy()\n",
    "\n",
    "            # 2024 02 06: use a collections.Counter(). This is also sloooooooow!\n",
    "            # this_counter = collections.Counter(nc_wg_id_list)\n",
    "            # this_counter.update(ls_wg_id_list)\n",
    "            # this_array = np.array(list(this_counter.items()))\n",
    "            # outcome = this_array[:, 1] == 2\n",
    "            # nc_ls_wg_id_list = this_array[outcome, 0]\n",
    "            # nc_ls_wg_id_set = None\n",
    "\n",
    "            # This is the fastest implementation\n",
    "            if matrix_extraction_option in (0, 6):\n",
    "                nc_ls_wg_id_set = nc_wg_id_set.intersection(ls_wg_id_set)\n",
    "                nc_ls_wg_id_list = cp.fromiter(iter=nc_ls_wg_id_set, dtype=int)\n",
    "                \n",
    "                # now, get the rows\n",
    "                nc_ls_wchar_matrix = wchar_matrix[nc_ls_wg_id_list,]\n",
    "                nc_ls_matrix_dict[nc_ls_id] = (\n",
    "                    nc_ls_wg_id_list,\n",
    "                    nc_ls_wchar_matrix\n",
    "                )\n",
    "\n",
    "            # get the right loop count\n",
    "            loop_count += 1\n",
    "            if loop_count % 1000 == 0:\n",
    "                print(\"...{:,}\".format(loop_count), \"records enumerated...\")\n",
    "\n",
    "        # display the final count\n",
    "        if matrix_extraction_option == 2:\n",
    "            n_sub_matrices = len(n_char_matrix_dict)\n",
    "\n",
    "        if matrix_extraction_option in (3, 4):\n",
    "            n_sub_matrices = len(single_letter_matrix_dict)\n",
    "\n",
    "        if matrix_extraction_option == 5:\n",
    "            n_sub_matrices = len(letter_selector_matrix_dict)\n",
    "\n",
    "        if matrix_extraction_option in (0, 6):\n",
    "            n_sub_matrices = len(nc_ls_matrix_dict)\n",
    "    else:\n",
    "        n_sub_matrices = 0\n",
    "\n",
    "    print(\"...{:,}\".format(n_sub_matrices), \"sub-matrices created...\")\n",
    "    p_time = calc_time(time_start=s_time)\n",
    "    print(\"Total extraction time:\", p_time, \"seconds.\")\n",
    "\n",
    "    # set things to None so that we can free up memory and reduce overhead\n",
    "    # these objects are no longer needed\n",
    "    # only return objects specific to the particular matrix extraction option\n",
    "    if matrix_extraction_option not in (0, 2):\n",
    "        # option 2\n",
    "        n_char_matrix_dict = None\n",
    "\n",
    "    if matrix_extraction_option not in (0, 3, 4):\n",
    "        # option 3 and 4\n",
    "        single_letter_matrix_dict = None\n",
    "\n",
    "    if matrix_extraction_option not in (0, 5):\n",
    "        # option 5\n",
    "        letter_selector_matrix_dict = None\n",
    "\n",
    "    if matrix_extraction_option not in (0, 6):\n",
    "        # option 6\n",
    "        nc_ls_matrix_dict = None\n",
    "\n",
    "    return (\n",
    "        wg_df,\n",
    "        n_char_matrix_dict,\n",
    "        single_letter_matrix_dict,\n",
    "        letter_selector_matrix_dict,\n",
    "        nc_ls_matrix_dict,\n",
    "        p_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545edc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_group_id_list = cp.asarray(word_group_id_list)\n",
    "wchar_matrix = cp.asarray(a = wchar_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96823550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the matrix\n",
    "n_subset_letters = 3\n",
    "matrix_extraction_option = 5\n",
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict, p_time = split_matrix_cp(\n",
    "    letter_dict=letter_dict,\n",
    "    word_group_id_list=word_group_id_list,\n",
    "    wg_df=wg_df,\n",
    "    wchar_matrix=wchar_matrix_cp,\n",
    "    n_subset_letters=n_subset_letters,\n",
    "    matrix_extraction_option=matrix_extraction_option\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wchar_matrix_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output_list_cp(outcome_word_id_list: cp.ndarray, wg_id: int) -> cp.ndarray:\n",
    "        \n",
    "    output_list = cp.zeros(shape=(outcome_word_id_list.shape[0], 2), dtype=int)\n",
    "\n",
    "    # update the output list with the word_id_list - these are from/parent words\n",
    "    output_list[:, 0] = outcome_word_id_list\n",
    "\n",
    "    # update with the word_id - this is the to/child word\n",
    "    output_list[:, 1] = wg_id\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def get_values_full_matrix_cp(\n",
    "    wg_id: int, wchar_matrix: cp.ndarray, word_group_id_list: cp.ndarray\n",
    "):\n",
    "        \n",
    "\n",
    "    # matrix extraction option 1\n",
    "    outcome = wchar_matrix - wchar_matrix[wg_id,]\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = word_group_id_list[outcome_indices]\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "\n",
    "def get_values_n_char_cp(wg_id: int, n_char: int, n_char_matrix_dict: dict):\n",
    "\n",
    "\n",
    "\n",
    "    # matrix extraction option 2\n",
    "    nc_wg_id_list, nc_sub_wchar_matrix = n_char_matrix_dict[n_char]\n",
    "    new_word_id = nc_wg_id_list == wg_id\n",
    "\n",
    "    # perform the comparison\n",
    "    outcome = nc_sub_wchar_matrix - nc_sub_wchar_matrix[new_word_id,]\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = nc_wg_id_list[outcome_indices]\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def get_values_single_letter_cp(\n",
    "    wg_id: int, single_letter_id: str, single_letter_matrix_dict: dict\n",
    "):\n",
    "    \n",
    "\n",
    "    # matrix extraction option 3 and 4\n",
    "    (\n",
    "        single_letter_word_group_id_list,\n",
    "        single_letter_wchar_matrix\n",
    "    ) = single_letter_matrix_dict[single_letter_id]\n",
    "\n",
    "    new_word_id = single_letter_word_group_id_list == wg_id\n",
    "\n",
    "    # now, peform the comparison\n",
    "    outcome = single_letter_wchar_matrix - \\\n",
    "        single_letter_wchar_matrix[new_word_id,]\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = single_letter_word_group_id_list[outcome_indices]\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def get_values_letter_selector_cp(\n",
    "    wg_id: int, letter_selector_id: str, letter_selector_matrix_dict: dict\n",
    "):\n",
    "    \n",
    "    # matrix extraction option 5\n",
    "    ls_wg_id_list, ls_wchar_matrix = letter_selector_matrix_dict[\n",
    "        letter_selector_id\n",
    "    ]\n",
    "\n",
    "    new_word_id = ls_wg_id_list == wg_id\n",
    "    print(type(new_word_id))\n",
    "\n",
    "    # now, perform the comparison\n",
    "    outcome = ls_wchar_matrix - ls_wchar_matrix[new_word_id,]\n",
    "    print(type(outcome))\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    print(type(outcome_indices))\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = ls_wg_id_list[outcome_indices]\n",
    "    print(type(outcome_word_id_list))\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "    print(type(output_list))\n",
    "\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def get_values_n_char_letter_selector_cp(\n",
    "    wg_id: int, nc_ls_id: tuple, nc_ls_matrix_dict: dict\n",
    "):   \n",
    "\n",
    "    # matrix extraction option 6\n",
    "    nc_ls_wg_id_list, nc_ls_wchar_matrix = nc_ls_matrix_dict[nc_ls_id]\n",
    "\n",
    "    new_word_id = nc_ls_wg_id_list == wg_id\n",
    "\n",
    "    # now, perform the comparison\n",
    "    outcome = nc_ls_wchar_matrix - nc_ls_wchar_matrix[new_word_id,]\n",
    "\n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    outcome_word_id_list = nc_ls_wg_id_list[outcome_indices]\n",
    "\n",
    "    output_list = format_output_list_cp(\n",
    "        outcome_word_id_list=outcome_word_id_list, wg_id=wg_id\n",
    "    )\n",
    "\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b78248",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# generate_from_to_word_group_pairs placeholder\n",
    "####\n",
    "def generate_from_to_word_group_pairs_simple_cp(\n",
    "    wg_df: pd.DataFrame,\n",
    "    n_possible_anagrams: int,\n",
    "    matrix_extraction_option: int,\n",
    "    wchar_matrix: cp.ndarray,\n",
    "    word_group_id_list: cp.ndarray,\n",
    "    n_char_matrix_dict: dict,\n",
    "    single_letter_matrix_dict: dict,\n",
    "    letter_selector_matrix_dict: dict,\n",
    "    nc_ls_matrix_dict: dict,\n",
    "    letter_subset_list: str = None\n",
    "):\n",
    "\n",
    "    # use numpy to pre-allocate an array that will be updated while enumerating.\n",
    "    # this eliminates list.append() calls which are fine in small amounts, but\n",
    "    # hundreds of thousands of append calls are very slow.      \n",
    "\n",
    "    output_list = cp.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "    # this dictionary will store the calculations for each word\n",
    "    proc_time_dict = {}\n",
    "\n",
    "    if letter_subset_list == 'SAMPLE':\n",
    "        # generate 100 samples within each n_chars and first_letter group combination\n",
    "        curr_wg_df = wg_df.groupby(['n_chars', 'first_letter']).sample(\n",
    "            n=100, replace=True, random_state=123).drop_duplicates()\n",
    "    elif isinstance(letter_subset_list, str) or isinstance(letter_subset_list, list):\n",
    "        # subset by a specific set of letters or a single letter\n",
    "        curr_wg_df = wg_df.loc[wg_df['first_letter'].isin(\n",
    "            set(letter_subset_list)), :].copy()\n",
    "    else:\n",
    "        curr_wg_df = wg_df.copy()\n",
    "\n",
    "    # display counts\n",
    "    curr_word_count = curr_wg_df.shape[0]\n",
    "\n",
    "    n_curr_words = \"{:,}\".format(curr_word_count)\n",
    "    print(\n",
    "        \"...finding parent anagrams for\",\n",
    "        n_curr_words,\n",
    "        \"words...\"\n",
    "    )\n",
    "\n",
    "    # establish counters for record keeping\n",
    "    row_count = 0\n",
    "    anagram_pair_count = 0\n",
    "    intmerdiate_to_word_count = collections.Counter()\n",
    "    # enumerate by word id, working with integers is faster than words\n",
    "    temp_curr_wg_df = curr_wg_df.iloc[0:10]\n",
    "    for row in temp_curr_wg_df.itertuples(index=False):\n",
    "        # start timing to record processing for each word\n",
    "        s_time = perf_counter_ns()\n",
    "\n",
    "        # word group id\n",
    "        wg_id = row.word_group_id\n",
    "\n",
    "        if matrix_extraction_option == 1:\n",
    "            # option 1: full matrix\n",
    "            outcome_word_id_list = get_values_full_matrix_cp(\n",
    "                wg_id=wg_id,\n",
    "                wchar_matrix=wchar_matrix,\n",
    "                word_group_id_list=word_group_id_list,\n",
    "            )\n",
    "        elif matrix_extraction_option == 2:\n",
    "            # option 2: word length\n",
    "            outcome_word_id_list = get_values_n_char_cp(\n",
    "                wg_id=wg_id,\n",
    "                n_char=row.n_chars,\n",
    "                n_char_matrix_dict=n_char_matrix_dict,\n",
    "            )\n",
    "        elif matrix_extraction_option == 3:\n",
    "            # option 3: first character\n",
    "            outcome_word_id_list = get_values_single_letter_cp(\n",
    "                wg_id=wg_id,\n",
    "                single_letter_id=row.first_letter_id,\n",
    "                single_letter_matrix_dict=single_letter_matrix_dict,\n",
    "            )\n",
    "        elif matrix_extraction_option == 4:\n",
    "            # option 4: single least common letter\n",
    "            outcome_word_id_list = get_values_single_letter_cp(\n",
    "                wg_id=wg_id,\n",
    "                single_letter_id=row.single_letter_id,\n",
    "                single_letter_matrix_dict=single_letter_matrix_dict,\n",
    "            )\n",
    "        elif matrix_extraction_option == 5:\n",
    "            # option 5: letter selector / focal letter\n",
    "            outcome_word_id_list = get_values_letter_selector_cp(\n",
    "                wg_id=wg_id,\n",
    "                letter_selector_id=row.letter_selector_id,\n",
    "                letter_selector_matrix_dict=letter_selector_matrix_dict,\n",
    "            )\n",
    "        else:\n",
    "            # option 6: word length and letter selector\n",
    "            outcome_word_id_list = get_values_n_char_letter_selector_cp(\n",
    "                wg_id=wg_id,\n",
    "                nc_ls_id=row.nc_ls_id,\n",
    "                nc_ls_matrix_dict=nc_ls_matrix_dict,\n",
    "            )\n",
    "\n",
    "        # if the outcome is greater than or equal to zero, then the current word is an\n",
    "        # anagram of the other word\n",
    "        # a value  >= 0 means that the current word contains the exact same number of focal letters\n",
    "        # mite --> time or miter --> time\n",
    "        # a value >= 1 means that current word contains at least the same number of focal letters\n",
    "        # terminator --> time\n",
    "        # a value of <= -1 means that the current word does not have the\n",
    "        # correct number of letters and is therefore not an anagram.\n",
    "        # trait <> time\n",
    "\n",
    "        # number of parent words found\n",
    "        n_from_words = outcome_word_id_list.shape[0]\n",
    "\n",
    "        if n_from_words >= 1:\n",
    "            # we have matches\n",
    "            # the focal word\n",
    "\n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count,\n",
    "                        :] = outcome_word_id_list\n",
    "\n",
    "            # n_to_word_counter = collections.Counter(output_list[:, 0])            \n",
    "            intmerdiate_to_word_count.update(outcome_word_id_list[:, 0].tolist())\n",
    "\n",
    "            # set the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "\n",
    "        # delete the intermediate list\n",
    "        del outcome_word_id_list\n",
    "\n",
    "        # record the time for the word\n",
    "        p_time = calc_time(time_start=s_time, round_digits=-1)\n",
    "\n",
    "        proc_time_dict[wg_id] = (p_time, n_from_words)\n",
    "\n",
    "        row_count += 1\n",
    "        if row_count % 1e4 == 0:\n",
    "            print('...found parent anagrams for',\n",
    "                  \"{:,}\".format(row_count), 'words...')\n",
    "\n",
    "    # last update\n",
    "    print('...found parent anagrams for', \"{:,}\".format(row_count), 'words...')\n",
    "    # create a dataframe from the proc_time_dict\n",
    "    proc_time_df = pd.DataFrame.from_dict(data=proc_time_dict, orient=\"index\")\n",
    "    proc_time_df = proc_time_df.reset_index()\n",
    "    proc_time_df.columns = [\"word_group_id\", \"n_seconds\", \"n_from_word_groups\"]\n",
    "\n",
    "    # display processing time for the current letter\n",
    "    total_proc_time_s = round(proc_time_df[\"n_seconds\"].sum(), 2)\n",
    "    total_proc_time_m = round(proc_time_df[\"n_seconds\"].sum() / 60, 2)\n",
    "    print(\n",
    "        \"...finding parent anagrams for\",\n",
    "        n_curr_words,\n",
    "        \"words took\",\n",
    "        total_proc_time_s,\n",
    "        \"seconds |\",\n",
    "        total_proc_time_m,\n",
    "        \"minutes...\"\n",
    "    )\n",
    "\n",
    "    # truncate the output array to only include rows with a from/to word pair\n",
    "    # this removes any row that has a value of -1\n",
    "    print('...truncating output list...')\n",
    "    output_indices = cp.all(output_list >= 0, axis=1)\n",
    "    output_list = output_list[output_indices,]\n",
    "    del output_indices\n",
    "\n",
    "    # initialize Counters to hold the count of found pairs for a given word\n",
    "    # for the count of to/child words, we need to count the number of times\n",
    "    # each word_group_id\n",
    "    # exists in the from/parent column\n",
    "    # count the number of to words\n",
    "    # seems little counter-intuitive... but we're counting the number of\n",
    "    # to-words from each from-word. So, this is the number of child words\n",
    "    # from each parent word.\n",
    "    # https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "\n",
    "    # we do not need the count of from-word, but leaving in for convenience\n",
    "    # print(\"...populating the count of from-words...\")\n",
    "    # n_from_word_counter = collections.Counter(output_list[:, 1])\n",
    "\n",
    "    print(\"...populating the count of to-words...\")\n",
    "    # big_count_start_time = perf_counter_ns()\n",
    "    # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "    # print(calc_time(time_start = big_count_start_time))\n",
    "    # outcome_test = intmerdiate_to_word_count == n_to_word_counter\n",
    "    # print(outcome_test)\n",
    "\n",
    "    # now, use the map function to get the number of from/to words and the number of\n",
    "    # candidate words for each word\n",
    "    proc_time_df[\"n_to_word_groups\"] = proc_time_df[\"word_group_id\"].map(\n",
    "        intmerdiate_to_word_count\n",
    "    )\n",
    "\n",
    "    # record the matrix extraction option\n",
    "    proc_time_df['matrix_extraction_option'] = matrix_extraction_option\n",
    "\n",
    "    # how many anagram pairs were found?\n",
    "    n_total_anagrams = output_list.shape[0]\n",
    "    n_total_anagrams_formatted = \"{:,}\".format(n_total_anagrams)\n",
    "    print(\"...total anagram pairs:\", n_total_anagrams_formatted)\n",
    "\n",
    "    return proc_time_df, output_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover from/to word group id pairs\n",
    "letter_subset_list = None\n",
    "matrix_extraction_option = 5\n",
    "proc_time_df, output_list = \\\n",
    "    generate_from_to_word_group_pairs_simple_cp(wg_df=wg_df,\n",
    "                                                n_possible_anagrams=n_possible_anagrams,\n",
    "                                                matrix_extraction_option=matrix_extraction_option,\n",
    "                                                wchar_matrix=wchar_matrix,\n",
    "                                                word_group_id_list=word_group_id_list,\n",
    "                                                n_char_matrix_dict=n_char_matrix_dict,\n",
    "                                                single_letter_matrix_dict=single_letter_matrix_dict,\n",
    "                                                letter_selector_matrix_dict=letter_selector_matrix_dict,\n",
    "                                                nc_ls_matrix_dict=nc_ls_matrix_dict,\n",
    "                                                letter_subset_list=letter_subset_list,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the matrix\n",
    "n_subset_letters = 3\n",
    "matrix_extraction_option = 5\n",
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict, p_time = split_matrix(\n",
    "    letter_dict=letter_dict,\n",
    "    word_group_id_list=cp.asnumpy(word_group_id_list),\n",
    "    wg_df=wg_df,\n",
    "    wchar_matrix=cp.asnumpy(wchar_matrix),\n",
    "    n_subset_letters=n_subset_letters,\n",
    "    matrix_extraction_option=matrix_extraction_option\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover from/to word group id pairs\n",
    "letter_subset_list = None\n",
    "matrix_extraction_option = 5\n",
    "proc_time_df, output_list = \\\n",
    "    generate_from_to_word_group_pairs_simple(wg_df=wg_df,\n",
    "                                                n_possible_anagrams=n_possible_anagrams,\n",
    "                                                matrix_extraction_option=matrix_extraction_option,\n",
    "                                                wchar_matrix=cp.asnumpy(wchar_matrix),\n",
    "                                                word_group_id_list=cp.asnumpy(word_group_id_list),\n",
    "                                                n_char_matrix_dict=n_char_matrix_dict,\n",
    "                                                single_letter_matrix_dict=single_letter_matrix_dict,\n",
    "                                                letter_selector_matrix_dict=letter_selector_matrix_dict,\n",
    "                                                nc_ls_matrix_dict=nc_ls_matrix_dict,\n",
    "                                                letter_subset_list=letter_subset_list,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac17b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example array\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "# Subtract each row from every other row\n",
    "result = arr[:, np.newaxis, :] - arr[np.newaxis, :, :]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d020cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = wchar_matrix[:, cp.newaxis, :] - wchar_matrix[cp.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e592fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
