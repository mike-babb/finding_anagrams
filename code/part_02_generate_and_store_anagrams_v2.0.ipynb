{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 4\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "# set to None to include all letters\n",
    "# test with a subset of letters by setting the letter_subset_list to ['q', 'x'] or \n",
    "# a different set of letters\n",
    "letter_subset_list = ['x']\n",
    "#letter_subset_list = None\n",
    "\n",
    "# generate a sample dataset of ten words that start with each letter\n",
    "\n",
    "# testo = wg_df.groupby(['first_letter']).sample(n = 10, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...query execution took: 1.770999 seconds...\n"
     ]
    }
   ],
   "source": [
    "# load the word_df, the words from Part 1\n",
    "sql = 'select * from words;'\n",
    "word_df = query_db(sql = sql, db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234370, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the column of word ids as a numpy array\n",
    "word_id_list = word_df['word_id'].to_numpy(dtype = int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the letters sorted by the frequency of words that\n",
    "# start with a particular letter\n",
    "agg_word_df = word_df['first_letter'].groupby(word_df['first_letter']).agg(np.size).to_frame()\n",
    "\n",
    "# set column names\n",
    "agg_word_df.columns = ['word_count']\n",
    "\n",
    "# reset the index to rename columns\n",
    "agg_word_df = agg_word_df.reset_index()\n",
    "\n",
    "# sort the dataframe by frequency\n",
    "agg_word_df = agg_word_df.sort_values(by='word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the letters sorted by word frequency\n",
    "sorted_first_letters = agg_word_df['first_letter'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the letter dictionary from part 1\n",
    "in_file_name = 'letter_dict.pkl'\n",
    "letter_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the word dictionary from part 1\n",
    "in_file_name = 'word_dict.pkl'\n",
    "word_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the char matrix from part 1\n",
    "in_file_name = 'char_matrix.npy'\n",
    "ipn = os.path.join(in_file_path, in_file_name)\n",
    "char_matrix = np.load(file = ipn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the word group df: wg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop duplicates based on the word group. \n",
    "# by default, this will only keep the first record and it will drop all others\n",
    "wg_df = word_df.drop_duplicates(subset = ['word_group_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wg_df = wg_df.sort_values(by = 'word_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215842, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique word groups\n",
    "wg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the word group ids\n",
    "word_group_id_list = wg_df['word_group_id'].to_numpy()\n",
    "# and the associated word_id\n",
    "word_id_list = wg_df['word_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trim the char matrix by word id\n",
    "# and not the word_group id\n",
    "wchar_matrix = char_matrix[word_id_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i don't use these objects, but i can't delete them?\n",
    "# build a word_id to word_group_id dictionary\n",
    "word_id_wg_id_dict = dict()\n",
    "# and a word_group_id to word_id dictionary\n",
    "wg_id_word_id_dict = dict()\n",
    "\n",
    "for word_id, wg_id in zip(wg_df['word_id'], wg_df['word_group_id']):\n",
    "    word_id_wg_id_dict[word_id] = wg_id\n",
    "    wg_id_word_id_dict[wg_id] = word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['letter_selector'] = wg_df['letter_group_ranked'].str[:n_subset_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...creating 16101 sets of ids\n"
     ]
    }
   ],
   "source": [
    "# there will be three parts to this function\n",
    "# The first part does a selection by a single character\n",
    "# The second part does the selection based on the newly created subselection\n",
    "\n",
    "# peforming selections on a dataframe is slow.\n",
    "# Especially so since we are comparing characters\n",
    "    \n",
    "# now, do it again, but this time use the dictionary\n",
    "# by word length and n least common letters\n",
    "wg_df['letter_selector'] = wg_df['letter_group_ranked'].str[:n_subset_letters]\n",
    "nc_ls_df = wg_df[['n_chars', 'letter_selector']].drop_duplicates()\n",
    "\n",
    "print('...creating', nc_ls_df.shape[0], 'sets of ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "Total extraction time: 68.083913\n",
      "...now writing: word_count_by_n_char\n",
      "...now writing: word_count_by_single_letter\n",
      "...now writing: word_count_by_letter_selector\n",
      "...now writing: word_count_by_n_char_and_letter_selector\n"
     ]
    }
   ],
   "source": [
    "n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict, split_count_df, single_letter_df = split_matrix(\n",
    "    letter_dict = letter_dict,\n",
    "    word_group_id_list = word_group_id_list,\n",
    "    nc_ls_df = nc_ls_df,\n",
    "                 wg_df = wg_df,\n",
    "                 wchar_matrix = wchar_matrix,\n",
    "db_path = db_path, \n",
    "db_name = db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df = pd.merge(left = wg_df, right = single_letter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join this back to the wg_df\n",
    "wg_df = pd.merge(left = wg_df, right = split_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# demonstrate the different matrix extraction options with the word 'achiever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_word = 'achiever'\n",
    "\n",
    "wg_id = word_df.loc[word_df['lcase'] == demo_word, 'word_group_id'].iloc[0]\n",
    "\n",
    "demo_wg_df = wg_df.loc[wg_df['word_group_id'] == wg_id, : ]\n",
    "\n",
    "# option 2\n",
    "n_char = demo_wg_df['n_chars'].iloc[0]\n",
    "\n",
    "# option 3\n",
    "first_letter = demo_wg_df['first_letter'].iloc[0]\n",
    "\n",
    "# option 4\n",
    "least_common_letter = demo_wg_df['letter_selector'].iloc[0][0]\n",
    "\n",
    "# option 5\n",
    "letter_selector = demo_wg_df['letter_selector'].iloc[0]\n",
    "\n",
    "# option 6\n",
    "nc_ls_tuple = demo_wg_df['nc_ls_tuple'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 full matrix: complete | get_values_full_matrix\n",
    "# 2 n char (word length): complete | get_values_n_char\n",
    "# 3 first letter: complete | get_value_first_letter\n",
    "# 3 focal letter: complete | get_values_letter_selector\n",
    "# 4 n char and least common letters: complete | get_values_n_char_letter_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the full matrix: option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the full matrix selection\n",
    "output = get_values_full_matrix(wg_id = wg_id, \n",
    "                    wchar_matrix = wchar_matrix,\n",
    "                   word_group_id_list = word_group_id_list)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by word-length: option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the n char selection\n",
    "output = get_values_n_char(wg_id = wg_id,\n",
    "                      n_char = n_char,\n",
    "                      n_char_matrix_dict = n_char_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the first letter: option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the single least common letter: option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the letter selector: option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo with the letter selector\n",
    "output = get_values_letter_selector(wg_id = wg_id,\n",
    "                      letter_selector = letter_selector,\n",
    "                      letter_selector_matrix_dict = letter_selector_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by word-length and the letter selector: option 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo with the n_char letter selector\n",
    "output = get_values_n_char_letter_selector(wg_id = wg_id,\n",
    "                           nc_ls_tuple = nc_ls_tuple,                           \n",
    "                           nc_ls_matrix_dict=nc_ls_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by full matrix\n",
      "Total time: 0.3227 seconds. Average time: 0.032275 seconds.\n",
      "Selecting by word length\n",
      "Total time: 0.2711 seconds. Average time: 0.02711 seconds.\n",
      "Selecting by first letter\n",
      "Total time: 0.4186 seconds. Average time: 0.04186 seconds.\n",
      "Selecting by single least common letter\n",
      "Total time: 0.0712 seconds. Average time: 0.007123 seconds.\n",
      "Selecting by letter selector\n",
      "Total time: 0.0012 seconds. Average time: 0.000123 seconds.\n",
      "Selecting by word length and letter selector\n",
      "Total time: 0.0012 seconds. Average time: 0.000117 seconds.\n"
     ]
    }
   ],
   "source": [
    "# we've tested with one word, let's time many evaluations to get a sense of how quickly \n",
    "# the different matrix extraction options work\n",
    "# use the timeit() function to evaluate how long, on average, a single matrix operation\n",
    "# takes to complete\n",
    "\n",
    "n_trials = 10\n",
    "\n",
    "code_snippet_dict = {\n",
    "    'Selecting by full matrix':\n",
    "\"\"\"get_values_full_matrix(wg_id = wg_id, wchar_matrix = wchar_matrix, word_group_id_list = word_group_id_list)\"\"\",\n",
    "    'Selecting by word length':\n",
    "\"\"\"get_values_n_char(wg_id = wg_id, n_char = n_char, n_char_matrix_dict = n_char_matrix_dict)\"\"\",\n",
    "    'Selecting by first letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter = first_letter, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",    \n",
    "    'Selecting by single least common letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",\n",
    "    'Selecting by letter selector':\n",
    "\"\"\"get_values_letter_selector(wg_id = wg_id, letter_selector = letter_selector, letter_selector_matrix_dict = letter_selector_matrix_dict)\"\"\",\n",
    "    'Selecting by word length and letter selector':\n",
    "\"\"\"get_values_n_char_letter_selector(wg_id = wg_id, nc_ls_tuple = nc_ls_tuple, nc_ls_matrix_dict=nc_ls_matrix_dict)\"\"\"\n",
    "}\n",
    "\n",
    "for csd, cs in code_snippet_dict.items():\n",
    "    \n",
    "    total_time = timeit.timeit(cs, number=n_trials, globals=globals())\n",
    "\n",
    "    # total time    \n",
    "    total_time_formatted = '{:,}'.format(round(total_time, 4))    \n",
    "\n",
    "    # average time\n",
    "    avg_time = total_time / n_trials\n",
    "    avg_time_formatted = '{:,}'.format(round(avg_time, 6)) \n",
    "        \n",
    "    print(csd)\n",
    "    # average number of seconds per trial\n",
    "    print('Total time:', total_time_formatted, 'seconds. Average time:', avg_time_formatted, 'seconds.')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combination of the word length and letter selector is the fastest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# estimate_total_pairs estimates the total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...estimated number of from/to pair word pairs: 196,320,089\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = estimate_total_pairs(word_df = word_df, wg_df = wg_df,\n",
    "                         nc_ls_matrix_dict = nc_ls_matrix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 364 words that start with x\n",
      "...finding parent anagrams for x words took 0.33 seconds...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize counters to count the number of to (child words) from a focal word.\n",
    "# we could do this in post-processing, but the data are already in memory and it's a simple\n",
    "# calculation to make.\n",
    "# we want to minimize the number of trips through our data.\n",
    "\n",
    "# the number of candidate words examined for each focal word\n",
    "\n",
    "# a list to hold the dataframes generated for each letter\n",
    "proc_time_df_list = []\n",
    "\n",
    "# subset the list of leters\n",
    "if letter_subset_list:\n",
    "    letters = letter_subset_list[:]\n",
    "else:\n",
    "    letters = sorted_first_letters\n",
    "\n",
    "anagram_pair_count = 0\n",
    "# use numpy to pre-allocate an array that will be updated while enumerating.\n",
    "# this eliminates list.append() calls\n",
    "\n",
    "output_list = np.full(shape=(n_possible_anagrams, 2), fill_value=-1, dtype=int)\n",
    "\n",
    "wg_count = 0\n",
    "\n",
    "for curr_letter in letters:\n",
    "    # enumerate by each letter\n",
    "    # this isn't absolutely necessary, we could just enumerate by word id,\n",
    "    # but for testing and development, letters are a handy way to chunk up the data.\n",
    "\n",
    "    # this dictionary will store the calculations for each letter\n",
    "    proc_time_dict = {}\n",
    "\n",
    "    # the list of words that start with the focal letter\n",
    "    curr_wg_df = wg_df.loc[wg_df[\"first_letter\"] == curr_letter, :]\n",
    "\n",
    "    # sort the dataframe by n_chars and letter_selector, if it exists.\n",
    "    # this will cut down on dictionary lookups for matrix_extraction_types 3 and 4.\n",
    "    curr_wg_df = curr_wg_df.sort_values(by=[\"n_chars\", \"letter_selector\"])\n",
    "    curr_word_group_id_list = curr_wg_df[\"word_group_id\"].to_numpy()\n",
    "    curr_nc_ls_tuple_list = curr_wg_df[\"nc_ls_tuple\"].to_numpy()\n",
    "\n",
    "    wg_count += len(curr_word_group_id_list)\n",
    "\n",
    "    n_curr_words = \"{:,}\".format(curr_wg_df.shape[0])\n",
    "    print(\n",
    "        \"...finding parent anagrams for\",\n",
    "        n_curr_words,\n",
    "        \"words that start with\",\n",
    "        curr_letter,\n",
    "    )\n",
    "\n",
    "    # enumerate by word id, working with integers is faster than words\n",
    "    for row in curr_wg_df.itertuples(index = False):\n",
    "        wg_id = row.word_group_id\n",
    "            \n",
    "        # start timing to record processing for each word\n",
    "        s_time = datetime.datetime.now()\n",
    "\n",
    "        # get the current word length, from the word id\n",
    "        # to_word, to_word_length, curr_first_letter, clg, clgr = word_dict[word_group_id]\n",
    "        to_word_length = word_dict[wg_id][1]\n",
    "\n",
    "        # get the tuple associated with the word id\n",
    "        # much faster to look up stored values for the hash value than it is to\n",
    "        # only look up if the hash value has changed\n",
    "\n",
    "        # get the possible candidate word_group_ids and char matrix\n",
    "        ####\n",
    "        ## TODO: CODE OPTIONS 1 THROUGH 4. OR 5?\n",
    "        ####\n",
    "        if matrix_extraction_option == 1:\n",
    "            # option 1: full matrix        \n",
    "            outcome_word_id_list = get_values_full_matrix(wg_id = wg_id, wchar_matrix = wchar_matrix, word_group_id_list = word_group_id_list)\n",
    "        elif matrix_extraction_option == 2:\n",
    "            # option 2: word length\n",
    "            outcome_word_id_list = get_values_n_char(wg_id = wg_id, n_char = row.n_chars, n_char_matrix_dict = n_char_matrix_dict)\n",
    "        elif matrix_extraction_option == 3:            \n",
    "            # option 3: first character\n",
    "            outcome_word_id_list = get_values_single_letter(wg_id = wg_id, single_letter = row.first_letter,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)\n",
    "        elif matrix_extraction_option == 4:\n",
    "            # option 4: single least common letter\n",
    "            outcome_word_id_list = get_values_single_letter(wg_id = wg_id, single_letter = row.letter_selector[0],\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)\n",
    "        elif matrix_extraction_option == 5:\n",
    "            # option 5: letter selector / focal letter\n",
    "            outcome_word_id_list = get_values_letter_selector(wg_id = wg_id, letter_selector = row.letter_selector, letter_selector_matrix_dict = letter_selector_matrix_dict)                            \n",
    "        else:     \n",
    "            # option 6: word length and letter selector\n",
    "            outcome_word_id_list = get_values_n_char_letter_selector(\n",
    "                wg_id=wg_id, nc_ls_tuple=row.nc_ls_tuple, nc_ls_matrix_dict=nc_ls_matrix_dict\n",
    "            )\n",
    "        \n",
    "        # if the outcome is greater than or equal to zero, then the current word is an\n",
    "        # anagram of the other word\n",
    "        # a value  >= 0 means that the current word contains the exact same number of focal letters\n",
    "        # mite --> time or miter --> time\n",
    "        # a value >= 1 means that current word contains at least the same number of focal letters\n",
    "        # terminator --> time\n",
    "        # a value of <=-1 means that the current word does not have the\n",
    "        # correct number of letters and is therefore not an anagram.\n",
    "        # trait <> time\n",
    "\n",
    "        # number of parent words found\n",
    "        n_from_words = outcome_word_id_list.shape[0]\n",
    "\n",
    "        if n_from_words > 1:\n",
    "            # we have matches\n",
    "            # the focal word\n",
    "\n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "            # the from words\n",
    "            # print(anagram_pair_count)\n",
    "            # print(new_anagram_pair_count)\n",
    "            # print(len(outcome_word_id_list))\n",
    "            # print(output_list.shape)\n",
    "            output_list[\n",
    "                anagram_pair_count:new_anagram_pair_count, 0\n",
    "            ] = outcome_word_id_list[:, 0]\n",
    "\n",
    "            # the to word\n",
    "            output_list[\n",
    "                anagram_pair_count:new_anagram_pair_count, 1\n",
    "            ] = outcome_word_id_list[:, 1]\n",
    "\n",
    "            # set the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "\n",
    "        del outcome_word_id_list\n",
    "\n",
    "        # record the time for the word\n",
    "        e_time = datetime.datetime.now()\n",
    "        p_time = e_time - s_time\n",
    "        p_time = round(p_time.total_seconds(), 8)        \n",
    "\n",
    "        proc_time_dict[wg_id] = (p_time, n_from_words)\n",
    "\n",
    "    # create a dataframe from the proc_time_dict\n",
    "    proc_time_df = pd.DataFrame.from_dict(data=proc_time_dict, orient=\"index\")\n",
    "    proc_time_df = proc_time_df.reset_index()\n",
    "    proc_time_df.columns = [\n",
    "        \"word_group_id\",\n",
    "        \"n_seconds\",\n",
    "        \"n_from_word_groups\"        \n",
    "    ]\n",
    "\n",
    "    # display processing time for the current letter\n",
    "    total_proc_time = round(proc_time_df[\"n_seconds\"].sum(), 2)\n",
    "    print(\n",
    "        \"...finding parent anagrams for\",\n",
    "        curr_letter,\n",
    "        \"words took\",\n",
    "        total_proc_time,\n",
    "        \"seconds...\",\n",
    "    )\n",
    "\n",
    "    proc_time_df_list.append(proc_time_df)\n",
    "\n",
    "# let's do some stuff that counts the words\n",
    "proc_time_df = pd.concat(objs = proc_time_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape and store output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# truncate the output array to only include indices with a from/to word pair\n",
    "output_indices = np.all(output_list >= 0, axis = 1)\n",
    "output_list = output_list[output_indices, ]\n",
    "del output_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...total anagrams 26,489\n"
     ]
    }
   ],
   "source": [
    "# how many anagram pairs were found?\n",
    "n_total_anagrams = len(output_list)\n",
    "n_total_anagrams_formatted = '{:,}'.format(n_total_anagrams)\n",
    "print('...total anagrams', n_total_anagrams_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## count the number of to words\n",
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "# number of to words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = db_path, db_name = db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to split up the dataframes tracking the total number of options and the processing time and found words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have three dataframes: wg_df, word_df, and proc_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>first_letter_lookup</th>\n",
       "      <th>nc_ls_tuple</th>\n",
       "      <th>full_matrix_lookup</th>\n",
       "      <th>n_char_lookup</th>\n",
       "      <th>single_letter_lookup</th>\n",
       "      <th>letter_selector_lookup</th>\n",
       "      <th>nc_ls_lookup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>133001</td>\n",
       "      <td>(1, a)</td>\n",
       "      <td>215842</td>\n",
       "      <td>215842</td>\n",
       "      <td>133001</td>\n",
       "      <td>133001</td>\n",
       "      <td>133001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>133001</td>\n",
       "      <td>(2, a)</td>\n",
       "      <td>215842</td>\n",
       "      <td>215816</td>\n",
       "      <td>133001</td>\n",
       "      <td>133001</td>\n",
       "      <td>133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>la</td>\n",
       "      <td>133001</td>\n",
       "      <td>(3, la)</td>\n",
       "      <td>215842</td>\n",
       "      <td>215717</td>\n",
       "      <td>98258</td>\n",
       "      <td>65528</td>\n",
       "      <td>65527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>5394</td>\n",
       "      <td>5305</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>la</td>\n",
       "      <td>133001</td>\n",
       "      <td>(3, la)</td>\n",
       "      <td>215842</td>\n",
       "      <td>215717</td>\n",
       "      <td>98258</td>\n",
       "      <td>65528</td>\n",
       "      <td>65527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>lai</td>\n",
       "      <td>133001</td>\n",
       "      <td>(5, lai)</td>\n",
       "      <td>215842</td>\n",
       "      <td>211614</td>\n",
       "      <td>98258</td>\n",
       "      <td>42754</td>\n",
       "      <td>42731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3    all    all        3            a     5394           5305           al   \n",
       "4  aalii  aalii        5            a        3              3          ail   \n",
       "\n",
       "  letter_group_ranked letter_selector  first_letter_lookup nc_ls_tuple  \\\n",
       "0                   a               a               133001      (1, a)   \n",
       "1                   a               a               133001      (2, a)   \n",
       "2                  la              la               133001     (3, la)   \n",
       "3                  la              la               133001     (3, la)   \n",
       "4                 lai             lai               133001    (5, lai)   \n",
       "\n",
       "   full_matrix_lookup  n_char_lookup  single_letter_lookup  \\\n",
       "0              215842         215842                133001   \n",
       "1              215842         215816                133001   \n",
       "2              215842         215717                 98258   \n",
       "3              215842         215717                 98258   \n",
       "4              215842         211614                 98258   \n",
       "\n",
       "   letter_selector_lookup  nc_ls_lookup  \n",
       "0                  133001        133001  \n",
       "1                  133001        133000  \n",
       "2                   65528         65527  \n",
       "3                   65528         65527  \n",
       "4                   42754         42731  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>n_seconds</th>\n",
       "      <th>n_from_word_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214062</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>6748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214287</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214291</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_group_id  n_seconds  n_from_word_groups\n",
       "0         214062   0.005999                6748\n",
       "1         214287   0.003001                4445\n",
       "2         214335   0.000000                 327\n",
       "3         214291   0.003002                1456\n",
       "4         214293   0.000000                1099"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_anagaram_processing(\n",
    "    output_list: np.array,\n",
    "    proc_time_df: pd.DataFrame,\n",
    "    word_df: pd.DataFrame,\n",
    "    wg_df: pd.DataFrame,\n",
    "    matrix_extraction_option: int,\n",
    "    db_path: str,\n",
    "    db_name: str) -> None:        \n",
    "    \n",
    "    # remove columns that will be duplicated, this is necessary for a\n",
    "    # subsequent join to the word_df\n",
    "    drop_col_names = [\n",
    "        \"word\",\n",
    "        \"lcase\",\n",
    "        \"n_chars\",\n",
    "        \"first_letter\",\n",
    "        \"word_id\",\n",
    "        \"letter_group\",\n",
    "        \"letter_group_ranked\",\n",
    "    ]\n",
    "\n",
    "    wg_df = wg_df.drop(labels=drop_col_names, axis=1)\n",
    "\n",
    "    # indicate which words were used in the data processing\n",
    "    wg_df[\"word_processed\"] = 1\n",
    "\n",
    "    # merge the word_df and wg_df, this has the processing times and the number of candidates.\n",
    "    word_df = pd.merge(left=word_df, right=wg_df)\n",
    "\n",
    "    # convert the nc_ls_tuple column to a string\n",
    "    word_df[\"nc_ls_tuple\"] = word_df[\"nc_ls_tuple\"].map(\n",
    "        lambda x: \",\".join([str(x[0]), x[1]])\n",
    "    )\n",
    "    \n",
    "    # the count of to/child words, and in order to do that,\n",
    "    # we need to count the number of times each word_group_id\n",
    "    # exists in the from/parent column\n",
    "    to_word_counter = collections.Counter(output_list[:, 0])\n",
    "\n",
    "    # now, use the map function to get the number of from/to words and the number of\n",
    "    # candidate words for each word\n",
    "    proc_time_df[\"n_to_word_groups\"] = proc_time_df[\"word_group_id\"].map(to_word_counter)\n",
    "    \n",
    "    # select and re-order columns\n",
    "    col_names = [\n",
    "        \"word\",\n",
    "        \"lcase\",\n",
    "        \"n_chars\",\n",
    "        \"first_letter\",\n",
    "        \"word_id\",\n",
    "        \"word_group_id\",\n",
    "        \"letter_group\",\n",
    "        \"letter_group_ranked\",\n",
    "        \"letter_selector\",\n",
    "        \"nc_ls_tuple\",\n",
    "        \"full_matrix_lookup\",\n",
    "        \"n_char_lookup\",\n",
    "        \"first_letter_lookup\",\n",
    "        \"single_letter_lookup\",\n",
    "        \"letter_selector_lookup\",\n",
    "        \"nc_ls_lookup\",        \n",
    "        \"word_processed\",\n",
    "    ]\n",
    "\n",
    "    word_df = word_df[col_names]\n",
    "\n",
    "    # rename some columns to include the matrix extraction option\n",
    "    rename_col_dict = {\"full_matrix_lookup\": \"me_01_full_matrix_lookup\",\n",
    "                       \"n_char_lookup\": \"me_02_n_char_lookup\",\n",
    "                       \"first_letter_lookup\": \"me_03_first_letter_lookup\",\n",
    "                       \"single_letter_lookup\": \"me_04_single_letter_lookup\",\n",
    "                       \"letter_selector_lookup\": \"me_05_letter_selector_lookup\",\n",
    "                       \"nc_ls_lookup\": \"me_06_nc_ls_lookup\"}\n",
    "    \n",
    "    word_df = word_df.rename(columns = rename_col_dict)   \n",
    "    \n",
    "\n",
    "    # add a matrix extraction option\n",
    "    proc_time_df[\"matrix_extraction_option\"] = int(matrix_extraction_option)\n",
    "    \n",
    "\n",
    "    return proc_time_df, word_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_anagram_processing(proc_time_df: str, word_df:str, matrix_extraction_option: str, db_path: str, db_name: str) -> None:\n",
    "\n",
    "    # create database connection objects\n",
    "    db_conn = build_db_conn(db_path=db_path, db_name=db_name)\n",
    "\n",
    "    # output table name\n",
    "    table_name = f\"words_me_{str(matrix_extraction_option).zfill(2)}\"\n",
    "\n",
    "    # write the processing option table\n",
    "    proc_time_df.to_sql(name=table_name, con=db_conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # write the word df to disk\n",
    "    table_name = 'words_processed'\n",
    "    word_df.to_sql(name = table_name, con=db_conn, if_exists='replace')\n",
    "\n",
    "    # close the connection\n",
    "    db_conn.close()       \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_total_processing_time(proc_time_df:pd.DataFrame, total_time_start: datetime.datetime) -> None:\n",
    "\n",
    "\n",
    "    anagram_discovery_time = proc_time_df[\"n_seconds\"].sum()\n",
    "    anagram_discovery_time = anagram_discovery_time / 60\n",
    "    anagram_discovery_time = round(anagram_discovery_time, 2)\n",
    "\n",
    "    print(\"...anagram discovery time:\", anagram_discovery_time, \"minutes\")\n",
    "\n",
    "    # record the total time\n",
    "    total_time_end = datetime.datetime.now()\n",
    "    total_time_proc = total_time_end - total_time_start\n",
    "    total_time_proc = total_time_proc.total_seconds()\n",
    "    total_time_proc = total_time_proc / 60\n",
    "    total_time_proc = round(total_time_proc, 2)\n",
    "\n",
    "    print(\"...total processing time:\", total_time_proc, \"minutes\")\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 0.01 minutes\n",
      "...total processing time: 2.22 minutes\n"
     ]
    }
   ],
   "source": [
    "proc_time_df, word_df = store_anagaram_processing_time(output_list=output_list, proc_time_df=proc_time_df, word_df=word_df,\n",
    "                               wg_df = wg_df,\n",
    "                               matrix_extraction_option = matrix_extraction_option, db_path=db_path,\n",
    "                               db_name=db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_total_processing_time(proc_time_df = proc_time_df, total_time_start = total_time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
