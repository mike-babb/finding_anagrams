{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import load_pickle, build_db_conn\n",
    "from part_00_process_functions import estimate_total_pairs, get_values, store_anagram_pairs, store_anagaram_processing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# option 1 - work with the full char_matrix\n",
    "# option 2 - create submatrices by word length\n",
    "# option 3 - create submatrices by word length and letter\n",
    "# option 4 - create submatrices by word length and least common two letters\n",
    "\n",
    "matrix_extraction_option = 4\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# option 4. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_common_letters = 2\n",
    "\n",
    "# set write_data to true to store the generated list of anagrams\n",
    "write_data = True\n",
    "\n",
    "# set to None to include all letters\n",
    "# test with a subset of letters by setting the letter_subset_list to ['q', 'x'] or \n",
    "# a different set of letters\n",
    "letter_subset_list = ['x']\n",
    "#letter_subset_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the word_df, the words from Part 1\n",
    "input_file_name = 'word_df.csv'\n",
    "# build the file path\n",
    "ipn = os.path.join(in_file_path, input_file_name)\n",
    "\n",
    "# specify the datatypes of the columns using a dictionary\n",
    "# because NA and NULL are reserved python words, but also words in our list of words,\n",
    "# we need to specify the data types of the columns\n",
    "dtype_dict = {'word': str,\n",
    "              'lcase': str,\n",
    "              'n_chars': int,\n",
    "              'first_letter': str,\n",
    "              'word_id': int,\n",
    "              'word_group_id': int,\n",
    "              'letter_group': str,\n",
    "              'letter_group_ranked': str}\n",
    "\n",
    "# read in the file and be careful of the NA and NULL values\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "word_df = pd.read_csv(filepath_or_buffer = ipn, sep = '\\t', header = 0,\n",
    "                          dtype=dtype_dict, na_values = '!!', keep_default_na=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234365</th>\n",
       "      <td>zythem</td>\n",
       "      <td>zythem</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234365</td>\n",
       "      <td>215837</td>\n",
       "      <td>ehmtyz</td>\n",
       "      <td>zyhmte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234366</th>\n",
       "      <td>Zythia</td>\n",
       "      <td>zythia</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234366</td>\n",
       "      <td>215838</td>\n",
       "      <td>ahityz</td>\n",
       "      <td>zyhtai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234367</th>\n",
       "      <td>zythum</td>\n",
       "      <td>zythum</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234367</td>\n",
       "      <td>215839</td>\n",
       "      <td>hmtuyz</td>\n",
       "      <td>zyhmut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234368</th>\n",
       "      <td>Zyzomys</td>\n",
       "      <td>zyzomys</td>\n",
       "      <td>7</td>\n",
       "      <td>z</td>\n",
       "      <td>234368</td>\n",
       "      <td>215840</td>\n",
       "      <td>mosyz</td>\n",
       "      <td>zymso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234369</th>\n",
       "      <td>Zyzzogeton</td>\n",
       "      <td>zyzzogeton</td>\n",
       "      <td>10</td>\n",
       "      <td>z</td>\n",
       "      <td>234369</td>\n",
       "      <td>215841</td>\n",
       "      <td>egnotyz</td>\n",
       "      <td>zgytnoe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word       lcase  n_chars first_letter  word_id  word_group_id  \\\n",
       "234365      zythem      zythem        6            z   234365         215837   \n",
       "234366      Zythia      zythia        6            z   234366         215838   \n",
       "234367      zythum      zythum        6            z   234367         215839   \n",
       "234368     Zyzomys     zyzomys        7            z   234368         215840   \n",
       "234369  Zyzzogeton  zyzzogeton       10            z   234369         215841   \n",
       "\n",
       "       letter_group letter_group_ranked  \n",
       "234365       ehmtyz              zyhmte  \n",
       "234366       ahityz              zyhtai  \n",
       "234367       hmtuyz              zyhmut  \n",
       "234368        mosyz               zymso  \n",
       "234369      egnotyz             zgytnoe  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the column of word ids as a numpy array\n",
    "word_id_list = word_df['word_id'].to_numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the letters sorted by the frequency of words that\n",
    "# start with a particular letter\n",
    "agg_word_df = word_df['first_letter'].groupby(word_df['first_letter']).agg(np.size).to_frame()\n",
    "\n",
    "# set column names\n",
    "agg_word_df.columns = ['word_count']\n",
    "\n",
    "# reset the index to rename columns\n",
    "agg_word_df = agg_word_df.reset_index()\n",
    "\n",
    "# sort the dataframe by frequency\n",
    "agg_word_df = agg_word_df.sort_values(by='word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>y</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>z</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v</td>\n",
       "      <td>3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w</td>\n",
       "      <td>3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>6228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>6771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>6836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>o</td>\n",
       "      <td>7830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r</td>\n",
       "      <td>9613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>10849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>10963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>12513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t</td>\n",
       "      <td>12853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u</td>\n",
       "      <td>16361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>16974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>19783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p</td>\n",
       "      <td>24341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>24929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_letter  word_count\n",
       "23            x         380\n",
       "24            y         663\n",
       "25            z         942\n",
       "16            q        1148\n",
       "9             j        1603\n",
       "10            k        2239\n",
       "21            v        3418\n",
       "22            w        3910\n",
       "11            l        6228\n",
       "13            n        6742\n",
       "6             g        6771\n",
       "5             f        6836\n",
       "14            o        7830\n",
       "4             e        8703\n",
       "8             i        8786\n",
       "7             h        8992\n",
       "17            r        9613\n",
       "3             d       10849\n",
       "1             b       10963\n",
       "12            m       12513\n",
       "19            t       12853\n",
       "20            u       16361\n",
       "0             a       16974\n",
       "2             c       19783\n",
       "15            p       24341\n",
       "18            s       24929"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_word_df.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the letters sorted by word frequency\n",
    "sorted_first_letters = agg_word_df['first_letter'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the letter dictionary from part 1\n",
    "in_file_name = 'letter_dict.pkl'\n",
    "letter_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the word dictionary from part 1\n",
    "in_file_name = 'word_dict.pkl'\n",
    "word_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the char matrix from part 1\n",
    "in_file_name = 'char_matrix.npy'\n",
    "ipn = os.path.join(in_file_path, in_file_name)\n",
    "char_matrix = np.load(file = ipn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract sub-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked  \n",
       "0                   a  \n",
       "1                   a  \n",
       "2                  la  \n",
       "3                 lai  \n",
       "4                  ma  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop duplicates based on the word group. \n",
    "# by default, this will only keep the first record and it will drop all others\n",
    "wg_df = word_df.drop_duplicates(subset = ['word_group_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wg_df = wg_df.sort_values(by = 'word_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215842"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique word groups\n",
    "len(wg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked  \n",
       "0                   a  \n",
       "1                   a  \n",
       "2                  la  \n",
       "3                 lai  \n",
       "4                  ma  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    215842.000000\n",
       "mean     107920.500000\n",
       "std       62308.362739\n",
       "min           0.000000\n",
       "25%       53960.250000\n",
       "50%      107920.500000\n",
       "75%      161880.750000\n",
       "max      215841.000000\n",
       "Name: word_group_id, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df['word_group_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the word group ids\n",
    "word_group_id_list = wg_df['word_group_id'].to_numpy()\n",
    "# and the associated word_id\n",
    "word_id_list = wg_df['word_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trim the char matrix by word id\n",
    "# and not the word_group id\n",
    "wchar_matrix = char_matrix[wg_df['word_id'].to_numpy(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i don't use these objects, but i can't delete them?\n",
    "# build a word_id to word_group_id dictionary\n",
    "word_id_wg_id_dict = dict()\n",
    "# and a word_group_id to word_id dictionary\n",
    "wg_id_word_id_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for word_id, wg_id in zip(wg_df['word_id'], wg_df['word_group_id']):\n",
    "    word_id_wg_id_dict[word_id] = wg_id\n",
    "    wg_id_word_id_dict[wg_id] = word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the dictionary holding the sub-matrices\n",
    "n_char_matrix_dict = {}\n",
    "\n",
    "# by word length\n",
    "word_length_list = sorted(wg_df['n_chars'].unique().tolist())\n",
    "\n",
    "# python dictionaries work by storing the hash values of objects\n",
    "# Anything that can be hashed can be a dictionary key. \n",
    "# Computing the hash value of an object ahead of time can reduce dictionary access time.\n",
    "# we'll compute the associated hash value of the tuple used to identify the sub-matrices.\n",
    "\n",
    "wg_id_n_char_matrix_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, now we need to populate two three sets of dictionaries:\n",
    "# word length\n",
    "# letter selector\n",
    "# the intersection of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need additional functions to process the word df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>wg_id_n_char_matrix_key</th>\n",
       "      <th>wg_id_n_char_matrix_key_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>(1, a)</td>\n",
       "      <td>-6360362268230980030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>(2, a)</td>\n",
       "      <td>-3556242904901448803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>la</td>\n",
       "      <td>(3, la)</td>\n",
       "      <td>6474388841896662971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>la</td>\n",
       "      <td>(5, la)</td>\n",
       "      <td>1171310771219076416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "      <td>ma</td>\n",
       "      <td>(3, ma)</td>\n",
       "      <td>-1796972308276022362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked letter_selector wg_id_n_char_matrix_key  \\\n",
       "0                   a               a                  (1, a)   \n",
       "1                   a               a                  (2, a)   \n",
       "2                  la              la                 (3, la)   \n",
       "3                 lai              la                 (5, la)   \n",
       "4                  ma              ma                 (3, ma)   \n",
       "\n",
       "   wg_id_n_char_matrix_key_hash  \n",
       "0          -6360362268230980030  \n",
       "1          -3556242904901448803  \n",
       "2           6474388841896662971  \n",
       "3           1171310771219076416  \n",
       "4          -1796972308276022362  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_char_dict(wg_df:pd.DataFrame):\n",
    "\n",
    "    n_char_dict = {}\n",
    "\n",
    "    n_char_list = wg_df['n_chars'].unique().tolist()\n",
    "\n",
    "    for nc in n_char_list:\n",
    "        curr_n_char_word_id_set = wg_df.loc[(wg_df['n_chars']>=nc) , 'word_group_id'].tolist()\n",
    "        curr_n_char_word_id_set = set(curr_n_char_word_id_set)\n",
    "        n_char_dict[nc] = curr_n_char_word_id_set\n",
    "\n",
    "    return n_char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_letter_selector_dict(wg_df:pd.DataFrame):\n",
    "    ls_dict = {}\n",
    "\n",
    "    # by word length and n least common letters\n",
    "    wg_df['letter_selector'] = wg_df['letter_group_ranked'].str[:n_common_letters]\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_char_dict = build_n_char_dict(wg_df = wg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...creating 3488 sub matrices\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "...sub-matrix extraction took 21.84 seconds...\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# populate the dictionaries\n",
    "####\n",
    "\n",
    "loop_count = 0\n",
    "s_time = datetime.datetime.now()\n",
    "# by word length and n least common letters\n",
    "wg_df['letter_selector'] = wg_df['letter_group_ranked'].str[:n_common_letters]\n",
    "\n",
    "# store the tuple in the wg_df\n",
    "# we have to use tuples because tuples are immutable - once created, they cannot be changed\n",
    "#https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences    \n",
    "wg_df['wg_id_n_char_matrix_key'] = tuple(zip(wg_df['n_chars'], wg_df['letter_selector']))\n",
    "\n",
    "# This is a combinatorial problem.\n",
    "# Limit the number of selections we need to make    \n",
    "letter_selector_df = wg_df[['n_chars', 'letter_selector']].drop_duplicates()\n",
    "n_sub_matrices = len(letter_selector_df)\n",
    "print('...creating', n_sub_matrices, 'sub matrices')\n",
    "# this means n_sub_matrices are queried.\n",
    "# we can expedite this by only selecting certain word ids once, converting to a set,\n",
    "# and then storing that set based on the selection criteria.\n",
    "# many words are going to have the same least common characters, let's identify the\n",
    "# corresponding rows accordingly\n",
    "\n",
    "letter_selector_list = letter_selector_df['letter_selector'].unique().tolist()\n",
    "n_char_word_id_list_dict = {}\n",
    "ls_word_id_list_dict = {}\n",
    "\n",
    "for n_chars, letter_selector in zip(letter_selector_df['n_chars'],\n",
    "                                    letter_selector_df['letter_selector']):\n",
    "\n",
    "    # word id set by character length\n",
    "    if n_chars in n_char_word_id_list_dict:\n",
    "        # get the set if it already exists\n",
    "        curr_n_char_word_id_set = n_char_word_id_list_dict[n_chars]\n",
    "    else:\n",
    "        # create the set if it does not exist\n",
    "        curr_n_char_word_id_set = wg_df.loc[(wg_df['n_chars']>=n_chars) , 'word_group_id'].tolist()\n",
    "        curr_n_char_word_id_set = set(curr_n_char_word_id_set)\n",
    "        n_char_word_id_list_dict[n_chars] = curr_n_char_word_id_set\n",
    "\n",
    "    # word id by letter selector\n",
    "    if letter_selector in ls_word_id_list_dict:\n",
    "        # get the set if it already exists\n",
    "        curr_letter_select_word_id_set = ls_word_id_list_dict[letter_selector]\n",
    "    else:\n",
    "        # the set needs to be computed\n",
    "        # build the oolumn selector using list comprehension\n",
    "        column_selector = [letter_dict[curr_letter] for curr_letter in letter_selector]\n",
    "\n",
    "        # create a true-false matrix where only certain columns, corresponding to\n",
    "        # letter indices, have a value of 1 or more\n",
    "        outcome = wchar_matrix[:, column_selector] > 0    \n",
    "\n",
    "        # which rows in the above matrix evaluate to all True\n",
    "        outcome_indices = np.all(a = outcome, axis = 1)\n",
    "\n",
    "        # these indices match with the word_id_list, extract the subset        \n",
    "        curr_letter_select_word_id_set = word_group_id_list[outcome_indices]\n",
    "        curr_letter_select_word_id_set = set(curr_letter_select_word_id_set)\n",
    "        ls_word_id_list_dict[letter_selector] = curr_letter_select_word_id_set\n",
    "\n",
    "    # the set intersection of the curr_n_char_word_id_set and the\n",
    "    # curr_letter_select_word_id_set are indices that feature a word of at\n",
    "    # least a certain length and the characters of interest\n",
    "    outcome_wg_id_set = curr_n_char_word_id_set.intersection(curr_letter_select_word_id_set)\n",
    "    # convert the set to an array\n",
    "    outcome_word_group_id_list = np.array(list(outcome_wg_id_set))\n",
    "\n",
    "    # subset the wchar_matrix to get the sub matrix\n",
    "    curr_wchar_matrix = wchar_matrix[outcome_word_group_id_list, ]\n",
    "\n",
    "    # now, store that in the sub matrix dictionary\n",
    "    key_value = (n_chars, letter_selector)\n",
    "    key_value_hash = hash(key_value)\n",
    "    n_char_matrix_dict[key_value_hash] = (outcome_word_group_id_list, curr_wchar_matrix)\n",
    "\n",
    "    # simple progress display\n",
    "    loop_count += 1\n",
    "    if loop_count % 1000 == 0:\n",
    "        print(loop_count)\n",
    "        \n",
    "wg_df['wg_id_n_char_matrix_key_hash'] = wg_df['wg_id_n_char_matrix_key'].map(hash)\n",
    "for curr_word_id, curr_key_hash in zip(wg_df['word_group_id'], wg_df['wg_id_n_char_matrix_key_hash']):\n",
    "    wg_id_n_char_matrix_dict[curr_word_id] = curr_key_hash\n",
    "\n",
    "e_time = datetime.datetime.now()\n",
    "p_time = e_time - s_time\n",
    "# how long did this pre-processing take?\n",
    "p_time = round(p_time.total_seconds(), 2)\n",
    "print('...sub-matrix extraction took', p_time, 'seconds...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215842"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wg_id_n_char_matrix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's examine what we've created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this will find all words in this group: emit, item, mite, time\n",
    "temp_focal_word = 'emit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58098\n",
      "-3049262637289096677\n",
      "(30390,)\n",
      "(30390, 26)\n"
     ]
    }
   ],
   "source": [
    "temp_focal_word_id = wg_df.loc[wg_df['lcase']==temp_focal_word, 'word_group_id'].iloc[0]\n",
    "# the ID of the focal word\n",
    "print(temp_focal_word_id)\n",
    "# the hash corresponding to the tuple of the candidate word ids and the sub-matrix\n",
    "temp_focal_word_hash_id = wg_id_n_char_matrix_dict[temp_focal_word_id]\n",
    "print(temp_focal_word_hash_id)\n",
    "# the candidate word ids and the sub matrix\n",
    "temp_word_id_list, temp_sub_matrix = n_char_matrix_dict[temp_focal_word_hash_id]\n",
    "print(temp_word_id_list.shape)\n",
    "print(temp_sub_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# demontrate the look up with the word 'quiet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_word_group_id = word_df.loc[word_df['lcase'] == 'quiet', 'word_group_id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151389"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_word_group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = get_values(wg_id = curr_word_group_id, \n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    wg_id_n_char_matrix_dict = wg_id_n_char_matrix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many parent/from words were found for the word 'quiet'?\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155650, 151389],\n",
       "       [155648, 151389],\n",
       "       [155649, 151389],\n",
       "       ...,\n",
       "       [155645, 151389],\n",
       "       [155646, 151389],\n",
       "       [155647, 151389]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an array of from words to the word 'quiet'\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and those words are...\n",
    "word_list = word_df.loc[word_df['word_group_id'].isin(output[:, 0]), 'lcase'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aceanthrenequinone',\n",
       " 'acquaintance',\n",
       " 'acquaintanceship',\n",
       " 'acquainted',\n",
       " 'acquaintedness',\n",
       " 'acquiescement',\n",
       " 'acquiescent',\n",
       " 'acquiescently',\n",
       " 'acquirement',\n",
       " 'acquisite',\n",
       " 'acquisited',\n",
       " 'acquisitive',\n",
       " 'acquisitively',\n",
       " 'acquisitiveness',\n",
       " 'acquitment',\n",
       " 'acquittance',\n",
       " 'acquitter',\n",
       " 'adequation',\n",
       " 'adequative',\n",
       " 'altiloquence',\n",
       " 'altiloquent',\n",
       " 'aminoanthraquinone',\n",
       " 'anthradiquinone',\n",
       " 'anthrahydroquinone',\n",
       " 'anthraquinone',\n",
       " 'anticritique',\n",
       " 'antimasque',\n",
       " 'antimasquer',\n",
       " 'antimasquerade',\n",
       " 'antiquarianize',\n",
       " 'antiquate',\n",
       " 'antiquated',\n",
       " 'antiquatedness',\n",
       " 'antique',\n",
       " 'antiquely',\n",
       " 'antiqueness',\n",
       " 'antiquer',\n",
       " 'appropinquate',\n",
       " 'aquarellist',\n",
       " 'aquatile',\n",
       " 'aquatinter',\n",
       " 'aquativeness',\n",
       " 'aquiculture',\n",
       " 'aquocellolitis',\n",
       " 'aquopentamminecobaltic',\n",
       " 'aquotize',\n",
       " 'architecturesque',\n",
       " 'arquerite',\n",
       " 'banqueteering',\n",
       " 'barquantine',\n",
       " 'becquerelite',\n",
       " 'bedquilt',\n",
       " 'bequirtle',\n",
       " 'bilboquet',\n",
       " 'biquadrate',\n",
       " 'biquarterly',\n",
       " 'biquintile',\n",
       " 'bisquette',\n",
       " 'breviloquent',\n",
       " 'briquette',\n",
       " 'byzantinesque',\n",
       " 'caquetio',\n",
       " 'centiloquy',\n",
       " 'chicquest',\n",
       " 'cinquecentism',\n",
       " 'cinquecentist',\n",
       " 'cinquecento',\n",
       " 'codelinquent',\n",
       " 'coequality',\n",
       " 'coequation',\n",
       " 'colliquate',\n",
       " 'colliquative',\n",
       " 'colliquativeness',\n",
       " 'consequential',\n",
       " 'consequentiality',\n",
       " 'consequentially',\n",
       " 'consequentialness',\n",
       " 'coquelicot',\n",
       " 'coquettish',\n",
       " 'coquettishly',\n",
       " 'coquettishness',\n",
       " 'coquimbite',\n",
       " 'corinthianesque',\n",
       " 'counteracquittance',\n",
       " 'counterequivalent',\n",
       " 'counterquestion',\n",
       " 'counterquip',\n",
       " 'critique',\n",
       " 'deaquation',\n",
       " 'delinquent',\n",
       " 'delinquently',\n",
       " 'deliquescent',\n",
       " 'dentiloquist',\n",
       " 'dentiloquy',\n",
       " 'desquamation',\n",
       " 'desquamative',\n",
       " 'diphenylquinomethane',\n",
       " 'disacquaintance',\n",
       " 'disequilibrate',\n",
       " 'disequilibration',\n",
       " 'disfrequent',\n",
       " 'disquiet',\n",
       " 'disquieted',\n",
       " 'disquietedly',\n",
       " 'disquietedness',\n",
       " 'disquieten',\n",
       " 'disquieter',\n",
       " 'disquieting',\n",
       " 'disquietingly',\n",
       " 'disquietly',\n",
       " 'disquietness',\n",
       " 'disquietude',\n",
       " 'disquisite',\n",
       " 'disquisitive',\n",
       " 'disquisitively',\n",
       " 'disquixote',\n",
       " 'earthquaking',\n",
       " 'eliquate',\n",
       " 'eliquation',\n",
       " 'eloquential',\n",
       " 'equability',\n",
       " 'equalist',\n",
       " 'equalitarian',\n",
       " 'equalitarianism',\n",
       " 'equality',\n",
       " 'equalization',\n",
       " 'equanimity',\n",
       " 'equation',\n",
       " 'equational',\n",
       " 'equationally',\n",
       " 'equationism',\n",
       " 'equationist',\n",
       " 'equatorial',\n",
       " 'equatorially',\n",
       " 'equestrial',\n",
       " 'equestrian',\n",
       " 'equestrianism',\n",
       " 'equestrianize',\n",
       " 'equestrianship',\n",
       " 'equestrienne',\n",
       " 'equianchorate',\n",
       " 'equiangularity',\n",
       " 'equiarticulate',\n",
       " 'equiatomic',\n",
       " 'equibiradiate',\n",
       " 'equicostate',\n",
       " 'equidensity',\n",
       " 'equidifferent',\n",
       " 'equidistance',\n",
       " 'equidistant',\n",
       " 'equidistantial',\n",
       " 'equidistantly',\n",
       " 'equidistribution',\n",
       " 'equidominant',\n",
       " 'equielliptical',\n",
       " 'equiformity',\n",
       " 'equijacent',\n",
       " 'equilateral',\n",
       " 'equilaterally',\n",
       " 'equilibrant',\n",
       " 'equilibrate',\n",
       " 'equilibration',\n",
       " 'equilibrative',\n",
       " 'equilibrator',\n",
       " 'equilibratory',\n",
       " 'equilibriate',\n",
       " 'equilibrist',\n",
       " 'equilibristat',\n",
       " 'equilibristic',\n",
       " 'equilibrity',\n",
       " 'equilobate',\n",
       " 'equilocation',\n",
       " 'equilucent',\n",
       " 'equimomental',\n",
       " 'equimultiple',\n",
       " 'equinate',\n",
       " 'equinity',\n",
       " 'equinoctial',\n",
       " 'equinoctially',\n",
       " 'equiomnipotent',\n",
       " 'equiparant',\n",
       " 'equiparate',\n",
       " 'equiparation',\n",
       " 'equipartile',\n",
       " 'equipartisan',\n",
       " 'equipartition',\n",
       " 'equipment',\n",
       " 'equipollent',\n",
       " 'equipollently',\n",
       " 'equipollentness',\n",
       " 'equiponderant',\n",
       " 'equiponderate',\n",
       " 'equiponderation',\n",
       " 'equipostile',\n",
       " 'equipotent',\n",
       " 'equipotential',\n",
       " 'equipotentiality',\n",
       " 'equiprobabilist',\n",
       " 'equiprobability',\n",
       " 'equiproportional',\n",
       " 'equiproportionality',\n",
       " 'equiradiate',\n",
       " 'equirotal',\n",
       " 'equisegmented',\n",
       " 'equisetaceae',\n",
       " 'equisetaceous',\n",
       " 'equisetales',\n",
       " 'equisetic',\n",
       " 'equisetum',\n",
       " 'equisonant',\n",
       " 'equispatial',\n",
       " 'equitable',\n",
       " 'equitableness',\n",
       " 'equitably',\n",
       " 'equitangential',\n",
       " 'equitant',\n",
       " 'equitation',\n",
       " 'equitative',\n",
       " 'equitemporal',\n",
       " 'equitemporaneous',\n",
       " 'equites',\n",
       " 'equitist',\n",
       " 'equitriangular',\n",
       " 'equity',\n",
       " 'equivalent',\n",
       " 'equivalently',\n",
       " 'equivaliant',\n",
       " 'equivelocity',\n",
       " 'equivocality',\n",
       " 'equivocate',\n",
       " 'equivocatingly',\n",
       " 'equivocation',\n",
       " 'equivocator',\n",
       " 'equivocatory',\n",
       " 'equivote',\n",
       " 'etiquette',\n",
       " 'etiquettical',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'exquisiteness',\n",
       " 'exquisitism',\n",
       " 'exquisitively',\n",
       " 'extraequilibrium',\n",
       " 'extraquiz',\n",
       " 'fatiloquent',\n",
       " 'foreacquaint',\n",
       " 'frequentation',\n",
       " 'frequentative',\n",
       " 'giantesque',\n",
       " 'gigantesque',\n",
       " 'giottesque',\n",
       " 'grandiloquent',\n",
       " 'grandiloquently',\n",
       " 'griquaite',\n",
       " 'grotesquerie',\n",
       " 'hindquarter',\n",
       " 'hydroxyanthraquinone',\n",
       " 'hyperequatorial',\n",
       " 'illaqueate',\n",
       " 'illaqueation',\n",
       " 'inacquaintance',\n",
       " 'inacquiescent',\n",
       " 'inadequate',\n",
       " 'inadequately',\n",
       " 'inadequateness',\n",
       " 'inadequation',\n",
       " 'inadequative',\n",
       " 'inadequatively',\n",
       " 'inconsequent',\n",
       " 'inconsequential',\n",
       " 'inconsequentiality',\n",
       " 'inconsequentially',\n",
       " 'inconsequently',\n",
       " 'inconsequentness',\n",
       " 'ineloquent',\n",
       " 'ineloquently',\n",
       " 'inequalitarian',\n",
       " 'inequality',\n",
       " 'inequation',\n",
       " 'inequicostate',\n",
       " 'inequidistant',\n",
       " 'inequilateral',\n",
       " 'inequilobate',\n",
       " 'inequipotential',\n",
       " 'inequipotentiality',\n",
       " 'inequitable',\n",
       " 'inequitableness',\n",
       " 'inequitably',\n",
       " 'inequity',\n",
       " 'inequivalent',\n",
       " 'infrequent',\n",
       " 'infrequently',\n",
       " 'iniquitable',\n",
       " 'iniquitousness',\n",
       " 'inquaintance',\n",
       " 'inquest',\n",
       " 'inquestual',\n",
       " 'inquiet',\n",
       " 'inquietation',\n",
       " 'inquietly',\n",
       " 'inquietness',\n",
       " 'inquietude',\n",
       " 'inquinate',\n",
       " 'inquirent',\n",
       " 'inquisite',\n",
       " 'inquisitive',\n",
       " 'inquisitively',\n",
       " 'inquisitiveness',\n",
       " 'inquisitorialness',\n",
       " 'inquisitress',\n",
       " 'inquisiturient',\n",
       " 'insequent',\n",
       " 'interequinoctial',\n",
       " 'interquarrel',\n",
       " 'interquarter',\n",
       " 'intersqueeze',\n",
       " 'isoquercitrin',\n",
       " 'italianesque',\n",
       " 'jacqueminot',\n",
       " 'jequirity',\n",
       " 'joaquinite',\n",
       " 'jusquaboutisme',\n",
       " 'lacquerist',\n",
       " 'latinesque',\n",
       " 'limequat',\n",
       " 'liquate',\n",
       " 'liquefacient',\n",
       " 'liquefaction',\n",
       " 'liquefactive',\n",
       " 'liquescent',\n",
       " 'liquidate',\n",
       " 'machinotechnique',\n",
       " 'magniloquent',\n",
       " 'magniloquently',\n",
       " 'maquiritare',\n",
       " 'marquisate',\n",
       " 'marquisette',\n",
       " 'marquisotte',\n",
       " 'mastoideosquamous',\n",
       " 'mesquite',\n",
       " 'microtechnique',\n",
       " 'milliequivalent',\n",
       " 'miquelet',\n",
       " 'misquote',\n",
       " 'misquoter',\n",
       " 'monchiquite',\n",
       " 'mosquitocide',\n",
       " 'mosquitoey',\n",
       " 'mousquetaire',\n",
       " 'multiloquence',\n",
       " 'multiloquent',\n",
       " 'naphthoquinone',\n",
       " 'nesquehonite',\n",
       " 'nonacquaintance',\n",
       " 'nonacquiescent',\n",
       " 'nonacquisitive',\n",
       " 'nondeliquescent',\n",
       " 'nondesquamative',\n",
       " 'nonequation',\n",
       " 'nonequatorial',\n",
       " 'nonequestrian',\n",
       " 'nonequilateral',\n",
       " 'nonequivalent',\n",
       " 'nonequivocating',\n",
       " 'nonrelinquishment',\n",
       " 'nonrequirement',\n",
       " 'nonrequisition',\n",
       " 'nonrequital',\n",
       " 'nonsequestration',\n",
       " 'novantique',\n",
       " 'obliquate',\n",
       " 'obsequiosity',\n",
       " 'obsequity',\n",
       " 'omniloquent',\n",
       " 'orthobenzoquinone',\n",
       " 'orthoquinone',\n",
       " 'outquestion',\n",
       " 'outquibble',\n",
       " 'overexquisite',\n",
       " 'overexquisitely',\n",
       " 'overquantity',\n",
       " 'overquiet',\n",
       " 'overquietly',\n",
       " 'overquietness',\n",
       " 'oxyanthraquinone',\n",
       " 'oxynaphtoquinone',\n",
       " 'oxyquinaseptol',\n",
       " 'parietoquadrate',\n",
       " 'parietosquamosal',\n",
       " 'pauciloquent',\n",
       " 'pauciloquently',\n",
       " 'pectoriloquial',\n",
       " 'pectoriloquism',\n",
       " 'pectoriloquous',\n",
       " 'pectoriloquy',\n",
       " 'pentaquine',\n",
       " 'perequitate',\n",
       " 'perquisite',\n",
       " 'perquisition',\n",
       " 'perquisitor',\n",
       " 'picqueter',\n",
       " 'picturesque',\n",
       " 'picturesquely',\n",
       " 'picturesqueness',\n",
       " 'picturesquish',\n",
       " 'piquantness',\n",
       " 'piquet',\n",
       " 'politique',\n",
       " 'postique',\n",
       " 'pratique',\n",
       " 'preacquaint',\n",
       " 'preacquaintance',\n",
       " 'preacquit',\n",
       " 'preacquittal',\n",
       " 'preantiquity',\n",
       " 'predelinquent',\n",
       " 'predelinquently',\n",
       " 'preinquisition',\n",
       " 'preliquidate',\n",
       " 'preliquidation',\n",
       " 'prequalification',\n",
       " 'prequarantine',\n",
       " 'prequestion',\n",
       " 'prequotation',\n",
       " 'prerequirement',\n",
       " 'prerequisite',\n",
       " 'prerequisition',\n",
       " 'preterequine',\n",
       " 'procritique',\n",
       " 'proequality',\n",
       " 'pseudoantique',\n",
       " 'pseudoaquatic',\n",
       " 'pseudoequalitarian',\n",
       " 'quadragintesimal',\n",
       " 'quadrantile',\n",
       " 'quadrantlike',\n",
       " 'quadratifera',\n",
       " 'quadratiferous',\n",
       " 'quadrialate',\n",
       " 'quadriannulate',\n",
       " 'quadriarticulate',\n",
       " 'quadriarticulated',\n",
       " 'quadricapsulate',\n",
       " 'quadricarinate',\n",
       " 'quadricentennial',\n",
       " 'quadriciliate',\n",
       " 'quadricostate',\n",
       " 'quadricotyledonous',\n",
       " 'quadricrescentic',\n",
       " 'quadricrescentoid',\n",
       " 'quadricuspidate',\n",
       " 'quadridentate',\n",
       " 'quadridentated',\n",
       " 'quadriderivative',\n",
       " 'quadridigitate',\n",
       " 'quadrienniumutile',\n",
       " 'quadrifoliate',\n",
       " 'quadrifoliolate',\n",
       " 'quadrifurcate',\n",
       " 'quadrifurcated',\n",
       " 'quadrigate',\n",
       " 'quadrigeminate',\n",
       " 'quadrijugate',\n",
       " 'quadrilaminate',\n",
       " 'quadrilateral',\n",
       " 'quadrilaterally',\n",
       " 'quadrilateralness',\n",
       " 'quadriliteral',\n",
       " 'quadrilobate',\n",
       " 'quadriloculate',\n",
       " 'quadrimetallic',\n",
       " 'quadrinucleate',\n",
       " 'quadrioxalate',\n",
       " 'quadripartite',\n",
       " 'quadripartitely',\n",
       " 'quadripennate',\n",
       " 'quadriphosphate',\n",
       " 'quadripinnate',\n",
       " 'quadriplicate',\n",
       " 'quadriplicated',\n",
       " 'quadriradiate',\n",
       " 'quadrisect',\n",
       " 'quadrisection',\n",
       " 'quadriseptate',\n",
       " 'quadrisetose',\n",
       " 'quadristearate',\n",
       " 'quadrisulcate',\n",
       " 'quadrisulcated',\n",
       " 'quadriternate',\n",
       " 'quadritubercular',\n",
       " 'quadrituberculate',\n",
       " 'quadriurate',\n",
       " 'quadrivalent',\n",
       " 'quadrivalently',\n",
       " 'quadrivoltine',\n",
       " 'quadrupedantic',\n",
       " 'quadrupedantical',\n",
       " 'quadrupedation',\n",
       " 'quadruplicate',\n",
       " 'quadruplicature',\n",
       " 'quaesitum',\n",
       " 'quaestorial',\n",
       " 'quaestorian',\n",
       " 'quaestorship',\n",
       " 'quaintance',\n",
       " 'quaintise',\n",
       " 'quaintness',\n",
       " 'quakerization',\n",
       " 'quaketail',\n",
       " 'qualificative',\n",
       " 'qualimeter',\n",
       " 'qualitative',\n",
       " 'qualitatively',\n",
       " 'qualitied',\n",
       " 'qualityless',\n",
       " 'quantifiable',\n",
       " 'quantifier',\n",
       " 'quantimeter',\n",
       " 'quantitate',\n",
       " 'quantitative',\n",
       " 'quantitatively',\n",
       " 'quantitativeness',\n",
       " 'quantitied',\n",
       " 'quantitive',\n",
       " 'quantitively',\n",
       " 'quantivalence',\n",
       " 'quantivalency',\n",
       " 'quantivalent',\n",
       " 'quantize',\n",
       " 'quarantinable',\n",
       " 'quarantine',\n",
       " 'quarantiner',\n",
       " 'quartenylic',\n",
       " 'quarterdeckish',\n",
       " 'quartering',\n",
       " 'quarterization',\n",
       " 'quartermasterlike',\n",
       " 'quartermastership',\n",
       " 'quartile',\n",
       " 'quartine',\n",
       " 'quartodeciman',\n",
       " 'quartodecimanism',\n",
       " 'quartziferous',\n",
       " 'quartzite',\n",
       " 'quassative',\n",
       " 'quaternarian',\n",
       " 'quaternarius',\n",
       " 'quaternion',\n",
       " 'quaternionic',\n",
       " 'quaternionist',\n",
       " 'quaternitarian',\n",
       " 'quaternity',\n",
       " 'quatrefeuille',\n",
       " 'quatrefoil',\n",
       " 'quatrefoiled',\n",
       " 'quatrefoliated',\n",
       " 'quatrible',\n",
       " 'quatrocentism',\n",
       " 'quatrocentist',\n",
       " 'quattie',\n",
       " 'quatuorvirate',\n",
       " 'quebrachitol',\n",
       " 'queenite',\n",
       " 'queenright',\n",
       " 'queerity',\n",
       " 'queesting',\n",
       " 'queintise',\n",
       " 'quenselite',\n",
       " 'quercetagetin',\n",
       " 'quercetic',\n",
       " 'quercetin',\n",
       " 'quercimeritrin',\n",
       " 'quercitannic',\n",
       " 'quercitannin',\n",
       " 'quercite',\n",
       " 'quercitin',\n",
       " 'quercitol',\n",
       " 'quercitrin',\n",
       " 'quercitron',\n",
       " 'querist',\n",
       " 'querulential',\n",
       " 'querulist',\n",
       " 'querulity',\n",
       " 'querulosity',\n",
       " 'queryist',\n",
       " 'quesited',\n",
       " 'quesitive',\n",
       " 'questingly',\n",
       " 'question',\n",
       " 'questionability',\n",
       " 'questionable',\n",
       " 'questionableness',\n",
       " 'questionably',\n",
       " 'questionary',\n",
       " 'questionee',\n",
       " 'questioner',\n",
       " 'questioningly',\n",
       " 'questionist',\n",
       " 'questionless',\n",
       " 'questionlessly',\n",
       " 'questionnaire',\n",
       " 'questionous',\n",
       " 'questionwise',\n",
       " 'questorial',\n",
       " 'questorship',\n",
       " 'quetenite',\n",
       " 'quiblet',\n",
       " 'quickhearted',\n",
       " 'quickset',\n",
       " 'quickstep',\n",
       " 'quiddative',\n",
       " 'quidditative',\n",
       " 'quidditatively',\n",
       " 'quiescent',\n",
       " 'quiescently',\n",
       " 'quiet',\n",
       " 'quietable',\n",
       " 'quieten',\n",
       " 'quietener',\n",
       " 'quieter',\n",
       " 'quieting',\n",
       " 'quietism',\n",
       " 'quietist',\n",
       " 'quietistic',\n",
       " 'quietive',\n",
       " 'quietlike',\n",
       " 'quietly',\n",
       " 'quietness',\n",
       " 'quietsome',\n",
       " 'quietude',\n",
       " 'quietus',\n",
       " 'quileute',\n",
       " 'quillet',\n",
       " 'quilleted',\n",
       " 'quilted',\n",
       " 'quilter',\n",
       " 'quinaielt',\n",
       " 'quinate',\n",
       " 'quinatoxine',\n",
       " 'quincentenary',\n",
       " 'quincentennial',\n",
       " 'quincewort',\n",
       " 'quindecemvirate',\n",
       " 'quinetum',\n",
       " 'quingentenary',\n",
       " 'quiniretin',\n",
       " 'quinisext',\n",
       " 'quinisextine',\n",
       " 'quinite',\n",
       " 'quinnet',\n",
       " 'quinometry',\n",
       " 'quinotoxine',\n",
       " 'quinovate',\n",
       " 'quinquecostate',\n",
       " 'quinquedentate',\n",
       " 'quinquedentated',\n",
       " 'quinquefoliate',\n",
       " 'quinquefoliated',\n",
       " 'quinquefoliolate',\n",
       " 'quinquelateral',\n",
       " 'quinqueliteral',\n",
       " 'quinquelobate',\n",
       " 'quinquelobated',\n",
       " 'quinquennialist',\n",
       " 'quinquepartite',\n",
       " 'quinquepetaloid',\n",
       " 'quinquepunctal',\n",
       " 'quinquepunctate',\n",
       " 'quinqueradiate',\n",
       " 'quinquertium',\n",
       " 'quinquesect',\n",
       " 'quinquesection',\n",
       " 'quinqueseptate',\n",
       " 'quinqueseriate',\n",
       " 'quinquetubercular',\n",
       " 'quinquetuberculate',\n",
       " 'quinquevalent',\n",
       " 'quinquevirate',\n",
       " 'quinquiliteral',\n",
       " 'quintadena',\n",
       " 'quintadene',\n",
       " 'quinte',\n",
       " 'quintelement',\n",
       " 'quintennial',\n",
       " 'quinternion',\n",
       " 'quinteron',\n",
       " 'quinteroon',\n",
       " 'quintessence',\n",
       " 'quintessential',\n",
       " 'quintessentiality',\n",
       " 'quintessentially',\n",
       " 'quintessentiate',\n",
       " 'quintet',\n",
       " 'quintette',\n",
       " 'quintetto',\n",
       " 'quintile',\n",
       " 'quintiped',\n",
       " 'quintole',\n",
       " 'quintuple',\n",
       " 'quintuplet',\n",
       " 'quintuplicate',\n",
       " 'quintuplinerved',\n",
       " 'quintupliribbed',\n",
       " 'quipster',\n",
       " 'quirite',\n",
       " 'quirites',\n",
       " 'quisqueite',\n",
       " 'quite',\n",
       " 'quitemoca',\n",
       " 'quiteno',\n",
       " 'quitrent',\n",
       " 'quittable',\n",
       " 'quittance',\n",
       " 'quitted',\n",
       " 'quitter',\n",
       " 'quixote',\n",
       " 'quixotize',\n",
       " 'quodlibet',\n",
       " 'quodlibetal',\n",
       " 'quodlibetarian',\n",
       " 'quodlibetary',\n",
       " 'quodlibetic',\n",
       " 'quodlibetical',\n",
       " 'quodlibetically',\n",
       " 'quoiter',\n",
       " 'quoitlike',\n",
       " 'quotative',\n",
       " 'quotennial',\n",
       " 'quotidianness',\n",
       " 'quotient',\n",
       " 'quotiety',\n",
       " 'quotlibet',\n",
       " 'reacquaint',\n",
       " 'reacquaintance',\n",
       " 'reacquisition',\n",
       " 'relinquent',\n",
       " 'relinquishment',\n",
       " 'reliquidate',\n",
       " 'reliquidation',\n",
       " 'requalification',\n",
       " 'requarantine',\n",
       " 'requestion',\n",
       " 'requirement',\n",
       " 'requisite',\n",
       " 'requisitely',\n",
       " 'requisiteness',\n",
       " 'requisition',\n",
       " 'requisitionary',\n",
       " 'requisitioner',\n",
       " 'requisitionist',\n",
       " 'requisitor',\n",
       " 'requisitorial',\n",
       " 'requisitory',\n",
       " 'requit',\n",
       " 'requitable',\n",
       " 'requital',\n",
       " 'requitative',\n",
       " 'requite',\n",
       " 'requiteful',\n",
       " 'requitement',\n",
       " 'requiter',\n",
       " 'requotation',\n",
       " 'resequestration',\n",
       " 'retranquilize',\n",
       " 'sanctiloquent',\n",
       " 'scioterique',\n",
       " 'semiacquaintance',\n",
       " 'semiantique',\n",
       " 'semiaquatic',\n",
       " 'semiequitant',\n",
       " 'semiliquidity',\n",
       " 'semiquadrantly',\n",
       " 'semiquadrate',\n",
       " 'semiquantitative',\n",
       " 'semiquantitatively',\n",
       " 'semiquartile',\n",
       " 'semiquietism',\n",
       " 'semiquietist',\n",
       " 'semiquintile',\n",
       " 'semiquote',\n",
       " 'sequacity',\n",
       " 'sequential',\n",
       " 'sequentiality',\n",
       " 'sequentially',\n",
       " 'sequestration',\n",
       " 'sequestratrices',\n",
       " 'sequestratrix',\n",
       " 'sequitur',\n",
       " 'seriogrotesque',\n",
       " 'sesquialter',\n",
       " 'sesquialtera',\n",
       " 'sesquialteral',\n",
       " 'sesquialteran',\n",
       " 'sesquialterous',\n",
       " 'sesquicarbonate',\n",
       " 'sesquicentennial',\n",
       " 'sesquiduplicate',\n",
       " 'sesquihydrate',\n",
       " 'sesquihydrated',\n",
       " 'sesquioctava',\n",
       " 'sesquioctaval',\n",
       " 'sesquipedality',\n",
       " 'sesquiplicate',\n",
       " 'sesquiquadrate',\n",
       " 'sesquiquarta',\n",
       " 'sesquiquartal',\n",
       " 'sesquiquartile',\n",
       " 'sesquiquinta',\n",
       " 'sesquiquintal',\n",
       " 'sesquiquintile',\n",
       " 'sesquisalt',\n",
       " 'sesquiseptimal',\n",
       " 'sesquisextal',\n",
       " 'sesquisilicate',\n",
       " 'sesquisulphate',\n",
       " 'sesquisulphuret',\n",
       " 'sesquiterpene',\n",
       " 'sesquitertia',\n",
       " 'sesquitertial',\n",
       " 'sesquitertian',\n",
       " 'sesquitertianal',\n",
       " 'sobriquet',\n",
       " 'sobriquetical',\n",
       " 'somniloquent',\n",
       " 'spheroquartic',\n",
       " 'squalodontidae',\n",
       " 'squamatine',\n",
       " 'squamipennate',\n",
       " 'squamipinnate',\n",
       " 'squamoepithelial',\n",
       " 'squamoparietal',\n",
       " 'squamosoimbricated',\n",
       " 'squamosoparietal',\n",
       " 'squamosoradiate',\n",
       " 'squaretail',\n",
       " 'squatinidae',\n",
       " 'squatinoidei',\n",
       " 'squattiness',\n",
       " 'squatwise',\n",
       " 'squeezability',\n",
       " 'squiblet',\n",
       " 'squinted',\n",
       " 'squinter',\n",
       " 'squintingness',\n",
       " 'squintness',\n",
       " 'squirelet',\n",
       " 'squiret',\n",
       " 'squirreltail',\n",
       " 'squirter',\n",
       " 'squirtiness',\n",
       " 'squitter',\n",
       " 'stultiloquence',\n",
       " 'stultiloquently',\n",
       " 'suaviloquent',\n",
       " 'subantique',\n",
       " 'subequality',\n",
       " 'subequatorial',\n",
       " 'subequilateral',\n",
       " 'subquestion',\n",
       " 'subquintuple',\n",
       " 'subsequential',\n",
       " 'subsequentially',\n",
       " 'subtriquetrous',\n",
       " 'superacquisition',\n",
       " 'superequivalent',\n",
       " 'superexquisite',\n",
       " 'superexquisitely',\n",
       " 'superexquisiteness',\n",
       " 'superinquisitive',\n",
       " 'superrequirement',\n",
       " 'supersesquitertial',\n",
       " 'supraquantivalence',\n",
       " 'supraquantivalent',\n",
       " 'tanquelinian',\n",
       " 'technique',\n",
       " 'techniquer',\n",
       " 'tequila',\n",
       " 'tequistlateca',\n",
       " 'tequistlatecan',\n",
       " 'thymoquinone',\n",
       " 'titanesque',\n",
       " 'titianesque',\n",
       " 'toluquinaldine',\n",
       " 'totaquine',\n",
       " 'tourniquet',\n",
       " 'tranquilize',\n",
       " 'tranquilizer',\n",
       " 'tranquillize',\n",
       " 'tranquilness',\n",
       " 'transequatorial',\n",
       " 'triequal',\n",
       " 'triptyque',\n",
       " 'triquetra',\n",
       " 'triquetral',\n",
       " 'triquetric',\n",
       " 'triquetrous',\n",
       " 'triquetrously',\n",
       " 'triquetrum',\n",
       " 'triquinate',\n",
       " 'trisquare',\n",
       " 'turquoise',\n",
       " 'turquoiseberry',\n",
       " 'turquoiselike',\n",
       " 'ubiquitariness',\n",
       " 'ubiquitousness',\n",
       " 'unacquaintable',\n",
       " 'unacquaintance',\n",
       " 'unacquainted',\n",
       " 'unacquaintedly',\n",
       " 'unacquaintedness',\n",
       " 'unacquiescent',\n",
       " 'unacquittable',\n",
       " 'unacquitted',\n",
       " 'unacquittedness',\n",
       " 'unantiquated',\n",
       " 'unantiquatedness',\n",
       " 'unantique',\n",
       " 'unconsequential',\n",
       " 'unconsequentially',\n",
       " 'unconsequentialness',\n",
       " 'uncoquettish',\n",
       " 'uncoquettishly',\n",
       " 'undisquieted',\n",
       " 'unequality',\n",
       " 'unequatorial',\n",
       " 'unequestrian',\n",
       " 'unequilateral',\n",
       " 'unequilibrated',\n",
       " 'unequitable',\n",
       " 'unequitableness',\n",
       " 'unequitably',\n",
       " 'unequivalent',\n",
       " 'uniequivalent',\n",
       " 'uninquisitive',\n",
       " 'uninquisitively',\n",
       " 'uninquisitiveness',\n",
       " 'unliquidatable',\n",
       " 'unliquidated',\n",
       " 'unpicturesque',\n",
       " 'unpicturesquely',\n",
       " 'unpicturesqueness',\n",
       " 'unqualitied',\n",
       " 'unquantified',\n",
       " 'unquantitative',\n",
       " 'unquarantined',\n",
       " 'unquestionability',\n",
       " 'unquestionable',\n",
       " 'unquestionableness',\n",
       " 'unquestionably',\n",
       " 'unquestionate',\n",
       " 'unquestioned',\n",
       " 'unquestionedly',\n",
       " 'unquestionedness',\n",
       " 'unquestioning',\n",
       " 'unquestioningly',\n",
       " 'unquestioningness',\n",
       " 'unquiescent',\n",
       " 'unquiescently',\n",
       " 'unquiet',\n",
       " 'unquietable',\n",
       " 'unquieted',\n",
       " 'unquieting',\n",
       " 'unquietly',\n",
       " 'unquietness',\n",
       " 'unquietude',\n",
       " 'unquilleted',\n",
       " 'unquilted',\n",
       " 'unquittable',\n",
       " 'unquitted',\n",
       " 'unrequisite',\n",
       " 'unrequitable',\n",
       " 'unrequital',\n",
       " 'unrequited',\n",
       " 'unrequitedly',\n",
       " 'unrequitedness',\n",
       " 'unrequitement',\n",
       " 'unrequiter',\n",
       " 'unrequiting',\n",
       " 'unsequential',\n",
       " 'unsquirted',\n",
       " 'untranquilized',\n",
       " 'untranquillize',\n",
       " 'untranquillized',\n",
       " 'vanquishment',\n",
       " 'vauquelinite',\n",
       " 'ventriloqual',\n",
       " 'ventriloqually',\n",
       " 'ventriloque',\n",
       " 'ventriloquial',\n",
       " 'ventriloquially',\n",
       " 'ventriloquism',\n",
       " 'ventriloquist',\n",
       " 'ventriloquistic',\n",
       " 'ventriloquize',\n",
       " 'ventriloquous',\n",
       " 'ventriloquously',\n",
       " 'ventriloquy',\n",
       " 'violaquercitrin',\n",
       " 'whitmanesque']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we've tested with one word, let's time many evaluations to get a sense of how quickly \n",
    "# the current matrix_extraction_option executes\n",
    "# use the timeit() function to evaluate how long, on average, a single matrix operation\n",
    "# takes to complete\n",
    "code_snippet = \"\"\"get_values(wg_id = curr_word_group_id, \n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    wg_id_n_char_matrix_dict = wg_id_n_char_matrix_dict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "total_time = timeit.timeit(code_snippet,\n",
    "              number=n_trials, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006090978999854997"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of seconds per trial\n",
    "total_time / n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# let's sample 10 words of each word length, compute the number of from/parent anagrams\n",
    "# for each word in the sample, compute the min, mean, and max, and apply those values\n",
    "# to the numbers of words by length and multiply accordingly\n",
    "# this will give us very generous upper bound of anagram pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...estimated number of from/to pair word pairs: 209,309,758\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = estimate_total_pairs(word_df = word_df, wg_df = wg_df,\n",
    "                                          n_char_matrix_dict = n_char_matrix_dict,\n",
    "                                           wg_id_n_char_matrix_dict = wg_id_n_char_matrix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 364 words that start with x\n",
      "...finding parent anagrams for x words took 0.09 seconds...\n"
     ]
    }
   ],
   "source": [
    "# initialize counters to count the number of to (child words) from a focal word.\n",
    "# we could do this in post-processing, but the data are already in memory and it's a simple \n",
    "# calculation to make.\n",
    "# we want to minimize the number of trips through our data.\n",
    "\n",
    "# the number of candidate words examined for each focal word\n",
    "\n",
    "# a list to hold the dataframes generated for each letter\n",
    "proc_time_df_list = []\n",
    "\n",
    "# subset the list of leters\n",
    "if letter_subset_list:\n",
    "    letters = letter_subset_list[:]\n",
    "else:\n",
    "    letters = sorted_first_letters\n",
    "\n",
    "anagram_pair_count = 0 \n",
    "# use numpy to pre-allocate an array that will be updated while enumerating. \n",
    "# this eliminates list.append() calls\n",
    "\n",
    "output_list = np.full(shape = (n_possible_anagrams, 2), fill_value = -1,  dtype=int)\n",
    "\n",
    "wg_count = 0\n",
    "\n",
    "for i_cl, curr_letter in enumerate(letters):\n",
    "    # enumerate by each letter\n",
    "    # this isn't absolutely necessary, we could just enumerate by word id, \n",
    "    # but for testing and development, letters are a handy way to chunk up the data. \n",
    "\n",
    "    # this dictionary will store the calculations for each letter\n",
    "    proc_time_dict = {}    \n",
    "    \n",
    "    # the list of words that start with the focal letter     \n",
    "    curr_wg_df = wg_df.loc[wg_df['first_letter'] == curr_letter, :]\n",
    "    \n",
    "    # sort the dataframe by n_chars and letter_selector, if it exists.\n",
    "    # this will cut down on dictionary lookups for matrix_extraction_types 3 and 4.        \n",
    "    curr_wg_df = curr_wg_df.sort_values(by = ['n_chars', 'letter_selector'])        \n",
    "    curr_word_group_id_list = curr_wg_df['word_group_id'].tolist()\n",
    "    \n",
    "    wg_count += len(curr_word_group_id_list)\n",
    "    \n",
    "    n_curr_words = '{:,}'.format(len(curr_wg_df))    \n",
    "    print('...finding parent anagrams for', n_curr_words, 'words that start with', curr_letter)               \n",
    "    \n",
    "    # enumerate by word id, working with integers is faster than words    \n",
    "    for i_wi, word_group_id in enumerate(curr_word_group_id_list):            \n",
    "        # start timing to record processing for each word            \n",
    "        s_time = datetime.datetime.now()\n",
    "        \n",
    "        # get the current word length, from the word id\n",
    "        #to_word, to_word_length, curr_first_letter, clg, clgr = word_dict[word_group_id]   \n",
    "        to_word_length = word_dict[word_group_id][1]               \n",
    "\n",
    "        # get the tuple associated with the word id\n",
    "        # much faster to look up stored values for the hash value than it is to \n",
    "        # only look up if the hash value has changed            \n",
    "        key_hash = wg_id_n_char_matrix_dict[word_group_id]                \n",
    "        # get the possible candidate word_group_ids and char matrix\n",
    "        curr_word_id_index_list, curr_char_matrix = n_char_matrix_dict[key_hash]                                \n",
    "\n",
    "        # how many candidates?\n",
    "        n_possible_words = len(curr_word_id_index_list)\n",
    "\n",
    "        # subtract the curr_test_vector from every row in the matrix\n",
    "        # this produces a new matrix.        \n",
    "        new_word_id = curr_word_id_index_list == word_group_id            \n",
    "        outcome = curr_char_matrix - curr_char_matrix[new_word_id, ]\n",
    "        del new_word_id\n",
    "                        \n",
    "        # compute the score by finding where rows, across all columns, are GTE 0\n",
    "        outcome_indices = np.all(outcome >= 0, axis = 1)\n",
    "        outcome = None        \n",
    "        \n",
    "        # extract anagrams based on same index values\n",
    "        outcome_word_id_list = curr_word_id_index_list[outcome_indices].tolist()\n",
    "            \n",
    "        outcome_indices = None               \n",
    "        \n",
    "        # if the outcome is greater than or equal to zero, then the current word is an\n",
    "        # anagram of the other word    \n",
    "        # a value  >= 0 means that the current word contains the exact same number of focal letters\n",
    "        # mite --> time or miter --> time\n",
    "        # a value >= 1 means that current word contains at least the same number of focal letters\n",
    "        # terminator --> time\n",
    "        # a value of <=-1 means that the current word does not have the \n",
    "        # correct number of letters and is therefore not an anagram.\n",
    "        # trait <> time        \n",
    "\n",
    "        # number of parent words found\n",
    "        n_from_words = len(outcome_word_id_list)\n",
    "\n",
    "        if n_from_words > 1:\n",
    "            \n",
    "            # we have matches\n",
    "            # the focal word   \n",
    "                                    \n",
    "            # enumerate the from/parent words            \n",
    "            new_anagram_pair_count = anagram_pair_count + len(outcome_word_id_list)\n",
    "            # the from words\n",
    "            #print(anagram_pair_count)    \n",
    "            #print(new_anagram_pair_count)\n",
    "            #print(len(outcome_word_id_list))\n",
    "            #print(output_list.shape)\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, 0] = outcome_word_id_list      \n",
    "            \n",
    "            # the to word\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, 1] = word_group_id                                            \n",
    "            \n",
    "            # set the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "                    \n",
    "                \n",
    "        del outcome_word_id_list\n",
    "            \n",
    "        # record the time for the word\n",
    "        e_time = datetime.datetime.now()\n",
    "        p_time = e_time - s_time    \n",
    "        p_time = p_time.total_seconds()\n",
    "\n",
    "        proc_time_dict[word_group_id] = (p_time, n_from_words, n_possible_words)       \n",
    "    \n",
    "    # create a dataframe from the proc_time_dict\n",
    "    proc_time_df = pd.DataFrame.from_dict(data=proc_time_dict, orient='index')\n",
    "    proc_time_df = proc_time_df.reset_index()\n",
    "    proc_time_df.columns = ['word_group_id', 'n_seconds', 'n_from_word_groups', 'n_candidates']                \n",
    "    \n",
    "    # display processing time for the current letter\n",
    "    total_proc_time = round(proc_time_df['n_seconds'].sum(), 2)\n",
    "    print('...finding parent anagrams for', curr_letter, 'words took', total_proc_time, 'seconds...')\n",
    "    \n",
    "    proc_time_df_list.append(proc_time_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape and store output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# truncate the output array to only include indices with a from/to word pair\n",
    "output_indices = np.all(output_list >= 0, axis = 1)\n",
    "output_list = output_list[output_indices, ]\n",
    "del output_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...total anagrams 26,489\n"
     ]
    }
   ],
   "source": [
    "# how many anagram pairs were found?\n",
    "n_total_anagrams = len(output_list)\n",
    "n_total_anagrams_formatted = '{:,}'.format(n_total_anagrams)\n",
    "print('...total anagrams', n_total_anagrams_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## count the number of to words\n",
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "# number of to words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...dropping previous table...\n",
      "...beginning to add anagram word group pairs...\n",
      "...commiting changes: 26,489 records\n",
      "...writing to db took 0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = db_path, db_name = db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 0.0 minutes\n",
      "...total processing time: 0.57 minutes\n"
     ]
    }
   ],
   "source": [
    "store_anagaram_processing_time(output_list=output_list, proc_time_df_list=proc_time_df_list, word_df=word_df,\n",
    "                               wg_df = wg_df,\n",
    "                               matrix_extraction_option = matrix_extraction_option, db_path=db_path,\n",
    "                               db_name=db_name, total_time_start=total_time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
