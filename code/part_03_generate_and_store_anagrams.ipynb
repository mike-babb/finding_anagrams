{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babb.mike@outlook.com\n",
    "# Find anagrams\n",
    "## Part 3: Generate and store the anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom libraries\n",
    "from _run_constants import *\n",
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 5\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "## Testing options\n",
    "# NoneL to include all letters\n",
    "# ['q', 'x'] or a different set of letters to test a specific letter\n",
    "# 'SAMPLE' to take a 10% sample by word length group\n",
    "#letter_subset_list = ['x']\n",
    "#letter_subset_list = 'SAMPLE'\n",
    "letter_subset_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = perf_counter_ns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 1.17 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 1.32 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, \\\n",
    "    word_group_id_list, word_id_list, wchar_matrix = load_input_data(\n",
    "        db_path=rc.db_path, db_name=rc.db_name, \n",
    "        in_file_path=rc.data_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the char_matrix into N sub matrices\n",
    "# See split_matrix() for a more elaborate description. \n",
    "# This function does a lot of things. Effectively, it computes and stores values in the wg_df, and splits the matrix into various components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...enumerating 16,101 records...\n",
      "...1,000 records enumerated...\n",
      "...2,000 records enumerated...\n",
      "...3,000 records enumerated...\n",
      "...4,000 records enumerated...\n",
      "...5,000 records enumerated...\n",
      "...6,000 records enumerated...\n",
      "...7,000 records enumerated...\n",
      "...8,000 records enumerated...\n",
      "...9,000 records enumerated...\n",
      "...10,000 records enumerated...\n",
      "...11,000 records enumerated...\n",
      "...12,000 records enumerated...\n",
      "...13,000 records enumerated...\n",
      "...14,000 records enumerated...\n",
      "...15,000 records enumerated...\n",
      "...16,000 records enumerated...\n",
      "...2,387 sub-matrices created...\n",
      "Total extraction time: 9.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict, p_time = split_matrix(\n",
    "    letter_dict=letter_dict,\n",
    "    word_group_id_list=word_group_id_list,\n",
    "    wg_df=wg_df,\n",
    "    wchar_matrix=wchar_matrix,\n",
    "    n_subset_letters=n_subset_letters,\n",
    "    matrix_extraction_option=matrix_extraction_option\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the total number of from/to word pairs from the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...query execution took: 0.0 seconds...\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = load_possible_anagrams(db_path = rc.db_path, db_name = rc.db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 215,842 words...\n",
      "...found parent anagrams for 10,000 words...\n",
      "...found parent anagrams for 20,000 words...\n",
      "...found parent anagrams for 30,000 words...\n",
      "...found parent anagrams for 40,000 words...\n",
      "...found parent anagrams for 50,000 words...\n",
      "...found parent anagrams for 60,000 words...\n",
      "...found parent anagrams for 70,000 words...\n",
      "...found parent anagrams for 80,000 words...\n",
      "...found parent anagrams for 90,000 words...\n",
      "...found parent anagrams for 100,000 words...\n",
      "...found parent anagrams for 110,000 words...\n",
      "...found parent anagrams for 120,000 words...\n",
      "...found parent anagrams for 130,000 words...\n",
      "...found parent anagrams for 140,000 words...\n",
      "...found parent anagrams for 150,000 words...\n",
      "...found parent anagrams for 160,000 words...\n",
      "...found parent anagrams for 170,000 words...\n",
      "...found parent anagrams for 180,000 words...\n",
      "...found parent anagrams for 190,000 words...\n",
      "...found parent anagrams for 200,000 words...\n",
      "...found parent anagrams for 210,000 words...\n",
      "...found parent anagrams for 215,842 words...\n",
      "...finding parent anagrams for 215,842 words took 175.18 seconds | 2.92 minutes...\n",
      "...truncating output list...\n",
      "...populating the count of to-words...\n",
      "...total anagram pairs: 73,218,235\n"
     ]
    }
   ],
   "source": [
    "proc_time_df, output_list = \\\n",
    "    generate_from_to_word_group_pairs_simple(wg_df=wg_df,\n",
    "                                             n_possible_anagrams=n_possible_anagrams,\n",
    "                                             matrix_extraction_option=matrix_extraction_option,\n",
    "                                             wchar_matrix=wchar_matrix,\n",
    "                                             word_group_id_list=word_group_id_list,\n",
    "                                             n_char_matrix_dict=n_char_matrix_dict,\n",
    "                                             single_letter_matrix_dict=single_letter_matrix_dict,\n",
    "                                             letter_selector_matrix_dict=letter_selector_matrix_dict,\n",
    "                                             nc_ls_matrix_dict=nc_ls_matrix_dict,\n",
    "                                             letter_subset_list=letter_subset_list,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = rc.db_path, db_name = rc.db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...now writing: words_me_05\n"
     ]
    }
   ],
   "source": [
    "store_anagram_processing(proc_time_df = proc_time_df, matrix_extraction_option = matrix_extraction_option, db_path = rc.db_path, db_name = rc.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 175.18 seconds | 2.92 minutes\n",
      "...total processing time: 198.48 seconds | 3.31 minutes\n"
     ]
    }
   ],
   "source": [
    "display_total_processing_time(proc_time_df = proc_time_df, total_time_start = total_time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
