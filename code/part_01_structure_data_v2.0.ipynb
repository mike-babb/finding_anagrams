{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find Anagrams\n",
    "## Part 1: Structure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom, user-defined functions\n",
    "from part_00_file_db_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path and name of input data\n",
    "in_file_path = '/git/finding_anagrams/data/'\n",
    "in_file_name = 'words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the input file path\n",
    "in_fpn = os.path.join(in_file_path, in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to output directories\n",
    "base_output_file_path = '/project/finding_anagrams'\n",
    "data_output_file_path = os.path.join(base_output_file_path, 'data')\n",
    "tabulation_output_file_path = os.path.join(base_output_file_path, 'tabulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data output path\n",
    "if os.path.exists(data_output_file_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(data_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the tabulation output path\n",
    "if os.path.exists(tabulation_output_file_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(tabulation_output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import list of words, shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to load the data\n",
    "# htps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "print('...Reading in list of words...')\n",
    "word_df = pd.read_csv(filepath_or_buffer = in_fpn, sep = ',', header = None, names = ['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first few rows\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words are we working with?\n",
    "n_words = len(word_df)\n",
    "print('...found', '{:,}'.format(n_words), 'words to find anagrams for...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the only column to a string - just to be safe.\n",
    "# 'nan' is a word in the dictionary. nan is an internal python value.\n",
    "# same with 'null'\n",
    "word_df['word'] = word_df['word'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lower case values of the words\n",
    "word_df['lcase'] = word_df['word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hyphens\n",
    "word_df['lcase'] = word_df['lcase'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now drop duplicates, based on the lowercase version of each word\n",
    "word_df = word_df.drop_duplicates('lcase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximately 234K words. That's a lot of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find word length\n",
    "word_df['n_chars'] = word_df['lcase'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first letter of each word\n",
    "word_df['first_letter'] = word_df['lcase'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an id\n",
    "word_df['word_id'] = range(0, len(word_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a hash id to capture the sorted letters in each word\n",
    "# use map() with a lambda function to chain several operations together\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html\n",
    "# as an example of what this is doing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted('example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(sorted('example'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has an example of what this is doing...\n",
    "hash(''.join(sorted('example')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, do this for all 234K words. \n",
    "word_df['hash_id'] = word_df['lcase'].map(lambda x: hash(''.join(sorted(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 234K words, but after sorting the letters in each word, there are about 216K unique words. \n",
    "word_df['hash_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the percentage?\n",
    "word_df['hash_id'].unique().shape[0] / word_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the unique, hashed values\n",
    "word_id_hash_id_df = word_df['hash_id'].drop_duplicates().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a unique id\n",
    "word_id_hash_id_df['word_group_id'] = range(0, len(word_id_hash_id_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_id_hash_id_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary using dictionary comprehension of the hash values using zip\n",
    "# https://docs.python.org/3/library/functions.html#zip\n",
    "hash_id_dict = {hash_id:word_group_id for word_group_id, hash_id in zip(word_id_hash_id_df['word_group_id'], word_id_hash_id_df['hash_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the word group id to the \n",
    "word_df['word_group_id'] = word_df['hash_id'].map(hash_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the hash id, no longer needed\n",
    "word_df = word_df.drop(labels = 'hash_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dictionary comprehension to store the letter\n",
    "# we'll import the letters from string.ascii_lowercase \n",
    "# index of the letter for fast look ups\n",
    "letter_dict = {l:li for li, l in enumerate(string.ascii_lowercase)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list of letters from the string.ascii_lowercase\n",
    "letters = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique letters in each word and then sort those letters\n",
    "word_df['letter_group'] = word_df['lcase'].map(lambda x: ''.join(sorted(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count letter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# several versions of the anagram determination technique require subsetting by letters in each word. \n",
    "# generate those data and use a ranking technique to help with anagram group identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a counter object to count the total occurences of each letter AND\n",
    "# a counter to count the number of words that feature each letter\n",
    "# counters are a special type of dictionary. \n",
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "# very fast\n",
    "total_letter_counter = collections.Counter()\n",
    "single_letter_counter = collections.Counter()\n",
    "\n",
    "# enumerate each word and then each letter\n",
    "for curr_word in word_df['lcase'].to_numpy():\n",
    "    total_letter_counter.update(list(curr_word))\n",
    "\n",
    "for curr_letter_group in word_df['letter_group'].to_numpy():\n",
    "    single_letter_counter.update(list(curr_letter_group))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from the counter object and then order from low to high\n",
    "letter_count_df = pd.DataFrame.from_dict(data=total_letter_counter, orient = 'index', columns = ['total_letter_count']).reset_index(names=['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a' is used 198,359 times. This is different than the number of words that feature the letter a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df['single_letter_count'] = letter_count_df['letter'].map(single_letter_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case, 'a' is featured in 144,511 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the total letter rank and the single_letter_count\n",
    "letter_count_df['total_letter_rank'] = letter_count_df['total_letter_count'].rank(ascending=False).astype(int)\n",
    "letter_count_df['single_letter_rank'] = letter_count_df['single_letter_count'].rank(ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by letter count\n",
    "letter_count_df = letter_count_df.sort_values(by = 'total_letter_count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df['total_letter_percent'] = letter_count_df['total_letter_count'] / letter_count_df['total_letter_count'].sum()\n",
    "# note the denomiantor - we are computing which words have a letter, most words have multiple letters. \n",
    "# two thirds of words feature the letter 'e'. Wow. \n",
    "letter_count_df['single_letter_percent'] = letter_count_df['single_letter_count'] / word_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head(n=26)\n",
    "# 'j' is the least common letter while 'e' is the most common letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# across all words, how many letters are used?\n",
    "letter_count_df['total_letter_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with the count of words that start with a focal letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df = word_df['first_letter'].groupby(word_df['first_letter']).agg(np.size).to_frame(name = 'first_letter_word_count').reset_index(names = ['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df['first_letter_word_percent'] = fl_count_df['first_letter_word_count'] / fl_count_df['first_letter_word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df['first_letter_rank'] = fl_count_df['first_letter_word_count'].rank(ascending = False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins\n",
    "letter_count_df = pd.merge(left=letter_count_df, right = fl_count_df,\n",
    "                          left_on=['letter'], right_on = ['letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the records\n",
    "letter_count_df = letter_count_df.sort_values(by = 'letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "col_names = ['letter',\n",
    "'total_letter_count',\n",
    "'single_letter_count',\n",
    "'first_letter_word_count',\n",
    "'total_letter_percent',\n",
    "'single_letter_percent',\n",
    "'first_letter_word_percent',\n",
    "'total_letter_rank',\n",
    "'single_letter_rank',\n",
    "'first_letter_rank']\n",
    "letter_count_df = letter_count_df[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the letter and its rank into a dictionary \n",
    "# as well as the rank and the corresponding letter\n",
    "# {'k':21, 21:'k'}\n",
    "letter_count_rank_dict = {}\n",
    "for cl, clr in zip(letter_count_df['letter'], letter_count_df['total_letter_rank']):\n",
    "    letter_count_rank_dict[cl] = clr\n",
    "    letter_count_rank_dict[clr] = cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what letter is ranked 21st?\n",
    "letter_count_rank_dict[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the rank of letter k?\n",
    "letter_count_rank_dict['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to order the unique letters in each word by\n",
    "# least common letter to most common letter\n",
    "def get_least_common_letters(x):    \n",
    "    if len(x) == 1:\n",
    "        lcl = x\n",
    "    else:\n",
    "        # ranking of each letter\n",
    "        rank_list = [letter_count_rank_dict[curr_letter] for curr_letter in x]        \n",
    "        # sort the ranking\n",
    "        rank_list = sorted(rank_list, reverse = True)\n",
    "        # generate the letters sorted by rank\n",
    "        rank_list = [letter_count_rank_dict[curr_letter] for curr_letter in rank_list]\n",
    "        lcl = ''.join(rank_list)\n",
    "    return lcl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract letters by ranking\n",
    "word_df['letter_group_ranked'] = word_df['letter_group'].map(get_least_common_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the character matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurences of each letter in each word and store the results in a matrix\n",
    "# populate the char_matrix and the word_id dictionary\n",
    "# Aapply a function to each row in the dataframe\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\n",
    "\n",
    "# Upon intialization, the char_matrix is zero-filled.\n",
    "# Each row in the char_matrix corresponds to a word.\n",
    "# The char_matrix is 26 columns wide. Each column corresponds to a letter.\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# Each cell is a count of the number of times each letter occurs in each word.  \n",
    "# the entry for emit (as do the entriees for time, mite, item) has the following value:\n",
    "# [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "# we need to find all words that have matching rows with at least these values.\n",
    "# for example, 'terminator'.\n",
    "# ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "# [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# the zero-filled matrix will be populated once the \n",
    "# fill_char_matrix() function is applied to the word_df\n",
    "char_matrix = np.zeros(shape=(len(word_df), 26), dtype=int)\n",
    "def fill_char_matrix(row):\n",
    "    # get a word from the current row\n",
    "    curr_word = row['lcase']    \n",
    "    ri = row['word_id'] # row index / word index    \n",
    "    # populate the char matrix\n",
    "    for i_letter, letter in enumerate(curr_word):\n",
    "        if letter in letter_dict:\n",
    "            # find the corresponding column index of that letter\n",
    "            li = letter_dict[letter]\n",
    "            # increment the count of letters in the current row and current column\n",
    "            char_matrix[ri, li] += 1\n",
    "    return None\n",
    "\n",
    "# catch the output from the function and delete\n",
    "output = word_df.apply(fill_char_matrix, 1)\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# what does it look like?\n",
    "char_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many letters are in use in our words?\n",
    "char_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# across all words, how many letters are used?\n",
    "letter_count_df['total_letter_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we wanted to see how many times the letter 'e' is used?\n",
    "char_matrix[:, 4].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same as:\n",
    "total_letter_counter['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the percentage of characters that feature the letter 'e'?\n",
    "char_matrix[:, 4].sum() / char_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the char matrix to compute how many words have the letter 'a' in them or the letter 's'. \n",
    "# this is different than the number of times each letter is used\n",
    "# we can save this to our dataframe\n",
    "single_letter_count = []\n",
    "for curr_letter, letter_index in letter_dict.items():    \n",
    "    outcome = np.where(char_matrix[:, letter_index] > 0)\n",
    "    n_rows = np.shape(outcome)[1]        \n",
    "    print(curr_letter, n_rows)\n",
    "    single_letter_count.append(n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the same values as:\n",
    "letter_count_df[['letter', 'single_letter_count']].head(n = 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and save the word_group dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates based on the word group. \n",
    "# by default, this will only keep the first record and it will drop all others\n",
    "wg_df = word_df.drop_duplicates(subset = ['word_group_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_group_counter = collections.Counter(word_df['word_group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['word_group_count'] = wg_df['word_group_id'].map(word_group_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data to disk - first the char matrix and the letter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the char matrix\n",
    "output_name = 'char_matrix.npy'\n",
    "opn = os.path.join(data_output_file_path, output_name)\n",
    "np.save(file = opn, arr = char_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter dictionary\n",
    "output_name = 'letter_dict.pkl'\n",
    "save_pickle(file_path = data_output_file_path, file_name = output_name, obj = letter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word df to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_sqlite(df = word_df, table_name = 'words', db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_sqlite(df = wg_df, table_name = 'word_groups', db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, the word / letter count\n",
    "write_data_to_sqlite(df = letter_count_df, table_name = 'letter_count', db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
