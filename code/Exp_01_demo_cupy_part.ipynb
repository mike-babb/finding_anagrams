{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966bc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we find parent/child word relationships faster\n",
    "# One way to achieve this is to use the GPU via cupy\n",
    "# cupy is basically numpy on the gpu. Let's start with a simple case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fa58d5-75a5-41ea-8943-ebae8f18d273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from time import perf_counter_ns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ce83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom libraries\n",
    "from _run_constants import *\n",
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbee031",
   "metadata": {},
   "source": [
    "# Load input data\n",
    "The char_matrix and the formatted words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247235e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 2.04 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 1.93 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, \\\n",
    "    word_group_id_list, word_id_list, wchar_matrix = load_input_data(\n",
    "        db_path=rc.DB_PATH, db_name=rc.DB_NAME,\n",
    "        in_file_path=rc.IN_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff2e4d",
   "metadata": {},
   "source": [
    "# let's process 1000 rows using a single lookup on the full wchar_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b36966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...query execution took: 0.01 seconds...\n"
     ]
    }
   ],
   "source": [
    "# load the total number of anagrams\n",
    "n_possible_anagrams = load_possible_anagrams(db_path=rc.DB_PATH,\n",
    "                                             db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25610500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'198,842,245'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{n_possible_anagrams :,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f806b2",
   "metadata": {},
   "source": [
    "# Using the CPU\n",
    "Create a data extraction scenario that is very similar to Matrix Extraction Technique 1: Using the full matrix. I remove the excess code and create a simple loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb82534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "truncating list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(367672, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1000 rows\n",
    "n_samples = 1000\n",
    "sample_wg_id = wg_df['word_group_id'].sample(n = n_samples, random_state = 42).to_list()\n",
    "\n",
    "# let's add a specific word: acanthology - the study of spines (as of sea urchins) especially as an adjunct of taxonomy\n",
    "# this is to ensure that extraction technique produces the correct values\n",
    "# On a complete run, there should by 26 parent words and 329 child words\n",
    "# This will find the 26 parent words, and depending on what else in the sample,\n",
    "# a number of child words\n",
    "\n",
    "if 746 not in sample_wg_id:\n",
    "    sample_wg_id.append(746)    \n",
    "\n",
    "# create an output object\n",
    "output_list = np.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "row_count = 0\n",
    "anagram_pair_count = 0\n",
    "\n",
    "for i_wg_id, wg_id in enumerate(sample_wg_id):\n",
    "    # identify parent words\n",
    "    outcome = wchar_matrix - wchar_matrix[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = np.all(outcome >= 0, axis=1)    \n",
    "\n",
    "    n_from_words = outcome_indices.sum()\n",
    "\n",
    "    if n_from_words >= 1:\n",
    "        # extract anagrams based on index values    \n",
    "        outcome_word_id_list = word_group_id_list[outcome_indices]    \n",
    "\n",
    "        # we have matches\n",
    "        # the focal word\n",
    "        curr_output_list = np.zeros(shape=(n_from_words, 2), dtype=int)\n",
    "\n",
    "        # update the output list with the word_id_list - these are from/parent words\n",
    "        curr_output_list[:, 0] = outcome_word_id_list\n",
    "\n",
    "        # update with the word_id - this is the to/child word\n",
    "        curr_output_list[:, 1] = wg_id\n",
    "\n",
    "        # enumerate the from/parent words\n",
    "        new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "        output_list[anagram_pair_count:new_anagram_pair_count,\n",
    "                    :] = curr_output_list\n",
    "\n",
    "        # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "        #intermediate_to_word_count.update(outcome_word_id_list.tolist())\n",
    "\n",
    "        # set the anagram pair count\n",
    "        anagram_pair_count = new_anagram_pair_count\n",
    "    \n",
    "    row_count += 1\n",
    "\n",
    "    if row_count % 100 == 0:\n",
    "        print(row_count)\n",
    "print('truncating list')\n",
    "output_indices = np.all(output_list >= 0, axis=1)\n",
    "output_list = output_list[output_indices,]\n",
    "del output_indices\n",
    "output_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bf651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximately 43 seconds\n",
    "from_word_counter = collections.Counter(output_list[:,1])\n",
    "to_word_counter = collections.Counter(output_list[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7663cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of from word groups\n",
    "# so, this technique is correct\n",
    "from_word_counter[746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeed954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a similar workflow, using CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74d835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac9c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bade31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb43301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4412a91e",
   "metadata": {},
   "source": [
    "# build a selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248af44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the matrix, gather the values for each split, and then combine\n",
    "n_subset_letters = 3\n",
    "wg_df[\"letter_selector\"] = wg_df[\"letter_group_ranked\"].str[:n_subset_letters]\n",
    "\n",
    "letter_selector_list = wg_df[\"letter_selector\"].unique()\n",
    "letter_selector_list.sort()\n",
    "letter_selector_id_dict = {ls: i_ls for i_ls, ls in enumerate(letter_selector_list)}\n",
    "\n",
    "wg_df[\"letter_selector_id\"] = wg_df[\"letter_selector\"].map(letter_selector_id_dict)\n",
    "# here's the thing: I need to be able to identify on a single matrix the rows that match various conditions.\n",
    "# I can't step through it and create objects at abandon. \n",
    "# so, given our wchar_matrix: what are the rows that match to such and such?\n",
    "# we can add three columns to track this... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load letter ranks\n",
    "sql = 'select letter, total_letter_rank from letter_count;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = query_db(sql = sql, db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09152a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dict = {l:r for l, r in zip(lr_df['letter'], lr_df['total_letter_rank'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d678aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['n_records'] = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a891d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['letter_selector_id', 'letter_selector', 'n_records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ac54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = wg_df[col_names].groupby(col_names[:-1]).agg(ls_count = ('n_records', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79512a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df['ls_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df['ls_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ls_index(ls:str):\n",
    "    return [letter_dict[l] for l in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46577b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is effectively a column selector\n",
    "ls_df['ls_index'] = ls_df['letter_selector'].map(get_ls_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_anagrams = load_possible_anagrams(db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output list\n",
    "output_list = np.full(shape = (n_possible_anagrams, 2), fill_value=-1)\n",
    "output_time_list = []\n",
    "\n",
    "# start counting\n",
    "anagram_pair_count = 0\n",
    "\n",
    "#for ls_id_index in range(0, 10):\n",
    "for ls_row_id, ls_row in ls_df.iloc[:None].iterrows():    \n",
    "    if ls_row_id % 100 == 0:\n",
    "        print(ls_row_id)\n",
    "    start_time = perf_counter_ns()\n",
    "    \n",
    "    # get letter selector id information\n",
    "    ls_id = ls_row['letter_selector_id']\n",
    "    ls_id_index = np.array(ls_row['ls_index'])    \n",
    "\n",
    "    ##\n",
    "    # BUILD A COLUMN SELECTOR\n",
    "    ##\n",
    "    # make sure that only values GTE 0 are selected so that the right number of\n",
    "    # columns are return.\n",
    "    #curr_ls_id = ls_id_index[ls_id_index >= 0]\n",
    "    \n",
    "    ##\n",
    "    # SUBSET THE wchar_matrix by column selector\n",
    "    ##    \n",
    "    outcome_indices = np.all(wchar_matrix[:, ls_id_index] >= 1, axis=1)\n",
    "    \n",
    "    # this is the sub-matrix from which to query\n",
    "    ls_wchar_matrix = wchar_matrix[outcome_indices, :]\n",
    "        \n",
    "    # this is the list of word group ids that correspond to the word group ids\n",
    "    # in the ls_wchar_matrix\n",
    "    temp_wg_id_list = word_group_id_list[outcome_indices]\n",
    "    # place into a dictionary to go from wg_id to wg_index. What is the index\n",
    "    # of wg_id 675?\n",
    "    # wg_id_dict = {wg_id:wg_index for wg_index, wg_id in enumerate(temp_wg_id_list)}\n",
    "\n",
    "    # this is the number of word groups that meet certain criteria. \n",
    "    # for example, words that feature the letters: 'bro'    \n",
    "    n_search_space = temp_wg_id_list.shape[0]\n",
    "        \n",
    "    #def my_func(row):\n",
    "    #    return temp_wg_id_list[np.all(a = (ls_wchar_matrix - ls_wchar_matrix[row, :]) >= 0, axis = 1)]\n",
    "\n",
    "    #for ii in range(0, ls_wchar_matrix.shape[0]):    \n",
    "    #for i_curr_wg_id, curr_wg_id in enumerate(temp_wg_id_list):\n",
    "    # the current list of words featuring the set of least common letters.\n",
    "    # these are the words have the least common letters of 'bro'    \n",
    "    curr_wg_id_list = wg_df.loc[wg_df['letter_selector_id'] == ls_id, 'word_group_id'].to_numpy()\n",
    "    # n_lookups = curr_wg_id_list.shape[0]\n",
    "    # n_search_space >= n_lookups, always. \n",
    "    for i_curr_wg_id, curr_wg_id in enumerate(curr_wg_id_list):\n",
    "    \n",
    "        \n",
    "        #temp_wg_id = wg_id_dict[curr_wg_id]\n",
    "        temp_wg_id = np.where(temp_wg_id_list == curr_wg_id)[0][0]\n",
    "        #print(curr_wg_id, temp_wg_id)\n",
    "\n",
    "        #outcome_word_id_list = my_func(row = temp_wg_id)\n",
    "        outcome_word_id_list = temp_wg_id_list[np.all(a = (ls_wchar_matrix - ls_wchar_matrix[temp_wg_id, :]) >= 0, axis = 1)]\n",
    "                \n",
    "        n_from_words = outcome_word_id_list.shape[0]\n",
    "        \n",
    "        if n_from_words > 0:\n",
    "            outcome_word_id_list = format_output_list(outcome_word_id_list=outcome_word_id_list, wg_id=curr_wg_id)\n",
    "            #print(outcome_word_id_list.shape)\n",
    "            \n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "            #print(anagram_pair_count, new_anagram_pair_count)\n",
    "\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, :] = outcome_word_id_list\n",
    "\n",
    "            # update the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "\n",
    "    curr_time = calc_time(time_start=start_time, round_digits=8)\n",
    "    output_time_list.append([ls_id, n_search_space, curr_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59105ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timing_and_output_objects(output_time_list:list, ls_df:pd.DataFrame):\n",
    "    \n",
    "    col_names =['letter_selector_id', 'n_search_space', 'curr_time']\n",
    "    time_df = pd.DataFrame(data = output_time_list, columns=col_names)\n",
    "    get_hms(seconds = time_df['curr_time'].sum(),round_seconds_digits=4)\n",
    "    # join in the other information\n",
    "    time_df = pd.merge(left = time_df, right = ls_df)\n",
    "\n",
    "    time_df['avg_lookup_time'] = time_df['curr_time'] / (time_df['ls_count'] * time_df['n_search_space'])\n",
    "\n",
    "    return time_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = build_timing_and_output_objects(output_time_list=output_time_list,\n",
    "                                          ls_df = ls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['n_search_space'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['ls_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['avg_lookup_time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...truncating output list...')\n",
    "output_indices = np.all(output_list >= 0, axis=1)\n",
    "output_list = output_list[output_indices,]\n",
    "output_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6071d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...building output counters...')\n",
    "from_word_counter = collections.Counter(output_list[:,1])\n",
    "to_word_counter = collections.Counter(output_list[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfacedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the word 'acanthology', with word_group_id 746 is in the counter\n",
    "print(from_word_counter[746])\n",
    "print(to_word_counter[746])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dba3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12643b41",
   "metadata": {},
   "source": [
    "# Do it with CUPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b68f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def my_func(a):\n",
    "    return cp.sqrt(cp.sum(a**2, axis=-1))\n",
    "\n",
    "a = cp.random.random((256, 1024))\n",
    "print(benchmark(my_func, (a,), n_repeat=20))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0030046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some gpu stats\n",
    "start_gpu = cp.cuda.Event()\n",
    "end_gpu = cp.cuda.Event()\n",
    "\n",
    "start_gpu.record()\n",
    "start_cpu = time.perf_counter()\n",
    "out = my_func(a)\n",
    "end_cpu = time.perf_counter()\n",
    "end_gpu.record()\n",
    "end_gpu.synchronize()\n",
    "t_gpu = cp.cuda.get_elapsed_time(start_gpu, end_gpu)\n",
    "t_cpu = end_cpu - start_cpu\n",
    "print(t_gpu, t_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc5074",
   "metadata": {},
   "source": [
    "## create cupy objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_matrix_cp = cp.asarray(a = char_matrix)\n",
    "word_group_id_list_cp = cp.asarray(a = word_group_id_list)\n",
    "word_id_list = cp.asarray(a = word_id_list)\n",
    "wchar_matrix_cp = cp.asarray(a = wchar_matrix)\n",
    "word_group_id_list_cp = cp.asarray(a = word_group_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the naive approach\n",
    "# establish counters for record keeping\n",
    "# sample 1000 rows\n",
    "n_samples = 1000\n",
    "sample_wg_id = wg_df['word_group_id'].sample(n = n_samples, random_state = 42)\n",
    "# sample_wg_id = wg_df['word_group_id'].to_numpy()\n",
    "sample_wg_id_cp = cp.asarray(a = sample_wg_id)\n",
    "\n",
    "output_list_cp = cp.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "row_count = 0\n",
    "anagram_pair_count = 0\n",
    "intermediate_to_word_count = collections.Counter()\n",
    "\n",
    "for wg_id in sample_wg_id_cp:\n",
    "    outcome = wchar_matrix_cp - wchar_matrix_cp[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices_cp = cp.all(outcome >= 0, axis=1)\n",
    "    outcome = None\n",
    "\n",
    "    n_from_words = outcome_indices_cp.sum()   \n",
    "            \n",
    "    \n",
    "    if n_from_words >= 1:\n",
    "        # extract anagrams based on index values    \n",
    "        outcome_word_id_list_cp = word_group_id_list_cp[outcome_indices_cp]    \n",
    "\n",
    "        # we have matches\n",
    "        curr_output_list_cp = cp.zeros(shape=(outcome_word_id_list_cp.shape[0], 2), dtype=int)\n",
    "\n",
    "        # update the output list with the word_id_list - these are from/parent words\n",
    "        curr_output_list_cp[:, 0] = outcome_word_id_list_cp\n",
    "\n",
    "        # update with the word_id - this is the to/child word\n",
    "        curr_output_list_cp[:, 1] = wg_id\n",
    "\n",
    "        # enumerate the from/parent wordsds\n",
    "        new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "        # update the total output list\n",
    "        output_list_cp[anagram_pair_count:new_anagram_pair_count,\n",
    "                    :] = curr_output_list_cp\n",
    "\n",
    "        # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "        intermediate_to_word_count.update(outcome_word_id_list_cp.tolist())\n",
    "\n",
    "        # set the anagram pair count\n",
    "        anagram_pair_count = new_anagram_pair_count\n",
    "    \n",
    "    row_count += 1\n",
    "\n",
    "    if row_count % 10000 == 0:\n",
    "        print(row_count)\n",
    "\n",
    "print('truncating list')\n",
    "output_indices_cp = cp.all(output_list_cp >= 0, axis=1)\n",
    "output_list_cp = output_list_cp[output_indices_cp,]\n",
    "del output_indices_cp\n",
    "print(output_list_cp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24751dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output_list_cp(outcome_word_id_list: cp.ndarray, wg_id: int) -> cp.ndarray:\n",
    "        \n",
    "    output_list = cp.zeros(shape=(outcome_word_id_list.shape[0], 2), dtype=int)\n",
    "\n",
    "    # update the output list with the word_id_list - these are from/parent words\n",
    "    output_list[:, 0] = outcome_word_id_list\n",
    "    \n",
    "\n",
    "    # update with the word_id - this is the to/child word\n",
    "    output_list[:, 1] = wg_id\n",
    "\n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc45f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output list\n",
    "output_list_cp = cp.full(shape = (n_possible_anagrams, 2), fill_value=-1)\n",
    "output_time_list = []\n",
    "\n",
    "# start counting\n",
    "anagram_pair_count = 0\n",
    "\n",
    "#for ls_id_index in range(0, 10):\n",
    "for ls_row_id, ls_row in ls_df.iloc[:100].iterrows():    \n",
    "    if ls_row_id % 100 == 0:\n",
    "        print(ls_row_id)\n",
    "    start_time = perf_counter_ns()\n",
    "    \n",
    "    # get letter selector id information\n",
    "    ls_id = ls_row['letter_selector_id']\n",
    "    #ls_id_index = cp.array(ls_row['ls_index'])    \n",
    "    ls_id_index = ls_row['ls_index']\n",
    "\n",
    "    ##\n",
    "    # BUILD A COLUMN SELECTOR\n",
    "    ##\n",
    "    # make sure that only values GTE 0 are selected so that the right number of\n",
    "    # columns are return.\n",
    "    #curr_ls_id = ls_id_index[ls_id_index >= 0]\n",
    "    \n",
    "    ##\n",
    "    # SUBSET THE wchar_matrix by column selector\n",
    "    ##    \n",
    "    outcome_indices_cp = cp.all(wchar_matrix_cp[:, ls_id_index] >= 1, axis=1)\n",
    "    \n",
    "    # this is the sub-matrix from which to query\n",
    "    ls_wchar_matrix_cp = wchar_matrix_cp[outcome_indices_cp, :]\n",
    "        \n",
    "    # this is the list of word group ids that correspond to the word group ids\n",
    "    # in the ls_wchar_matrix\n",
    "    temp_wg_id_list_cp = word_group_id_list_cp[outcome_indices_cp]\n",
    "    # place into a dictionary to go from wg_id to wg_index. What is the index\n",
    "    # of wg_id 675?\n",
    "    # wg_id_dict = {wg_id:wg_index for wg_index, wg_id in enumerate(temp_wg_id_list)}\n",
    "\n",
    "    # this is the number of word groups that meet certain criteria. \n",
    "    # for example, words that feature the letters: 'bro'    \n",
    "    n_search_space = temp_wg_id_list_cp.shape[0]\n",
    "        \n",
    "    #def my_func(row):\n",
    "    #    return temp_wg_id_list[np.all(a = (ls_wchar_matrix - ls_wchar_matrix[row, :]) >= 0, axis = 1)]\n",
    "\n",
    "    #for ii in range(0, ls_wchar_matrix.shape[0]):    \n",
    "    #for i_curr_wg_id, curr_wg_id in enumerate(temp_wg_id_list):\n",
    "    # the current list of words featuring the set of least common letters.\n",
    "    # these are the words have the least common letters of 'bro'    \n",
    "    curr_wg_id_list = wg_df.loc[wg_df['letter_selector_id'] == ls_id, 'word_group_id'].to_list()\n",
    "    # n_lookups = curr_wg_id_list.shape[0]\n",
    "    # n_search_space >= n_lookups, always. \n",
    "    for i_curr_wg_id, curr_wg_id in enumerate(curr_wg_id_list):    \n",
    "        \n",
    "        #temp_wg_id = wg_id_dict[curr_wg_id]\n",
    "        temp_wg_id = cp.where(temp_wg_id_list_cp == curr_wg_id)[0][0]\n",
    "        #print(curr_wg_id, temp_wg_id)\n",
    "\n",
    "        #outcome_word_id_list = my_func(row = temp_wg_id)\n",
    "        outcome_word_id_list_cp = temp_wg_id_list_cp[cp.all(a = (ls_wchar_matrix_cp - ls_wchar_matrix_cp[temp_wg_id, :]) >= 0, axis = 1)]\n",
    "                \n",
    "        n_from_words = outcome_word_id_list_cp.shape[0]\n",
    "        \n",
    "        if n_from_words > 0:\n",
    "            outcome_word_id_list = format_output_list_cp(outcome_word_id_list=outcome_word_id_list_cp, wg_id=curr_wg_id)\n",
    "            #print(outcome_word_id_list.shape)\n",
    "            \n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "            #print(anagram_pair_count, new_anagram_pair_count)\n",
    "\n",
    "            output_list_cp[anagram_pair_count:new_anagram_pair_count, :] = outcome_word_id_list\n",
    "\n",
    "            # update the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "\n",
    "    curr_time = calc_time(time_start=start_time, round_digits=8)\n",
    "    output_time_list.append([ls_id, n_search_space, curr_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2fb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names =['letter_selector_id', 'n_search_space', 'curr_time']\n",
    "time_df = pd.DataFrame(data = output_time_list, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03285ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hms(seconds = time_df['curr_time'].sum(),round_seconds_digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join in the other information\n",
    "time_df = pd.merge(left = time_df, right = ls_df)\n",
    "time_df['n_search_space'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...truncating output list...')\n",
    "output_indices_cp = cp.all(output_list_cp >= 0, axis=1)\n",
    "output_list_cp = output_list_cp[output_indices_cp,]\n",
    "\n",
    "output_list_cp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_word_counter = collections.Counter(cp.asnumpy(output_list_cp)[:,1])\n",
    "to_word_counter = collections.Counter(cp.asnumpy(output_list_cp)[:,0])\n",
    "\n",
    "# check to see if the word 'acanthology', with word_group_id 746 is in the counter\n",
    "print(from_word_counter[746])\n",
    "print(to_word_counter[746])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4d0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be5aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799174d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
