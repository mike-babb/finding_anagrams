{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "from time import perf_counter_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 5\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "## Testing options\n",
    "# NoneL to include all letters\n",
    "# ['q', 'x'] or a different set of letters to test a specific letter\n",
    "# 'SAMPLE' to take a 10% sample by word length group\n",
    "#letter_subset_list = ['x']\n",
    "letter_subset_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = perf_counter_ns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 1.34 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 1.32 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, word_group_id_list, word_id_list, wchar_matrix = load_input_data(db_path = db_path, db_name = db_name, in_file_path = in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the char_matrix into N sub matrices\n",
    "# See split_matrix() for a more elaborate description. \n",
    "# This function does a lot of things. Effectively, it computes and stores values in the wg_df, and splits the matrix into various components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...enumerating 16,101 records...\n",
      "...1,000 records enumerated...\n",
      "...2,000 records enumerated...\n",
      "...3,000 records enumerated...\n",
      "...4,000 records enumerated...\n",
      "...5,000 records enumerated...\n",
      "...6,000 records enumerated...\n",
      "...7,000 records enumerated...\n",
      "...8,000 records enumerated...\n",
      "...9,000 records enumerated...\n",
      "...10,000 records enumerated...\n",
      "...11,000 records enumerated...\n",
      "...12,000 records enumerated...\n",
      "...13,000 records enumerated...\n",
      "...14,000 records enumerated...\n",
      "...15,000 records enumerated...\n",
      "...16,000 records enumerated...\n",
      "...2,387 sub-matrices created...\n",
      "Total extraction time: 9.15 seconds.\n"
     ]
    }
   ],
   "source": [
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict= split_matrix(\n",
    "        letter_dict = letter_dict,\n",
    "        word_group_id_list = word_group_id_list,\n",
    "            wg_df = wg_df,\n",
    "        wchar_matrix = wchar_matrix, \n",
    "        n_subset_letters = n_subset_letters,\n",
    "        matrix_extraction_option=matrix_extraction_option\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# estimate_total_pairs() estimates the total number of from/to word pairs\n",
    "# the reason for estimating the upper bound is that it is both just interesting \n",
    "# to know but it also means that we can use the estimated values to allocate an \n",
    "# object in memory as opposed to incrementally appending to a list - this is faster\n",
    "# the object in memory is a NumPy Array that will store integers: from word group id | to word group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...estimated number of from/to pair word pairs: 194,572,272\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = estimate_total_pairs(wg_df = wg_df, letter_selector_matrix_dict = letter_selector_matrix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 215,842 words...\n",
      "...found parent anagrams for 10,000 words...\n",
      "...found parent anagrams for 20,000 words...\n",
      "...found parent anagrams for 30,000 words...\n",
      "...found parent anagrams for 40,000 words...\n",
      "...found parent anagrams for 50,000 words...\n",
      "...found parent anagrams for 60,000 words...\n",
      "...found parent anagrams for 70,000 words...\n",
      "...found parent anagrams for 80,000 words...\n",
      "...found parent anagrams for 90,000 words...\n",
      "...found parent anagrams for 100,000 words...\n",
      "...found parent anagrams for 110,000 words...\n",
      "...found parent anagrams for 120,000 words...\n",
      "...found parent anagrams for 130,000 words...\n",
      "...found parent anagrams for 140,000 words...\n",
      "...found parent anagrams for 150,000 words...\n",
      "...found parent anagrams for 160,000 words...\n",
      "...found parent anagrams for 170,000 words...\n",
      "...found parent anagrams for 180,000 words...\n",
      "...found parent anagrams for 190,000 words...\n",
      "...found parent anagrams for 200,000 words...\n",
      "...found parent anagrams for 210,000 words...\n",
      "...found parent anagrams for 215,842 words...\n",
      "...finding parent anagrams for 215,842 words took 150.47 seconds | 2.51 minutes...\n",
      "...truncating output list...\n",
      "...populating the count of to-words...\n",
      "...total anagram pairs: 73,179,245\n"
     ]
    }
   ],
   "source": [
    "proc_time_df, output_list = \\\n",
    "    generate_from_to_word_group_pairs_simple(wg_df = wg_df,                                      \n",
    "                                      n_possible_anagrams = n_possible_anagrams,\n",
    "                                      matrix_extraction_option = matrix_extraction_option,\n",
    "                                                   wchar_matrix = wchar_matrix,\n",
    "                                                   word_group_id_list = word_group_id_list,\n",
    "                                                   n_char_matrix_dict = n_char_matrix_dict,\n",
    "                                                   single_letter_matrix_dict = single_letter_matrix_dict,\n",
    "                                                   letter_selector_matrix_dict = letter_selector_matrix_dict,\n",
    "                                                   nc_ls_matrix_dict = nc_ls_matrix_dict,\n",
    "                                             letter_subset_list = letter_subset_list,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = db_path, db_name = db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...now writing: words_me_05\n"
     ]
    }
   ],
   "source": [
    "store_anagram_processing(proc_time_df = proc_time_df, matrix_extraction_option = matrix_extraction_option, db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 150.47 seconds | 2.51 minutes\n",
      "...total processing time: 206.0 seconds | 3.43 minutes\n"
     ]
    }
   ],
   "source": [
    "display_total_processing_time(proc_time_df = proc_time_df, total_time_start = total_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
