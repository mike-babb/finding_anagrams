{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 5\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "# set to None to include all letters\n",
    "# test with a subset of letters by setting the letter_subset_list to ['q', 'x'] or \n",
    "# a different set of letters\n",
    "letter_subset_list = ['x']\n",
    "# letter_subset_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 1.877372 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 1.416619 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, word_group_id_list, word_id_list, wchar_matrix = load_input_data(db_path = db_path, db_name = db_name, in_file_path = in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the char_matrix into N sub matrices\n",
    "# See split_matrix() for a more elaborate description. \n",
    "# This function does a lot of things. Effectively, it computes and stores values in the wg_df, and splits the matrix into various components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...enumerating 16,101 records...\n",
      "...1,000 records enumerated...\n",
      "...2,000 records enumerated...\n",
      "...3,000 records enumerated...\n",
      "...4,000 records enumerated...\n",
      "...5,000 records enumerated...\n",
      "...6,000 records enumerated...\n",
      "...7,000 records enumerated...\n",
      "...8,000 records enumerated...\n",
      "...9,000 records enumerated...\n",
      "...10,000 records enumerated...\n",
      "...11,000 records enumerated...\n",
      "...12,000 records enumerated...\n",
      "...13,000 records enumerated...\n",
      "...14,000 records enumerated...\n",
      "...15,000 records enumerated...\n",
      "...16,000 records enumerated...\n",
      "...2,387 sub-matrices created...\n",
      "Total extraction time: 11.69 seconds.\n"
     ]
    }
   ],
   "source": [
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict= split_matrix(\n",
    "        letter_dict = letter_dict,\n",
    "        word_group_id_list = word_group_id_list,\n",
    "            wg_df = wg_df,\n",
    "        wchar_matrix = wchar_matrix, \n",
    "        n_subset_letters = n_subset_letters,\n",
    "        matrix_extraction_option=matrix_extraction_option\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# estimate_total_pairs() estimates the total number of from/to word pairs\n",
    "# the reason for estimating the upper bound is that it is both just interesting \n",
    "# to know but it also means that we can use the estimated values to allocate an \n",
    "# object in memory as opposed to incrementally appending to a list - this is faster\n",
    "# the object in memory is a NumPy Array that will store integers: from word group id | to word group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...estimated number of from/to pair word pairs: 194,572,272\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = estimate_total_pairs(wg_df = wg_df, letter_selector_matrix_dict = letter_selector_matrix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we want to santize the inputs? no.\n",
    "# that is beyond the scope of this. \n",
    "# little bobby tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 364 words...\n",
      "...found parent anagrams for 364 words...\n",
      "...finding parent anagrams for 364 words took 0.0683 seconds | 0.0011 minutes...\n",
      "...truncating output list...\n",
      "...populating the count of to-words...\n",
      "...total anagram pairs: 26,489\n"
     ]
    }
   ],
   "source": [
    "proc_time_df, output_list, processed_word_id = \\\n",
    "    generate_from_to_word_group_pairs_simple(wg_df = wg_df,                                      \n",
    "                                      n_possible_anagrams = n_possible_anagrams,\n",
    "                                      matrix_extraction_option = matrix_extraction_option,\n",
    "                                                   wchar_matrix = wchar_matrix,\n",
    "                                                   word_group_id_list = word_group_id_list,\n",
    "                                                   n_char_matrix_dict = n_char_matrix_dict,\n",
    "                                                   single_letter_matrix_dict = single_letter_matrix_dict,\n",
    "                                                   letter_selector_matrix_dict = letter_selector_matrix_dict,\n",
    "                                                   nc_ls_matrix_dict = nc_ls_matrix_dict,\n",
    "                                             letter_subset_list = letter_subset_list,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>n_seconds</th>\n",
       "      <th>n_from_word_groups</th>\n",
       "      <th>n_to_word_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_group_id  n_seconds  n_from_word_groups  n_to_word_groups\n",
       "0         214131        0.0                   2                 7\n",
       "1         214139        0.0                   4                12\n",
       "2         214208        0.0                   1                 5\n",
       "3         214209        0.0                   2                12\n",
       "4         214211        0.0                   1                 4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>word_group_count</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>first_letter_id</th>\n",
       "      <th>single_letter_id</th>\n",
       "      <th>letter_selector_id</th>\n",
       "      <th>nc_ls_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>5394</td>\n",
       "      <td>5305</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>1</td>\n",
       "      <td>la</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>1</td>\n",
       "      <td>lai</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3    all    all        3            a     5394           5305           al   \n",
       "4  aalii  aalii        5            a        3              3          ail   \n",
       "\n",
       "  letter_group_ranked  word_group_count letter_selector  first_letter_id  \\\n",
       "0                   a                 1               a                0   \n",
       "1                   a                 1               a                0   \n",
       "2                  la                 2              la                0   \n",
       "3                  la                 1              la                0   \n",
       "4                 lai                 1             lai                0   \n",
       "\n",
       "   single_letter_id  letter_selector_id  nc_ls_id  \n",
       "0                 0                   0         0  \n",
       "1                 0                   0         1  \n",
       "2                11                1081         2  \n",
       "3                11                1081         2  \n",
       "4                11                1083         3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = db_path, db_name = db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have three dataframes: wg_df, word_df, and proc_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_time_df, word_df = format_anagaram_processing(proc_time_df = proc_time_df,                                                   \n",
    "                                                   word_df = word_df,\n",
    "                                                   wg_df = wg_df,\n",
    "                                                   processed_word_id=processed_word_id,                                                   \n",
    "                                                   matrix_extraction_option = matrix_extraction_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2024 02 22: all that we need for the word_df is the word_id, word_group_id, and the word_processed variable. \n",
    "# this stuff is stored elsewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...now writing: words_me_05\n",
      "...now writing: words_processed_me_05\n"
     ]
    }
   ],
   "source": [
    "store_anagram_processing(proc_time_df = proc_time_df, word_df = word_df, matrix_extraction_option = matrix_extraction_option, db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 0.0683 seconds | 0.0011 minutes\n",
      "...total processing time: 24.207409 seconds | 0.4 minutes\n"
     ]
    }
   ],
   "source": [
    "display_total_processing_time(proc_time_df = proc_time_df, total_time_start = total_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
