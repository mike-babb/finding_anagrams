{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# Option 1: Full matrix\n",
    "# Option 2: Word-length\n",
    "# Option 3: First letter\n",
    "# Option 4: Single-least common letter\n",
    "# Option 5: n least common letters\n",
    "# Option 6: word-length and n least common letters\n",
    "\n",
    "matrix_extraction_option = 6\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# options 5 and 6. More letters means more sub-matrices\n",
    "# 3 seems to be the sweet spot\n",
    "n_subset_letters = 3\n",
    "\n",
    "# set write_data to True to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "# set to None to include all letters\n",
    "# test with a subset of letters by setting the letter_subset_list to ['q', 'x'] or \n",
    "# a different set of letters\n",
    "letter_subset_list = ['x']\n",
    "# letter_subset_list = None\n",
    "\n",
    "# generate a sample dataset of ten words that start with each letter\n",
    "\n",
    "# testo = wg_df.groupby(['first_letter']).sample(n = 10, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading words into a dataframe...\n",
      "...query execution took: 2.131913 seconds...\n",
      "...loading word groups into a dataframe...\n",
      "...query execution took: 2.21272 seconds...\n",
      "...loading the letter dictionary...\n",
      "...loading the char matrix...\n",
      "...subsetting the char matrix...\n"
     ]
    }
   ],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, word_group_id_list, word_id_list, wchar_matrix = load_input_data(db_path = db_path, db_name = db_name, in_file_path = in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the char_matrix into N sub matrices\n",
    "# See split_matrix() for a more elaborate description. \n",
    "# This function does a lot of things. Effectively, it computes and stores values in the wg_df, and splits the matrix into various components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...creating 16,101 sub-matrices...\n",
      "...1,000 sub-matrices created...\n",
      "...2,000 sub-matrices created...\n",
      "...3,000 sub-matrices created...\n",
      "...4,000 sub-matrices created...\n",
      "...5,000 sub-matrices created...\n",
      "...6,000 sub-matrices created...\n",
      "...7,000 sub-matrices created...\n",
      "...8,000 sub-matrices created...\n",
      "...9,000 sub-matrices created...\n",
      "...10,000 sub-matrices created...\n",
      "...11,000 sub-matrices created...\n",
      "...12,000 sub-matrices created...\n",
      "...13,000 sub-matrices created...\n",
      "...14,000 sub-matrices created...\n",
      "...15,000 sub-matrices created...\n",
      "...16,000 sub-matrices created...\n",
      "... 16,101 sub-matrices created...\n",
      "Total extraction time: 101.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "wg_df, n_char_matrix_dict, single_letter_matrix_dict, letter_selector_matrix_dict, nc_ls_matrix_dict= split_matrix(\n",
    "    letter_dict = letter_dict,\n",
    "    word_group_id_list = word_group_id_list,\n",
    "        wg_df = wg_df,\n",
    "    wchar_matrix = wchar_matrix, \n",
    "    n_subset_letters = n_subset_letters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# demonstrate the different matrix extraction options with the word 'achiever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_word = 'achiever'\n",
    "\n",
    "wg_id = word_df.loc[word_df['lcase'] == demo_word, 'word_group_id'].iloc[0]\n",
    "\n",
    "demo_wg_df = wg_df.loc[wg_df['word_group_id'] == wg_id, : ]\n",
    "\n",
    "# option 1 - Full matrix\n",
    "# No additional data needed\n",
    "\n",
    "# option 2 -  Number of characters\n",
    "n_char = demo_wg_df['n_chars'].iloc[0]\n",
    "\n",
    "# option 3 - First letter\n",
    "first_letter = demo_wg_df['first_letter'].iloc[0]\n",
    "\n",
    "# option 4 - Least common letter\n",
    "least_common_letter = demo_wg_df['letter_selector'].iloc[0][0]\n",
    "\n",
    "# option 5 - Multiple least common letters\n",
    "letter_selector = demo_wg_df['letter_selector'].iloc[0]\n",
    "\n",
    "# option 6 - Number of characters and multiple least common letters\n",
    "nc_ls_tuple = demo_wg_df['nc_ls_tuple'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the full matrix: option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the full matrix selection\n",
    "output = get_values_full_matrix(wg_id = wg_id, \n",
    "                    wchar_matrix = wchar_matrix,\n",
    "                   word_group_id_list = word_group_id_list)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by word-length: option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the n char selection\n",
    "output = get_values_n_char(wg_id = wg_id,\n",
    "                      n_char = n_char,\n",
    "                      n_char_matrix_dict = n_char_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the first letter: option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the single least common letter: option 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo the first letter selection\n",
    "output = get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter,\n",
    "                                                           single_letter_matrix_dict = single_letter_matrix_dict)         \n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by the letter selector: option 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo with the letter selector\n",
    "output = get_values_letter_selector(wg_id = wg_id,\n",
    "                      letter_selector = letter_selector,\n",
    "                      letter_selector_matrix_dict = letter_selector_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select on the matrices split by word-length and the letter selector: option 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 parent/from word groups for the word achiever\n",
      "There are 46 parent/from words for the word achiever\n",
      "The first five words are:\n",
      "1348               achiever\n",
      "12440          archdeceiver\n",
      "12445         archdetective\n",
      "12624          architective\n",
      "12737    archrepresentative\n",
      "Name: lcase, dtype: object\n",
      "The last five words are:\n",
      "224512       urethrovesical\n",
      "225856        vaucheriaceae\n",
      "225857       vaucheriaceous\n",
      "227047    vibrotherapeutics\n",
      "233655       zepharovichite\n",
      "Name: lcase, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo with the n_char letter selector\n",
    "output = get_values_n_char_letter_selector(wg_id = wg_id,\n",
    "                           nc_ls_tuple = nc_ls_tuple,                           \n",
    "                           nc_ls_matrix_dict=nc_ls_matrix_dict)\n",
    "\n",
    "# this is an array of from words to the word 'achiever'\n",
    "format_demo_output(demo_word = demo_word,\n",
    "                   word_df = word_df,\n",
    "                   demo_output = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Selection Option 1: Selecting by full matrix\n",
      "Total time: 0.3654 seconds. Average time: 0.036536 seconds.\n",
      "Matrix Selection Option 2: Selecting by word length\n",
      "Total time: 0.2404 seconds. Average time: 0.02404 seconds.\n",
      "Matrix Selection Option 3: Selecting by first letter\n",
      "Total time: 0.2647 seconds. Average time: 0.026469 seconds.\n",
      "Matrix Selection Option 4: Selecting by single least common letter\n",
      "Total time: 0.0315 seconds. Average time: 0.003146 seconds.\n",
      "Matrix Selection Option 5: Selecting by letter selector\n",
      "Total time: 0.0011 seconds. Average time: 0.000106 seconds.\n",
      "Matrix Selection Option 6: Selecting by word length and letter selector\n",
      "Total time: 0.0018 seconds. Average time: 0.000177 seconds.\n"
     ]
    }
   ],
   "source": [
    "# we've tested with one word, let's time many evaluations to get a sense of how quickly \n",
    "# the different matrix extraction options work\n",
    "# use the timeit() function to evaluate how long, on average, a single matrix operation\n",
    "# takes to complete\n",
    "\n",
    "n_trials = 10\n",
    "\n",
    "code_snippet_dict = {\n",
    "    'Matrix Selection Option 1: Selecting by full matrix':\n",
    "\"\"\"get_values_full_matrix(wg_id = wg_id, wchar_matrix = wchar_matrix, word_group_id_list = word_group_id_list)\"\"\",\n",
    "    'Matrix Selection Option 2: Selecting by word length':\n",
    "\"\"\"get_values_n_char(wg_id = wg_id, n_char = n_char, n_char_matrix_dict = n_char_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 3: Selecting by first letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter = first_letter, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",    \n",
    "    'Matrix Selection Option 4: Selecting by single least common letter':\n",
    "\"\"\"get_values_single_letter(wg_id = wg_id, single_letter = least_common_letter, single_letter_matrix_dict = single_letter_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 5: Selecting by letter selector':\n",
    "\"\"\"get_values_letter_selector(wg_id = wg_id, letter_selector = letter_selector, letter_selector_matrix_dict = letter_selector_matrix_dict)\"\"\",\n",
    "    'Matrix Selection Option 6: Selecting by word length and letter selector':\n",
    "\"\"\"get_values_n_char_letter_selector(wg_id = wg_id, nc_ls_tuple = nc_ls_tuple, nc_ls_matrix_dict=nc_ls_matrix_dict)\"\"\"\n",
    "}\n",
    "\n",
    "for csd, cs in code_snippet_dict.items():\n",
    "    \n",
    "    total_time = timeit.timeit(cs, number=n_trials, globals=globals())\n",
    "\n",
    "    # total time    \n",
    "    total_time_formatted = '{:,}'.format(round(total_time, 4))    \n",
    "\n",
    "    # average time\n",
    "    avg_time = total_time / n_trials\n",
    "    avg_time_formatted = '{:,}'.format(round(avg_time, 6)) \n",
    "        \n",
    "    print(csd)\n",
    "    # average number of seconds per trial\n",
    "    print('Total time:', total_time_formatted, 'seconds. Average time:', avg_time_formatted, 'seconds.')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the combination of the word length and letter selector is the fastest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# estimate_total_pairs estimates the total number of from/to word pairs\n",
    "# the reason for estimating the upper bound is that it is both just interesting \n",
    "# to know but it also means that we can use the estimated values to an allocate an \n",
    "# object in memory as opposed to incrementally appending to a list\n",
    "# the object in memory is a NumPy Array that will store integers: from word group id | to word group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...estimated number of from/to pair word pairs: 194,572,272\n"
     ]
    }
   ],
   "source": [
    "n_possible_anagrams = estimate_total_pairs(wg_df = wg_df, nc_ls_matrix_dict = nc_ls_matrix_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word group id pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 364 words that start with x\n",
      "...finding parent anagrams for x words took 0.32 seconds...\n",
      "...total anagrams: 26,489\n",
      "...total anagram discovery time: 0.323 seconds\n"
     ]
    }
   ],
   "source": [
    "proc_time_df, output_list = \\\n",
    "    generate_from_to_word_group_pairs(wg_df = wg_df,\n",
    "                                      letter_subset_list = letter_subset_list,\n",
    "                                      n_possible_anagrams = n_possible_anagrams,\n",
    "                                      matrix_extraction_option = matrix_extraction_option,\n",
    "                                                   wchar_matrix = wchar_matrix,\n",
    "                                                   word_group_id_list = word_group_id_list,\n",
    "                                                   n_char_matrix_dict = n_char_matrix_dict,\n",
    "                                                   single_letter_matrix_dict = single_letter_matrix_dict,\n",
    "                                                   letter_selector_matrix_dict = letter_selector_matrix_dict,\n",
    "                                                   nc_ls_matrix_dict = nc_ls_matrix_dict\n",
    "                                     \n",
    "                                     \n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "    store_anagram_pairs(output_list = output_list, db_path = db_path, db_name = db_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have three dataframes: wg_df, word_df, and proc_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_time_df, word_df = format_anagaram_processing(output_list = output_list, \n",
    "                                                   proc_time_df = proc_time_df,\n",
    "                                                   word_df = word_df,\n",
    "                                                   wg_df = wg_df,\n",
    "                                                   matrix_extraction_option = matrix_extraction_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_anagram_processing(proc_time_df = proc_time_df, word_df = word_df, matrix_extraction_option = matrix_extraction_option, db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 0.323 seconds | 0.0054 minutes\n",
      "...total processing time: 6.8 minutes\n"
     ]
    }
   ],
   "source": [
    "display_total_processing_time(proc_time_df = proc_time_df, total_time_start = total_time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
