{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 5: Generate a graph of word relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import csv\n",
    "import os\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part_00_process_functions import build_db_conn, query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database path and name\n",
    "db_path = '/project/anagrams/db'\n",
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = '/project/anagrams/data'\n",
    "output_file_name = 'sample_graph.gexf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofpn = os.path.join(output_file_path, output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select lcase, word_id from words;'\n",
    "word_df = query_db(sql=sql, db_path = db_path, db_name = db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is now stored in our the db table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_word_list = ['it', 'tie', 'item', 'mite', 'time', 'emit', 'rite', 'terminator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dictionary comprehension to create a very fast lookup table\n",
    "word_id_dict = {}\n",
    "for word, word_id in zip(word_df['lcase'], word_df['word_id']):\n",
    "    word_id_dict[word] = word_id \n",
    "    word_id_dict[word_id] = word    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_word_id_list = [word_id_dict[focal_word] for focal_word in focal_word_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load 'from' words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parent words\n",
    "sql = 'select from_word_id, to_word_id from anagrams where to_word_id = (?);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent words\n",
    "pw_df_list = []\n",
    "for focal_word_id in focal_word_id_list:\n",
    "    pw_df = query_db(sql = sql, db_path = db_path, db_name = db_name, params = (focal_word_id,))\n",
    "    pw_df_list.append(pw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df = pd.concat(pw_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the parent words\n",
    "pw_df['from_word'] = pw_df['from_word_id'].map(word_id_dict)\n",
    "pw_df['to_word'] = pw_df['to_word_id'].map(word_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load 'to' words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get child words\n",
    "sql = 'select from_word_id, to_word_id from anagrams where from_word_id = (?);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df_list = []\n",
    "for focal_word_id in focal_word_id_list:\n",
    "    cw_df = query_db(sql = sql, db_path = db_path, db_name = db_name, params = (focal_word_id,))    \n",
    "    cw_df_list.append(cw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df = pd.concat(cw_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_df['from_word'] = cw_df['from_word_id'].map(word_id_dict)\n",
    "cw_df['to_word'] = cw_df['to_word_id'].map(word_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatente\n",
    "anagram_df = pd.concat([pw_df, cw_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_df = anagram_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of edges:\n",
    "len(anagram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nodes?\n",
    "my_set = set(anagram_df['from_word'].unique().tolist()).union(anagram_df['to_word'].unique().tolist()                                                             )\n",
    "len(my_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### focus only on a few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's focus on just our words of interest\n",
    "anagram_df = anagram_df.loc[anagram_df['from_word_id'].isin(focal_word_id_list), ]\n",
    "anagram_df = anagram_df.loc[anagram_df['to_word_id'].isin(focal_word_id_list), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create and save graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed graph using networkx\n",
    "# https://networkx.org/\n",
    "my_graph = nx.from_pandas_edgelist(df=anagram_df,source = 'from_word',\n",
    "                                    target = 'to_word', create_using = nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk as a GEXF for visualization in Gephi\n",
    "# https://gephi.org/\n",
    "nx.write_gexf(G=my_graph, path = ofpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('analysis': conda)",
   "language": "python",
   "name": "python37664bitanalysisconda9de0f707a5a443ea87ec25563936da81"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
