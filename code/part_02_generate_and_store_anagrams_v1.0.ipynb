{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mike Babb\n",
    "# babbm@uw.edu\n",
    "# Find anagrams\n",
    "## Part 2: Generate and store the anagrams v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries - installed by default\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import sqlite3\n",
    "import string\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries - not installed by default\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from part_00_process_functions import load_pickle, build_db_conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base file path\n",
    "base_file_path = '/project/finding_anagrams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path\n",
    "in_file_path = 'data'\n",
    "in_file_path = os.path.join(base_file_path, in_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output db path and name\n",
    "db_path = 'db'\n",
    "db_path = os.path.join(base_file_path, db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'words.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a sqlite3 database connection and cursor object\n",
    "db_path_name = os.path.join(db_path, db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process control flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to perform matrix opertions and determine from/to and exact anagram relationships\n",
    "# option 1 - work with the full char_matrix\n",
    "# option 2 - create submatrices by word length\n",
    "# option 3 - create submatrices by word length and letter\n",
    "# option 4 - create submatrices by word length and least common two letters\n",
    "\n",
    "matrix_extraction_option = 4\n",
    "\n",
    "# max number of letters to slice to use for the generation of sub-matrices for\n",
    "# option 4. More letters means more sub-matrices\n",
    "n_common_letters = 3\n",
    "\n",
    "# set write_data to true to store the generated list of anagrams\n",
    "write_data = False\n",
    "\n",
    "# set to None to include all letters\n",
    "# test with a subset of letters by setting the letter_subset_list to ['q', 'x'] or \n",
    "# a different set of letters\n",
    "#letter_subset_list = ['q', 'x', 's']\n",
    "letter_subset_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a timer to record the entire operation\n",
    "total_time_start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the word_df, the words from Part 1\n",
    "input_file_name = 'word_df.csv'\n",
    "# build the file path\n",
    "ipn = os.path.join(in_file_path, input_file_name)\n",
    "\n",
    "# specify the datatypes of the columns using a dictionary\n",
    "# because NA and NULL are reserved python words, but also words in our list of words,\n",
    "# we need to specify the data types of the columns\n",
    "dtype_dict = {'word': str,\n",
    "              'lcase': str,\n",
    "              'n_chars': int,\n",
    "              'first_letter': str,\n",
    "              'word_id': int,\n",
    "              'word_group_id': int,\n",
    "              'letter_group': str,\n",
    "              'letter_group_ranked': str}\n",
    "\n",
    "# read in the file and be careful of the NA and NULL values\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "word_df = pd.read_csv(filepath_or_buffer = ipn, sep = '\\t',header = 0,\n",
    "                          dtype=dtype_dict, na_values = '!!', keep_default_na=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>letters_sorted</th>\n",
       "      <th>letters_ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234365</th>\n",
       "      <td>zythem</td>\n",
       "      <td>zythem</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234365</td>\n",
       "      <td>215837</td>\n",
       "      <td>ehmtyz</td>\n",
       "      <td>zyhmte</td>\n",
       "      <td>ehmtyz</td>\n",
       "      <td>zyhmte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234366</th>\n",
       "      <td>Zythia</td>\n",
       "      <td>zythia</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234366</td>\n",
       "      <td>215838</td>\n",
       "      <td>ahityz</td>\n",
       "      <td>zyhtai</td>\n",
       "      <td>ahityz</td>\n",
       "      <td>zyhtai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234367</th>\n",
       "      <td>zythum</td>\n",
       "      <td>zythum</td>\n",
       "      <td>6</td>\n",
       "      <td>z</td>\n",
       "      <td>234367</td>\n",
       "      <td>215839</td>\n",
       "      <td>hmtuyz</td>\n",
       "      <td>zyhmut</td>\n",
       "      <td>hmtuyz</td>\n",
       "      <td>zyhmut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234368</th>\n",
       "      <td>Zyzomys</td>\n",
       "      <td>zyzomys</td>\n",
       "      <td>7</td>\n",
       "      <td>z</td>\n",
       "      <td>234368</td>\n",
       "      <td>215840</td>\n",
       "      <td>mosyz</td>\n",
       "      <td>zymso</td>\n",
       "      <td>mosyyzz</td>\n",
       "      <td>zzyymso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234369</th>\n",
       "      <td>Zyzzogeton</td>\n",
       "      <td>zyzzogeton</td>\n",
       "      <td>10</td>\n",
       "      <td>z</td>\n",
       "      <td>234369</td>\n",
       "      <td>215841</td>\n",
       "      <td>egnotyz</td>\n",
       "      <td>zgytnoe</td>\n",
       "      <td>egnootyzzz</td>\n",
       "      <td>zzzgytnooe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word       lcase  n_chars first_letter  word_id  word_group_id  \\\n",
       "234365      zythem      zythem        6            z   234365         215837   \n",
       "234366      Zythia      zythia        6            z   234366         215838   \n",
       "234367      zythum      zythum        6            z   234367         215839   \n",
       "234368     Zyzomys     zyzomys        7            z   234368         215840   \n",
       "234369  Zyzzogeton  zyzzogeton       10            z   234369         215841   \n",
       "\n",
       "       letter_group letter_group_ranked letters_sorted letters_ranked  \n",
       "234365       ehmtyz              zyhmte         ehmtyz         zyhmte  \n",
       "234366       ahityz              zyhtai         ahityz         zyhtai  \n",
       "234367       hmtuyz              zyhmut         hmtuyz         zyhmut  \n",
       "234368        mosyz               zymso        mosyyzz        zzyymso  \n",
       "234369      egnotyz             zgytnoe     egnootyzzz     zzzgytnooe  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the column of word ids as a numpy array\n",
    "word_id_list = word_df['word_id'].to_numpy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the letters sorted by the frequency of words that\n",
    "# start with a particular letter\n",
    "agg_word_df = word_df['first_letter'].groupby(word_df['first_letter']).agg(np.size).to_frame()\n",
    "\n",
    "# set column names\n",
    "agg_word_df.columns = ['word_count']\n",
    "\n",
    "# reset the index to rename columns\n",
    "agg_word_df = agg_word_df.reset_index()\n",
    "\n",
    "# sort the dataframe by frequency\n",
    "agg_word_df = agg_word_df.sort_values(by='word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>y</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>z</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v</td>\n",
       "      <td>3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w</td>\n",
       "      <td>3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>6228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>6771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>6836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>o</td>\n",
       "      <td>7830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r</td>\n",
       "      <td>9613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>10849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>10963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>12513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t</td>\n",
       "      <td>12853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u</td>\n",
       "      <td>16361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>16974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>19783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p</td>\n",
       "      <td>24341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>24929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_letter  word_count\n",
       "23            x         380\n",
       "24            y         663\n",
       "25            z         942\n",
       "16            q        1148\n",
       "9             j        1603\n",
       "10            k        2239\n",
       "21            v        3418\n",
       "22            w        3910\n",
       "11            l        6228\n",
       "13            n        6742\n",
       "6             g        6771\n",
       "5             f        6836\n",
       "14            o        7830\n",
       "4             e        8703\n",
       "8             i        8786\n",
       "7             h        8992\n",
       "17            r        9613\n",
       "3             d       10849\n",
       "1             b       10963\n",
       "12            m       12513\n",
       "19            t       12853\n",
       "20            u       16361\n",
       "0             a       16974\n",
       "2             c       19783\n",
       "15            p       24341\n",
       "18            s       24929"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_word_df.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the letters sorted by word frequency\n",
    "sorted_first_letters = agg_word_df['first_letter'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the letter dictionary from part 1\n",
    "in_file_name = 'letter_dict.pkl'\n",
    "letter_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the word dictionary from part 1\n",
    "in_file_name = 'word_dict.pkl'\n",
    "word_dict = load_pickle(in_file_path = in_file_path, in_file_name=in_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the char matrix from part 1\n",
    "in_file_name = 'char_matrix.npy'\n",
    "ipn = os.path.join(in_file_path, in_file_name)\n",
    "char_matrix = np.load(file = ipn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract sub-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>letters_sorted</th>\n",
       "      <th>letters_ranked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>aal</td>\n",
       "      <td>laa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>aaiil</td>\n",
       "      <td>laaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "      <td>aam</td>\n",
       "      <td>maa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked letters_sorted letters_ranked  \n",
       "0                   a              a              a  \n",
       "1                   a             aa             aa  \n",
       "2                  la            aal            laa  \n",
       "3                 lai          aaiil          laaii  \n",
       "4                  ma            aam            maa  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 does not take advantage of submatrices. Options 2, 3, and 4 do.\n",
    "\n",
    "# the dictionary holding the sub-matrices\n",
    "n_char_matrix_dict = {}\n",
    "\n",
    "# by word length\n",
    "word_length_list = sorted(word_df['n_chars'].unique().tolist())\n",
    "\n",
    "# python dictionaries work by storing the hash values of objects\n",
    "# Anything that can be hashed can be a dictionary key. \n",
    "# Computing the hash value of an object ahead of time can reduce dictionary access time.\n",
    "# we'll compute the associated hash value of the tuple used to identify the sub-matrices.\n",
    "\n",
    "word_id_n_char_matrix_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# BUILD OUT SUBMATRICES FOR OPTION 2\n",
    "####\n",
    "# Create submatrices based on the words with at least the same length as the focal word\n",
    "if matrix_extraction_option == 2:\n",
    "    loop_count = 0\n",
    "    s_time = datetime.datetime.now()\n",
    "    n_sub_matrices = len(word_length_list)\n",
    "    print('...creating', n_sub_matrices, 'sub matrices')\n",
    "        \n",
    "    for i_nchars, n_chars in enumerate(word_length_list):\n",
    "        # word id by character length\n",
    "        curr_n_char_word_id_list  = word_df.loc[word_df['n_chars']>=n_chars, 'word_id'].to_numpy()\n",
    "        \n",
    "        #curr_n_char_word_id_list = curr_df['word_id']\n",
    "        curr_char_matrix = char_matrix[curr_n_char_word_id_list, ]\n",
    "                \n",
    "        # use an empty string to form a consistent dictionary key \n",
    "        # across matrix_extraction_options\n",
    "        key_value = (n_chars, '')\n",
    "        key_value_hash = hash(key_value)\n",
    "        n_char_matrix_dict[key_value_hash] = (curr_n_char_word_id_list, curr_char_matrix)        \n",
    "    \n",
    "    # store the tuple in the word_df\n",
    "    word_df['word_id_n_char_matrix_key'] = word_df['n_chars'].map(lambda x: (x, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...creating 16101 sub matrices\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# BUILD OUT SUBMATRICES FOR OPTIONS 3 OR 4. \n",
    "####\n",
    "if matrix_extraction_option in (3,4):\n",
    "    loop_count = 0\n",
    "    s_time = datetime.datetime.now()\n",
    "    if matrix_extraction_option == 3:\n",
    "        # by word length and first letter\n",
    "        word_df['letter_selector'] = word_df['first_letter']\n",
    "    else:   \n",
    "        # by word length and n least common letters\n",
    "        word_df['letter_selector'] = word_df['letter_group_ranked'].str[:n_common_letters]\n",
    "    \n",
    "    # store the tuple in the word_df\n",
    "    # we have to use tuples because tuples are immutable - once created, they cannot be changed\n",
    "    #https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences    \n",
    "    word_df['word_id_n_char_matrix_key'] = tuple(zip(word_df['n_chars'], word_df['letter_selector']))\n",
    "    \n",
    "    # This is a combinatorial problem.\n",
    "    # Limit the number of selections we need to make    \n",
    "    letter_selector_df = word_df[['n_chars', 'letter_selector']].drop_duplicates()\n",
    "    n_sub_matrices = len(letter_selector_df)\n",
    "    print('...creating', n_sub_matrices, 'sub matrices')\n",
    "    # this means n_sub_matrices are queried.\n",
    "    # we can expedite this by only selecting certain word ids once, converting to a set,\n",
    "    # and then storing that set based on the selection criteria.\n",
    "    # many words are going to have the same least common characters, let's identify the\n",
    "    # corresponding rows accordingly\n",
    "    \n",
    "    letter_selector_list = letter_selector_df['letter_selector'].unique().tolist()\n",
    "    n_char_word_id_list_dict = {}\n",
    "    ls_word_id_list_dict = {}\n",
    "    \n",
    "    for n_chars, letter_selector in zip(letter_selector_df['n_chars'], letter_selector_df['letter_selector']):\n",
    "        \n",
    "        # word id set by character length\n",
    "        if n_chars in n_char_word_id_list_dict:\n",
    "            # get the set if it already exists\n",
    "            curr_n_char_word_id_set = n_char_word_id_list_dict[n_chars]\n",
    "        else:\n",
    "            # create the set if it does not exist\n",
    "            curr_n_char_word_id_set = word_df.loc[(word_df['n_chars']>=n_chars) , 'word_id'].tolist()\n",
    "            curr_n_char_word_id_set = set(curr_n_char_word_id_set)\n",
    "            n_char_word_id_list_dict[n_chars] = curr_n_char_word_id_set\n",
    "\n",
    "        # word id by letter selector\n",
    "        if letter_selector in ls_word_id_list_dict:\n",
    "            # get the set if it already exists\n",
    "            curr_letter_select_word_id_set = ls_word_id_list_dict[letter_selector]\n",
    "        else:\n",
    "            # the set needs to be computed\n",
    "            # build the oolumn selector using list comprehension\n",
    "            column_selector = [letter_dict[curr_letter] for curr_letter in letter_selector]\n",
    "            \n",
    "            # create a true-false matrix where only certain columns, corresponding to\n",
    "            # letter indices, have a value of 1 or more\n",
    "            outcome = char_matrix[:, column_selector] > 0    \n",
    "        \n",
    "            # which rows in the above matrix evaluate to all True\n",
    "            outcome_indices = np.all(a = outcome, axis = 1)\n",
    "        \n",
    "            # these indices match with the word_id_list, extract the subset        \n",
    "            curr_letter_select_word_id_set = word_id_list[outcome_indices]\n",
    "            curr_letter_select_word_id_set = set(curr_letter_select_word_id_set)\n",
    "            ls_word_id_list_dict[letter_selector] = curr_letter_select_word_id_set\n",
    "            \n",
    "        # the set intersection of the curr_n_char_word_id_set and the\n",
    "        # curr_letter_select_word_id_set are indices that feature a word of at\n",
    "        # least a certain length and the characters of interest\n",
    "        outcome_word_id_set = curr_n_char_word_id_set.intersection(curr_letter_select_word_id_set)\n",
    "        # convert the set to an array\n",
    "        outcome_word_id_list = np.array(list(outcome_word_id_set))\n",
    "        \n",
    "        # subset the char_matrix to get the sub matrix\n",
    "        curr_char_matrix = char_matrix[outcome_word_id_list, ]\n",
    "\n",
    "        # now, store that in the sub matrix dictionary\n",
    "        key_value = (n_chars, letter_selector)\n",
    "        key_value_hash = hash(key_value)\n",
    "        n_char_matrix_dict[key_value_hash] = (outcome_word_id_list, curr_char_matrix)\n",
    "        \n",
    "        # simple progress display\n",
    "        loop_count += 1\n",
    "        if loop_count % 100 == 0:\n",
    "            print(loop_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...sub-matrix extraction took 41.32 seconds...\n"
     ]
    }
   ],
   "source": [
    "if matrix_extraction_option != 1:    \n",
    "    # populate the key_hash_field and then the word_id_n_char_matrix_dict\n",
    "    # the word_id and the hashed (word_length, letters of interest) tuple are stored\n",
    "    # in a dictionary to expedite comparison. This is a quick way to go from one id to another.    \n",
    "    word_df['word_id_n_char_matrix_key_hash'] = word_df['word_id_n_char_matrix_key'].map(hash)\n",
    "    for curr_word_id, curr_key_hash in zip(word_df['word_id'], word_df['word_id_n_char_matrix_key_hash']):\n",
    "        word_id_n_char_matrix_dict[curr_word_id] = curr_key_hash\n",
    "            \n",
    "    e_time = datetime.datetime.now()\n",
    "    p_time = e_time - s_time\n",
    "    # how long did this pre-processing take?\n",
    "    p_time = round(p_time.total_seconds(), 2)\n",
    "    print('...sub-matrix extraction took', p_time, 'seconds...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234370"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_id_n_char_matrix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine what we've created, for processing options 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_focal_word = 'orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130834\n",
      "-2736852336467197552\n",
      "(13408,)\n",
      "(13408, 26)\n"
     ]
    }
   ],
   "source": [
    "if matrix_extraction_option in (3,4):\n",
    "    temp_focal_word_id = word_df.loc[word_df['lcase']==temp_focal_word, 'word_id'].iloc[0]\n",
    "    # the ID of the focal word\n",
    "    print(temp_focal_word_id)\n",
    "    # the hash corresponding to the tuple of the candidate word ids and the sub-matrix\n",
    "    temp_focal_word_hash_id = word_id_n_char_matrix_dict[temp_focal_word_id]\n",
    "    print(temp_focal_word_hash_id)\n",
    "    # the candidate word ids and the sub matrix\n",
    "    temp_word_id_list, temp_sub_matrix = n_char_matrix_dict[temp_focal_word_hash_id]\n",
    "    print(temp_word_id_list.shape)\n",
    "    print(temp_sub_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lcase</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_group_id</th>\n",
       "      <th>letter_group</th>\n",
       "      <th>letter_group_ranked</th>\n",
       "      <th>letters_sorted</th>\n",
       "      <th>letters_ranked</th>\n",
       "      <th>letter_selector</th>\n",
       "      <th>word_id_n_char_matrix_key</th>\n",
       "      <th>word_id_n_char_matrix_key_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>(1, a)</td>\n",
       "      <td>2573987472660525763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "      <td>a</td>\n",
       "      <td>(2, a)</td>\n",
       "      <td>8025778741640545687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aal</td>\n",
       "      <td>aal</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>la</td>\n",
       "      <td>aal</td>\n",
       "      <td>laa</td>\n",
       "      <td>la</td>\n",
       "      <td>(3, la)</td>\n",
       "      <td>-6956116240943725092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalii</td>\n",
       "      <td>aalii</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ail</td>\n",
       "      <td>lai</td>\n",
       "      <td>aaiil</td>\n",
       "      <td>laaii</td>\n",
       "      <td>lai</td>\n",
       "      <td>(5, lai)</td>\n",
       "      <td>2430473564524324450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aam</td>\n",
       "      <td>aam</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>ma</td>\n",
       "      <td>aam</td>\n",
       "      <td>maa</td>\n",
       "      <td>ma</td>\n",
       "      <td>(3, ma)</td>\n",
       "      <td>2173495933721432365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  lcase  n_chars first_letter  word_id  word_group_id letter_group  \\\n",
       "0      A      a        1            a        0              0            a   \n",
       "1     aa     aa        2            a        1              1            a   \n",
       "2    aal    aal        3            a        2              2           al   \n",
       "3  aalii  aalii        5            a        3              3          ail   \n",
       "4    aam    aam        3            a        4              4           am   \n",
       "\n",
       "  letter_group_ranked letters_sorted letters_ranked letter_selector  \\\n",
       "0                   a              a              a               a   \n",
       "1                   a             aa             aa               a   \n",
       "2                  la            aal            laa              la   \n",
       "3                 lai          aaiil          laaii             lai   \n",
       "4                  ma            aam            maa              ma   \n",
       "\n",
       "  word_id_n_char_matrix_key  word_id_n_char_matrix_key_hash  \n",
       "0                    (1, a)             2573987472660525763  \n",
       "1                    (2, a)             8025778741640545687  \n",
       "2                   (3, la)            -6956116240943725092  \n",
       "3                  (5, lai)             2430473564524324450  \n",
       "4                   (3, ma)             2173495933721432365  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function to query the matrix, examine the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(word_id, word_dict, word_id_list, matrix_extraction_option,                \n",
    "               n_char_matrix_dict, word_id_n_char_matrix_dict, char_matrix):\n",
    "    \"\"\" FIND ANAGRAMS FOR A SPECIFIC USING word_id AND MATRIX COMPARISONS    \n",
    "    \"\"\" \n",
    "    \n",
    "    # A USEFUL WAY TO PROTOTYPE, TIME, AND DETERMINE THE\n",
    "    # CORRECTNESS OF PROGRAM OPERATION AND OUTPUT\n",
    "\n",
    "    # get information data based on word id\n",
    "    cw, cw_length, cfl, clg, clgr = word_dict[word_id]   \n",
    "    \n",
    "    if matrix_extraction_option == 1:\n",
    "        outcome = char_matrix - char_matrix[word_id, ]\n",
    "        \n",
    "    if matrix_extraction_option in (2, 3, 4):        \n",
    "        key_hash = word_id_n_char_matrix_dict[word_id]\n",
    "        \n",
    "        cw_id_list, curr_char_matrix = n_char_matrix_dict[key_hash]\n",
    "        # subtract the curr_test_vector from every row in the matrix\n",
    "        # this produces a new matrix.        \n",
    "        new_word_id = cw_id_list==word_id        \n",
    "        outcome = curr_char_matrix - curr_char_matrix[new_word_id, ]\n",
    "        \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = np.all(outcome >= 0, axis = 1)\n",
    "    outcome = None        \n",
    "\n",
    "    # extract anagrams based on index values\n",
    "    if matrix_extraction_option == 1:\n",
    "        outcome_word_id_list = word_id_list[outcome_indices]\n",
    "    else:\n",
    "        outcome_word_id_list = cw_id_list[outcome_indices]    \n",
    "    \n",
    "    output_list = np.zeros(shape = (len(outcome_word_id_list), 2),  dtype=np.int32)\n",
    "    \n",
    "    # update the output list with the word_id_list - these are from/parent words    \n",
    "    output_list[:, 0] = outcome_word_id_list\n",
    "    \n",
    "    # update with the word_id - this is the to/child word\n",
    "    output_list[:, 1] = word_id\n",
    "        \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with the word 'quiet', id 160875\n",
    "curr_word_id = 160875\n",
    "curr_word, curr_word_length, curr_first_letter, curr_letter_group, curr_letter_group_ranked = word_dict[curr_word_id] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quiet'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_id_n_char_matrix_dict[160875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_values(word_id = curr_word_id, word_dict = word_dict, word_id_list = word_id_list, \n",
    "                    matrix_extraction_option = matrix_extraction_option,\n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    word_id_n_char_matrix_dict = word_id_n_char_matrix_dict,\n",
    "                    char_matrix = char_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many parent/from words were found for the word 'quiet'?\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106496, 160875],\n",
       "       [106497, 160875],\n",
       "       [106504, 160875],\n",
       "       ...,\n",
       "       [177472, 160875],\n",
       "       [106493, 160875],\n",
       "       [106495, 160875]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an array of from words to the word 'quiet'\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and those words are...\n",
    "word_list = word_df.loc[word_df['word_id'].isin(output[:, 0]), 'lcase'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aceanthrenequinone',\n",
       " 'acquaintance',\n",
       " 'acquaintanceship',\n",
       " 'acquainted',\n",
       " 'acquaintedness',\n",
       " 'acquiescement',\n",
       " 'acquiescent',\n",
       " 'acquiescently',\n",
       " 'acquirement',\n",
       " 'acquisite',\n",
       " 'acquisited',\n",
       " 'acquisitive',\n",
       " 'acquisitively',\n",
       " 'acquisitiveness',\n",
       " 'acquitment',\n",
       " 'acquittance',\n",
       " 'acquitter',\n",
       " 'adequation',\n",
       " 'adequative',\n",
       " 'altiloquence',\n",
       " 'altiloquent',\n",
       " 'aminoanthraquinone',\n",
       " 'anthradiquinone',\n",
       " 'anthrahydroquinone',\n",
       " 'anthraquinone',\n",
       " 'anticritique',\n",
       " 'antimasque',\n",
       " 'antimasquer',\n",
       " 'antimasquerade',\n",
       " 'antiquarianize',\n",
       " 'antiquate',\n",
       " 'antiquated',\n",
       " 'antiquatedness',\n",
       " 'antique',\n",
       " 'antiquely',\n",
       " 'antiqueness',\n",
       " 'antiquer',\n",
       " 'appropinquate',\n",
       " 'aquarellist',\n",
       " 'aquatile',\n",
       " 'aquatinter',\n",
       " 'aquativeness',\n",
       " 'aquiculture',\n",
       " 'aquocellolitis',\n",
       " 'aquopentamminecobaltic',\n",
       " 'aquotize',\n",
       " 'architecturesque',\n",
       " 'arquerite',\n",
       " 'banqueteering',\n",
       " 'barquantine',\n",
       " 'becquerelite',\n",
       " 'bedquilt',\n",
       " 'bequirtle',\n",
       " 'bilboquet',\n",
       " 'biquadrate',\n",
       " 'biquarterly',\n",
       " 'biquintile',\n",
       " 'bisquette',\n",
       " 'breviloquent',\n",
       " 'briquette',\n",
       " 'byzantinesque',\n",
       " 'caquetio',\n",
       " 'centiloquy',\n",
       " 'chicquest',\n",
       " 'cinquecentism',\n",
       " 'cinquecentist',\n",
       " 'cinquecento',\n",
       " 'codelinquent',\n",
       " 'coequality',\n",
       " 'coequation',\n",
       " 'colliquate',\n",
       " 'colliquative',\n",
       " 'colliquativeness',\n",
       " 'consequential',\n",
       " 'consequentiality',\n",
       " 'consequentially',\n",
       " 'consequentialness',\n",
       " 'coquelicot',\n",
       " 'coquettish',\n",
       " 'coquettishly',\n",
       " 'coquettishness',\n",
       " 'coquimbite',\n",
       " 'corinthianesque',\n",
       " 'counteracquittance',\n",
       " 'counterequivalent',\n",
       " 'counterquestion',\n",
       " 'counterquip',\n",
       " 'critique',\n",
       " 'deaquation',\n",
       " 'delinquent',\n",
       " 'delinquently',\n",
       " 'deliquescent',\n",
       " 'dentiloquist',\n",
       " 'dentiloquy',\n",
       " 'desquamation',\n",
       " 'desquamative',\n",
       " 'diphenylquinomethane',\n",
       " 'disacquaintance',\n",
       " 'disequilibrate',\n",
       " 'disequilibration',\n",
       " 'disfrequent',\n",
       " 'disquiet',\n",
       " 'disquieted',\n",
       " 'disquietedly',\n",
       " 'disquietedness',\n",
       " 'disquieten',\n",
       " 'disquieter',\n",
       " 'disquieting',\n",
       " 'disquietingly',\n",
       " 'disquietly',\n",
       " 'disquietness',\n",
       " 'disquietude',\n",
       " 'disquisite',\n",
       " 'disquisitive',\n",
       " 'disquisitively',\n",
       " 'disquixote',\n",
       " 'earthquaking',\n",
       " 'eliquate',\n",
       " 'eliquation',\n",
       " 'eloquential',\n",
       " 'equability',\n",
       " 'equalist',\n",
       " 'equalitarian',\n",
       " 'equalitarianism',\n",
       " 'equality',\n",
       " 'equalization',\n",
       " 'equanimity',\n",
       " 'equation',\n",
       " 'equational',\n",
       " 'equationally',\n",
       " 'equationism',\n",
       " 'equationist',\n",
       " 'equatorial',\n",
       " 'equatorially',\n",
       " 'equestrial',\n",
       " 'equestrian',\n",
       " 'equestrianism',\n",
       " 'equestrianize',\n",
       " 'equestrianship',\n",
       " 'equestrienne',\n",
       " 'equianchorate',\n",
       " 'equiangularity',\n",
       " 'equiarticulate',\n",
       " 'equiatomic',\n",
       " 'equibiradiate',\n",
       " 'equicostate',\n",
       " 'equidensity',\n",
       " 'equidifferent',\n",
       " 'equidistance',\n",
       " 'equidistant',\n",
       " 'equidistantial',\n",
       " 'equidistantly',\n",
       " 'equidistribution',\n",
       " 'equidominant',\n",
       " 'equielliptical',\n",
       " 'equiformity',\n",
       " 'equijacent',\n",
       " 'equilateral',\n",
       " 'equilaterally',\n",
       " 'equilibrant',\n",
       " 'equilibrate',\n",
       " 'equilibration',\n",
       " 'equilibrative',\n",
       " 'equilibrator',\n",
       " 'equilibratory',\n",
       " 'equilibriate',\n",
       " 'equilibrist',\n",
       " 'equilibristat',\n",
       " 'equilibristic',\n",
       " 'equilibrity',\n",
       " 'equilobate',\n",
       " 'equilocation',\n",
       " 'equilucent',\n",
       " 'equimomental',\n",
       " 'equimultiple',\n",
       " 'equinate',\n",
       " 'equinity',\n",
       " 'equinoctial',\n",
       " 'equinoctially',\n",
       " 'equiomnipotent',\n",
       " 'equiparant',\n",
       " 'equiparate',\n",
       " 'equiparation',\n",
       " 'equipartile',\n",
       " 'equipartisan',\n",
       " 'equipartition',\n",
       " 'equipment',\n",
       " 'equipollent',\n",
       " 'equipollently',\n",
       " 'equipollentness',\n",
       " 'equiponderant',\n",
       " 'equiponderate',\n",
       " 'equiponderation',\n",
       " 'equipostile',\n",
       " 'equipotent',\n",
       " 'equipotential',\n",
       " 'equipotentiality',\n",
       " 'equiprobabilist',\n",
       " 'equiprobability',\n",
       " 'equiproportional',\n",
       " 'equiproportionality',\n",
       " 'equiradiate',\n",
       " 'equirotal',\n",
       " 'equisegmented',\n",
       " 'equisetaceae',\n",
       " 'equisetaceous',\n",
       " 'equisetales',\n",
       " 'equisetic',\n",
       " 'equisetum',\n",
       " 'equisonant',\n",
       " 'equispatial',\n",
       " 'equitable',\n",
       " 'equitableness',\n",
       " 'equitably',\n",
       " 'equitangential',\n",
       " 'equitant',\n",
       " 'equitation',\n",
       " 'equitative',\n",
       " 'equitemporal',\n",
       " 'equitemporaneous',\n",
       " 'equites',\n",
       " 'equitist',\n",
       " 'equitriangular',\n",
       " 'equity',\n",
       " 'equivalent',\n",
       " 'equivalently',\n",
       " 'equivaliant',\n",
       " 'equivelocity',\n",
       " 'equivocality',\n",
       " 'equivocate',\n",
       " 'equivocatingly',\n",
       " 'equivocation',\n",
       " 'equivocator',\n",
       " 'equivocatory',\n",
       " 'equivote',\n",
       " 'etiquette',\n",
       " 'etiquettical',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'exquisiteness',\n",
       " 'exquisitism',\n",
       " 'exquisitively',\n",
       " 'extraequilibrium',\n",
       " 'extraquiz',\n",
       " 'fatiloquent',\n",
       " 'foreacquaint',\n",
       " 'frequentation',\n",
       " 'frequentative',\n",
       " 'giantesque',\n",
       " 'gigantesque',\n",
       " 'giottesque',\n",
       " 'grandiloquent',\n",
       " 'grandiloquently',\n",
       " 'griquaite',\n",
       " 'grotesquerie',\n",
       " 'hindquarter',\n",
       " 'hydroxyanthraquinone',\n",
       " 'hyperequatorial',\n",
       " 'illaqueate',\n",
       " 'illaqueation',\n",
       " 'inacquaintance',\n",
       " 'inacquiescent',\n",
       " 'inadequate',\n",
       " 'inadequately',\n",
       " 'inadequateness',\n",
       " 'inadequation',\n",
       " 'inadequative',\n",
       " 'inadequatively',\n",
       " 'inconsequent',\n",
       " 'inconsequential',\n",
       " 'inconsequentiality',\n",
       " 'inconsequentially',\n",
       " 'inconsequently',\n",
       " 'inconsequentness',\n",
       " 'ineloquent',\n",
       " 'ineloquently',\n",
       " 'inequalitarian',\n",
       " 'inequality',\n",
       " 'inequation',\n",
       " 'inequicostate',\n",
       " 'inequidistant',\n",
       " 'inequilateral',\n",
       " 'inequilobate',\n",
       " 'inequipotential',\n",
       " 'inequipotentiality',\n",
       " 'inequitable',\n",
       " 'inequitableness',\n",
       " 'inequitably',\n",
       " 'inequity',\n",
       " 'inequivalent',\n",
       " 'infrequent',\n",
       " 'infrequently',\n",
       " 'iniquitable',\n",
       " 'iniquitousness',\n",
       " 'inquaintance',\n",
       " 'inquest',\n",
       " 'inquestual',\n",
       " 'inquiet',\n",
       " 'inquietation',\n",
       " 'inquietly',\n",
       " 'inquietness',\n",
       " 'inquietude',\n",
       " 'inquinate',\n",
       " 'inquirent',\n",
       " 'inquisite',\n",
       " 'inquisitive',\n",
       " 'inquisitively',\n",
       " 'inquisitiveness',\n",
       " 'inquisitorialness',\n",
       " 'inquisitress',\n",
       " 'inquisiturient',\n",
       " 'insequent',\n",
       " 'interequinoctial',\n",
       " 'interquarrel',\n",
       " 'interquarter',\n",
       " 'intersqueeze',\n",
       " 'isoquercitrin',\n",
       " 'italianesque',\n",
       " 'jacqueminot',\n",
       " 'jequirity',\n",
       " 'joaquinite',\n",
       " 'jusquaboutisme',\n",
       " 'lacquerist',\n",
       " 'latinesque',\n",
       " 'limequat',\n",
       " 'liquate',\n",
       " 'liquefacient',\n",
       " 'liquefaction',\n",
       " 'liquefactive',\n",
       " 'liquescent',\n",
       " 'liquidate',\n",
       " 'machinotechnique',\n",
       " 'magniloquent',\n",
       " 'magniloquently',\n",
       " 'maquiritare',\n",
       " 'marquisate',\n",
       " 'marquisette',\n",
       " 'marquisotte',\n",
       " 'mastoideosquamous',\n",
       " 'mesquite',\n",
       " 'microtechnique',\n",
       " 'milliequivalent',\n",
       " 'miquelet',\n",
       " 'misquote',\n",
       " 'misquoter',\n",
       " 'monchiquite',\n",
       " 'mosquitocide',\n",
       " 'mosquitoey',\n",
       " 'mousquetaire',\n",
       " 'multiloquence',\n",
       " 'multiloquent',\n",
       " 'naphthoquinone',\n",
       " 'nesquehonite',\n",
       " 'nonacquaintance',\n",
       " 'nonacquiescent',\n",
       " 'nonacquisitive',\n",
       " 'nondeliquescent',\n",
       " 'nondesquamative',\n",
       " 'nonequation',\n",
       " 'nonequatorial',\n",
       " 'nonequestrian',\n",
       " 'nonequilateral',\n",
       " 'nonequivalent',\n",
       " 'nonequivocating',\n",
       " 'nonrelinquishment',\n",
       " 'nonrequirement',\n",
       " 'nonrequisition',\n",
       " 'nonrequital',\n",
       " 'nonsequestration',\n",
       " 'novantique',\n",
       " 'obliquate',\n",
       " 'obsequiosity',\n",
       " 'obsequity',\n",
       " 'omniloquent',\n",
       " 'orthobenzoquinone',\n",
       " 'orthoquinone',\n",
       " 'outquestion',\n",
       " 'outquibble',\n",
       " 'overexquisite',\n",
       " 'overexquisitely',\n",
       " 'overquantity',\n",
       " 'overquiet',\n",
       " 'overquietly',\n",
       " 'overquietness',\n",
       " 'oxyanthraquinone',\n",
       " 'oxynaphtoquinone',\n",
       " 'oxyquinaseptol',\n",
       " 'parietoquadrate',\n",
       " 'parietosquamosal',\n",
       " 'pauciloquent',\n",
       " 'pauciloquently',\n",
       " 'pectoriloquial',\n",
       " 'pectoriloquism',\n",
       " 'pectoriloquous',\n",
       " 'pectoriloquy',\n",
       " 'pentaquine',\n",
       " 'perequitate',\n",
       " 'perquisite',\n",
       " 'perquisition',\n",
       " 'perquisitor',\n",
       " 'picqueter',\n",
       " 'picturesque',\n",
       " 'picturesquely',\n",
       " 'picturesqueness',\n",
       " 'picturesquish',\n",
       " 'piquantness',\n",
       " 'piquet',\n",
       " 'politique',\n",
       " 'postique',\n",
       " 'pratique',\n",
       " 'preacquaint',\n",
       " 'preacquaintance',\n",
       " 'preacquit',\n",
       " 'preacquittal',\n",
       " 'preantiquity',\n",
       " 'predelinquent',\n",
       " 'predelinquently',\n",
       " 'preinquisition',\n",
       " 'preliquidate',\n",
       " 'preliquidation',\n",
       " 'prequalification',\n",
       " 'prequarantine',\n",
       " 'prequestion',\n",
       " 'prequotation',\n",
       " 'prerequirement',\n",
       " 'prerequisite',\n",
       " 'prerequisition',\n",
       " 'preterequine',\n",
       " 'procritique',\n",
       " 'proequality',\n",
       " 'pseudoantique',\n",
       " 'pseudoaquatic',\n",
       " 'pseudoequalitarian',\n",
       " 'quadragintesimal',\n",
       " 'quadrantile',\n",
       " 'quadrantlike',\n",
       " 'quadratifera',\n",
       " 'quadratiferous',\n",
       " 'quadrialate',\n",
       " 'quadriannulate',\n",
       " 'quadriarticulate',\n",
       " 'quadriarticulated',\n",
       " 'quadricapsulate',\n",
       " 'quadricarinate',\n",
       " 'quadricentennial',\n",
       " 'quadriciliate',\n",
       " 'quadricostate',\n",
       " 'quadricotyledonous',\n",
       " 'quadricrescentic',\n",
       " 'quadricrescentoid',\n",
       " 'quadricuspidate',\n",
       " 'quadridentate',\n",
       " 'quadridentated',\n",
       " 'quadriderivative',\n",
       " 'quadridigitate',\n",
       " 'quadrienniumutile',\n",
       " 'quadrifoliate',\n",
       " 'quadrifoliolate',\n",
       " 'quadrifurcate',\n",
       " 'quadrifurcated',\n",
       " 'quadrigate',\n",
       " 'quadrigeminate',\n",
       " 'quadrijugate',\n",
       " 'quadrilaminate',\n",
       " 'quadrilateral',\n",
       " 'quadrilaterally',\n",
       " 'quadrilateralness',\n",
       " 'quadriliteral',\n",
       " 'quadrilobate',\n",
       " 'quadriloculate',\n",
       " 'quadrimetallic',\n",
       " 'quadrinucleate',\n",
       " 'quadrioxalate',\n",
       " 'quadripartite',\n",
       " 'quadripartitely',\n",
       " 'quadripennate',\n",
       " 'quadriphosphate',\n",
       " 'quadripinnate',\n",
       " 'quadriplicate',\n",
       " 'quadriplicated',\n",
       " 'quadriradiate',\n",
       " 'quadrisect',\n",
       " 'quadrisection',\n",
       " 'quadriseptate',\n",
       " 'quadrisetose',\n",
       " 'quadristearate',\n",
       " 'quadrisulcate',\n",
       " 'quadrisulcated',\n",
       " 'quadriternate',\n",
       " 'quadritubercular',\n",
       " 'quadrituberculate',\n",
       " 'quadriurate',\n",
       " 'quadrivalent',\n",
       " 'quadrivalently',\n",
       " 'quadrivoltine',\n",
       " 'quadrupedantic',\n",
       " 'quadrupedantical',\n",
       " 'quadrupedation',\n",
       " 'quadruplicate',\n",
       " 'quadruplicature',\n",
       " 'quaesitum',\n",
       " 'quaestorial',\n",
       " 'quaestorian',\n",
       " 'quaestorship',\n",
       " 'quaintance',\n",
       " 'quaintise',\n",
       " 'quaintness',\n",
       " 'quakerization',\n",
       " 'quaketail',\n",
       " 'qualificative',\n",
       " 'qualimeter',\n",
       " 'qualitative',\n",
       " 'qualitatively',\n",
       " 'qualitied',\n",
       " 'qualityless',\n",
       " 'quantifiable',\n",
       " 'quantifier',\n",
       " 'quantimeter',\n",
       " 'quantitate',\n",
       " 'quantitative',\n",
       " 'quantitatively',\n",
       " 'quantitativeness',\n",
       " 'quantitied',\n",
       " 'quantitive',\n",
       " 'quantitively',\n",
       " 'quantivalence',\n",
       " 'quantivalency',\n",
       " 'quantivalent',\n",
       " 'quantize',\n",
       " 'quarantinable',\n",
       " 'quarantine',\n",
       " 'quarantiner',\n",
       " 'quartenylic',\n",
       " 'quarterdeckish',\n",
       " 'quartering',\n",
       " 'quarterization',\n",
       " 'quartermasterlike',\n",
       " 'quartermastership',\n",
       " 'quartile',\n",
       " 'quartine',\n",
       " 'quartodeciman',\n",
       " 'quartodecimanism',\n",
       " 'quartziferous',\n",
       " 'quartzite',\n",
       " 'quassative',\n",
       " 'quaternarian',\n",
       " 'quaternarius',\n",
       " 'quaternion',\n",
       " 'quaternionic',\n",
       " 'quaternionist',\n",
       " 'quaternitarian',\n",
       " 'quaternity',\n",
       " 'quatrefeuille',\n",
       " 'quatrefoil',\n",
       " 'quatrefoiled',\n",
       " 'quatrefoliated',\n",
       " 'quatrible',\n",
       " 'quatrocentism',\n",
       " 'quatrocentist',\n",
       " 'quattie',\n",
       " 'quatuorvirate',\n",
       " 'quebrachitol',\n",
       " 'queenite',\n",
       " 'queenright',\n",
       " 'queerity',\n",
       " 'queesting',\n",
       " 'queintise',\n",
       " 'quenselite',\n",
       " 'quercetagetin',\n",
       " 'quercetic',\n",
       " 'quercetin',\n",
       " 'quercimeritrin',\n",
       " 'quercitannic',\n",
       " 'quercitannin',\n",
       " 'quercite',\n",
       " 'quercitin',\n",
       " 'quercitol',\n",
       " 'quercitrin',\n",
       " 'quercitron',\n",
       " 'querist',\n",
       " 'querulential',\n",
       " 'querulist',\n",
       " 'querulity',\n",
       " 'querulosity',\n",
       " 'queryist',\n",
       " 'quesited',\n",
       " 'quesitive',\n",
       " 'questingly',\n",
       " 'question',\n",
       " 'questionability',\n",
       " 'questionable',\n",
       " 'questionableness',\n",
       " 'questionably',\n",
       " 'questionary',\n",
       " 'questionee',\n",
       " 'questioner',\n",
       " 'questioningly',\n",
       " 'questionist',\n",
       " 'questionless',\n",
       " 'questionlessly',\n",
       " 'questionnaire',\n",
       " 'questionous',\n",
       " 'questionwise',\n",
       " 'questorial',\n",
       " 'questorship',\n",
       " 'quetenite',\n",
       " 'quiblet',\n",
       " 'quickhearted',\n",
       " 'quickset',\n",
       " 'quickstep',\n",
       " 'quiddative',\n",
       " 'quidditative',\n",
       " 'quidditatively',\n",
       " 'quiescent',\n",
       " 'quiescently',\n",
       " 'quiet',\n",
       " 'quietable',\n",
       " 'quieten',\n",
       " 'quietener',\n",
       " 'quieter',\n",
       " 'quieting',\n",
       " 'quietism',\n",
       " 'quietist',\n",
       " 'quietistic',\n",
       " 'quietive',\n",
       " 'quietlike',\n",
       " 'quietly',\n",
       " 'quietness',\n",
       " 'quietsome',\n",
       " 'quietude',\n",
       " 'quietus',\n",
       " 'quileute',\n",
       " 'quillet',\n",
       " 'quilleted',\n",
       " 'quilted',\n",
       " 'quilter',\n",
       " 'quinaielt',\n",
       " 'quinate',\n",
       " 'quinatoxine',\n",
       " 'quincentenary',\n",
       " 'quincentennial',\n",
       " 'quincewort',\n",
       " 'quindecemvirate',\n",
       " 'quinetum',\n",
       " 'quingentenary',\n",
       " 'quiniretin',\n",
       " 'quinisext',\n",
       " 'quinisextine',\n",
       " 'quinite',\n",
       " 'quinnet',\n",
       " 'quinometry',\n",
       " 'quinotoxine',\n",
       " 'quinovate',\n",
       " 'quinquecostate',\n",
       " 'quinquedentate',\n",
       " 'quinquedentated',\n",
       " 'quinquefoliate',\n",
       " 'quinquefoliated',\n",
       " 'quinquefoliolate',\n",
       " 'quinquelateral',\n",
       " 'quinqueliteral',\n",
       " 'quinquelobate',\n",
       " 'quinquelobated',\n",
       " 'quinquennialist',\n",
       " 'quinquepartite',\n",
       " 'quinquepetaloid',\n",
       " 'quinquepunctal',\n",
       " 'quinquepunctate',\n",
       " 'quinqueradiate',\n",
       " 'quinquertium',\n",
       " 'quinquesect',\n",
       " 'quinquesection',\n",
       " 'quinqueseptate',\n",
       " 'quinqueseriate',\n",
       " 'quinquetubercular',\n",
       " 'quinquetuberculate',\n",
       " 'quinquevalent',\n",
       " 'quinquevirate',\n",
       " 'quinquiliteral',\n",
       " 'quintadena',\n",
       " 'quintadene',\n",
       " 'quinte',\n",
       " 'quintelement',\n",
       " 'quintennial',\n",
       " 'quinternion',\n",
       " 'quinteron',\n",
       " 'quinteroon',\n",
       " 'quintessence',\n",
       " 'quintessential',\n",
       " 'quintessentiality',\n",
       " 'quintessentially',\n",
       " 'quintessentiate',\n",
       " 'quintet',\n",
       " 'quintette',\n",
       " 'quintetto',\n",
       " 'quintile',\n",
       " 'quintiped',\n",
       " 'quintole',\n",
       " 'quintuple',\n",
       " 'quintuplet',\n",
       " 'quintuplicate',\n",
       " 'quintuplinerved',\n",
       " 'quintupliribbed',\n",
       " 'quipster',\n",
       " 'quirite',\n",
       " 'quirites',\n",
       " 'quisqueite',\n",
       " 'quite',\n",
       " 'quitemoca',\n",
       " 'quiteno',\n",
       " 'quitrent',\n",
       " 'quittable',\n",
       " 'quittance',\n",
       " 'quitted',\n",
       " 'quitter',\n",
       " 'quixote',\n",
       " 'quixotize',\n",
       " 'quodlibet',\n",
       " 'quodlibetal',\n",
       " 'quodlibetarian',\n",
       " 'quodlibetary',\n",
       " 'quodlibetic',\n",
       " 'quodlibetical',\n",
       " 'quodlibetically',\n",
       " 'quoiter',\n",
       " 'quoitlike',\n",
       " 'quotative',\n",
       " 'quotennial',\n",
       " 'quotidianness',\n",
       " 'quotient',\n",
       " 'quotiety',\n",
       " 'quotlibet',\n",
       " 'reacquaint',\n",
       " 'reacquaintance',\n",
       " 'reacquisition',\n",
       " 'relinquent',\n",
       " 'relinquishment',\n",
       " 'reliquidate',\n",
       " 'reliquidation',\n",
       " 'requalification',\n",
       " 'requarantine',\n",
       " 'requestion',\n",
       " 'requirement',\n",
       " 'requisite',\n",
       " 'requisitely',\n",
       " 'requisiteness',\n",
       " 'requisition',\n",
       " 'requisitionary',\n",
       " 'requisitioner',\n",
       " 'requisitionist',\n",
       " 'requisitor',\n",
       " 'requisitorial',\n",
       " 'requisitory',\n",
       " 'requit',\n",
       " 'requitable',\n",
       " 'requital',\n",
       " 'requitative',\n",
       " 'requite',\n",
       " 'requiteful',\n",
       " 'requitement',\n",
       " 'requiter',\n",
       " 'requotation',\n",
       " 'resequestration',\n",
       " 'retranquilize',\n",
       " 'sanctiloquent',\n",
       " 'scioterique',\n",
       " 'semiacquaintance',\n",
       " 'semiantique',\n",
       " 'semiaquatic',\n",
       " 'semiequitant',\n",
       " 'semiliquidity',\n",
       " 'semiquadrantly',\n",
       " 'semiquadrate',\n",
       " 'semiquantitative',\n",
       " 'semiquantitatively',\n",
       " 'semiquartile',\n",
       " 'semiquietism',\n",
       " 'semiquietist',\n",
       " 'semiquintile',\n",
       " 'semiquote',\n",
       " 'sequacity',\n",
       " 'sequential',\n",
       " 'sequentiality',\n",
       " 'sequentially',\n",
       " 'sequestration',\n",
       " 'sequestratrices',\n",
       " 'sequestratrix',\n",
       " 'sequitur',\n",
       " 'seriogrotesque',\n",
       " 'sesquialter',\n",
       " 'sesquialtera',\n",
       " 'sesquialteral',\n",
       " 'sesquialteran',\n",
       " 'sesquialterous',\n",
       " 'sesquicarbonate',\n",
       " 'sesquicentennial',\n",
       " 'sesquiduplicate',\n",
       " 'sesquihydrate',\n",
       " 'sesquihydrated',\n",
       " 'sesquioctava',\n",
       " 'sesquioctaval',\n",
       " 'sesquipedality',\n",
       " 'sesquiplicate',\n",
       " 'sesquiquadrate',\n",
       " 'sesquiquarta',\n",
       " 'sesquiquartal',\n",
       " 'sesquiquartile',\n",
       " 'sesquiquinta',\n",
       " 'sesquiquintal',\n",
       " 'sesquiquintile',\n",
       " 'sesquisalt',\n",
       " 'sesquiseptimal',\n",
       " 'sesquisextal',\n",
       " 'sesquisilicate',\n",
       " 'sesquisulphate',\n",
       " 'sesquisulphuret',\n",
       " 'sesquiterpene',\n",
       " 'sesquitertia',\n",
       " 'sesquitertial',\n",
       " 'sesquitertian',\n",
       " 'sesquitertianal',\n",
       " 'sobriquet',\n",
       " 'sobriquetical',\n",
       " 'somniloquent',\n",
       " 'spheroquartic',\n",
       " 'squalodontidae',\n",
       " 'squamatine',\n",
       " 'squamipennate',\n",
       " 'squamipinnate',\n",
       " 'squamoepithelial',\n",
       " 'squamoparietal',\n",
       " 'squamosoimbricated',\n",
       " 'squamosoparietal',\n",
       " 'squamosoradiate',\n",
       " 'squaretail',\n",
       " 'squatinidae',\n",
       " 'squatinoidei',\n",
       " 'squattiness',\n",
       " 'squatwise',\n",
       " 'squeezability',\n",
       " 'squiblet',\n",
       " 'squinted',\n",
       " 'squinter',\n",
       " 'squintingness',\n",
       " 'squintness',\n",
       " 'squirelet',\n",
       " 'squiret',\n",
       " 'squirreltail',\n",
       " 'squirter',\n",
       " 'squirtiness',\n",
       " 'squitter',\n",
       " 'stultiloquence',\n",
       " 'stultiloquently',\n",
       " 'suaviloquent',\n",
       " 'subantique',\n",
       " 'subequality',\n",
       " 'subequatorial',\n",
       " 'subequilateral',\n",
       " 'subquestion',\n",
       " 'subquintuple',\n",
       " 'subsequential',\n",
       " 'subsequentially',\n",
       " 'subtriquetrous',\n",
       " 'superacquisition',\n",
       " 'superequivalent',\n",
       " 'superexquisite',\n",
       " 'superexquisitely',\n",
       " 'superexquisiteness',\n",
       " 'superinquisitive',\n",
       " 'superrequirement',\n",
       " 'supersesquitertial',\n",
       " 'supraquantivalence',\n",
       " 'supraquantivalent',\n",
       " 'tanquelinian',\n",
       " 'technique',\n",
       " 'techniquer',\n",
       " 'tequila',\n",
       " 'tequistlateca',\n",
       " 'tequistlatecan',\n",
       " 'thymoquinone',\n",
       " 'titanesque',\n",
       " 'titianesque',\n",
       " 'toluquinaldine',\n",
       " 'totaquine',\n",
       " 'tourniquet',\n",
       " 'tranquilize',\n",
       " 'tranquilizer',\n",
       " 'tranquillize',\n",
       " 'tranquilness',\n",
       " 'transequatorial',\n",
       " 'triequal',\n",
       " 'triptyque',\n",
       " 'triquetra',\n",
       " 'triquetral',\n",
       " 'triquetric',\n",
       " 'triquetrous',\n",
       " 'triquetrously',\n",
       " 'triquetrum',\n",
       " 'triquinate',\n",
       " 'trisquare',\n",
       " 'turquoise',\n",
       " 'turquoiseberry',\n",
       " 'turquoiselike',\n",
       " 'ubiquitariness',\n",
       " 'ubiquitousness',\n",
       " 'unacquaintable',\n",
       " 'unacquaintance',\n",
       " 'unacquainted',\n",
       " 'unacquaintedly',\n",
       " 'unacquaintedness',\n",
       " 'unacquiescent',\n",
       " 'unacquittable',\n",
       " 'unacquitted',\n",
       " 'unacquittedness',\n",
       " 'unantiquated',\n",
       " 'unantiquatedness',\n",
       " 'unantique',\n",
       " 'unconsequential',\n",
       " 'unconsequentially',\n",
       " 'unconsequentialness',\n",
       " 'uncoquettish',\n",
       " 'uncoquettishly',\n",
       " 'undisquieted',\n",
       " 'unequality',\n",
       " 'unequatorial',\n",
       " 'unequestrian',\n",
       " 'unequilateral',\n",
       " 'unequilibrated',\n",
       " 'unequitable',\n",
       " 'unequitableness',\n",
       " 'unequitably',\n",
       " 'unequivalent',\n",
       " 'uniequivalent',\n",
       " 'uninquisitive',\n",
       " 'uninquisitively',\n",
       " 'uninquisitiveness',\n",
       " 'unliquidatable',\n",
       " 'unliquidated',\n",
       " 'unpicturesque',\n",
       " 'unpicturesquely',\n",
       " 'unpicturesqueness',\n",
       " 'unqualitied',\n",
       " 'unquantified',\n",
       " 'unquantitative',\n",
       " 'unquarantined',\n",
       " 'unquestionability',\n",
       " 'unquestionable',\n",
       " 'unquestionableness',\n",
       " 'unquestionably',\n",
       " 'unquestionate',\n",
       " 'unquestioned',\n",
       " 'unquestionedly',\n",
       " 'unquestionedness',\n",
       " 'unquestioning',\n",
       " 'unquestioningly',\n",
       " 'unquestioningness',\n",
       " 'unquiescent',\n",
       " 'unquiescently',\n",
       " 'unquiet',\n",
       " 'unquietable',\n",
       " 'unquieted',\n",
       " 'unquieting',\n",
       " 'unquietly',\n",
       " 'unquietness',\n",
       " 'unquietude',\n",
       " 'unquilleted',\n",
       " 'unquilted',\n",
       " 'unquittable',\n",
       " 'unquitted',\n",
       " 'unrequisite',\n",
       " 'unrequitable',\n",
       " 'unrequital',\n",
       " 'unrequited',\n",
       " 'unrequitedly',\n",
       " 'unrequitedness',\n",
       " 'unrequitement',\n",
       " 'unrequiter',\n",
       " 'unrequiting',\n",
       " 'unsequential',\n",
       " 'unsquirted',\n",
       " 'untranquilized',\n",
       " 'untranquillize',\n",
       " 'untranquillized',\n",
       " 'vanquishment',\n",
       " 'vauquelinite',\n",
       " 'ventriloqual',\n",
       " 'ventriloqually',\n",
       " 'ventriloque',\n",
       " 'ventriloquial',\n",
       " 'ventriloquially',\n",
       " 'ventriloquism',\n",
       " 'ventriloquist',\n",
       " 'ventriloquistic',\n",
       " 'ventriloquize',\n",
       " 'ventriloquous',\n",
       " 'ventriloquously',\n",
       " 'ventriloquy',\n",
       " 'violaquercitrin',\n",
       " 'whitmanesque']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've tested with one word, let's time many evaluations to get a sense of how quickly \n",
    "# the current matrix_extraction_option executes\n",
    "# use the timeit() function to evaluate how long, on average, a single matrix operation\n",
    "# takes to complete\n",
    "code_snippet = \"\"\"get_values(word_id = curr_word_id, word_dict = word_dict, word_id_list = word_id_list, \n",
    "                    matrix_extraction_option = matrix_extraction_option,\n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    word_id_n_char_matrix_dict = word_id_n_char_matrix_dict,\n",
    "                    char_matrix = char_matrix)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "total_time = timeit.timeit(code_snippet,\n",
    "              number=n_trials, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002201231000071857"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of seconds per trial\n",
    "total_time / n_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate total number of from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many anagrams are there?\n",
    "# let's estimate the number of anagrams by assuming that the number of\n",
    "# parent/from words is a function of word length. \n",
    "# let's sample 10 words of each word length, compute the number of from/parent anagrams\n",
    "# for each word in the sample, compute the min, mean, and max, and apply those values\n",
    "# to the numbers of words by length and multiply accordingly\n",
    "# this will give us very generous upper bound of anagram pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the number of characters per word\n",
    "n_char_list = sorted(word_df['n_chars'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate and sample\n",
    "output_list = []\n",
    "for i_n_char, n_char in enumerate(n_char_list):\n",
    "    curr_id_list = word_df.loc[word_df['n_chars']==n_char, 'word_id'].to_numpy()\n",
    "    # sample with replacement\n",
    "    sample_id_list = np.random.choice(a = curr_id_list, size = 10, replace = True)\n",
    "    for sid in sample_id_list:\n",
    "        output = get_values(word_id = sid, word_dict = word_dict, word_id_list = word_id_list, \n",
    "                    matrix_extraction_option = matrix_extraction_option,\n",
    "                    n_char_matrix_dict = n_char_matrix_dict,\n",
    "                    word_id_n_char_matrix_dict = word_id_n_char_matrix_dict,\n",
    "                    char_matrix = char_matrix)\n",
    "        curr_from_words = len(output)\n",
    "        curr_output = [n_char, curr_from_words]\n",
    "        output_list.append(curr_output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe\n",
    "pos_df = pd.DataFrame(data = output_list, columns = ['n_chars', 'n_from_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum, max, and mean number of from words\n",
    "agg_pos_df = pos_df.groupby('n_chars').agg([np.min, np.max, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">n_from_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_chars</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8012</td>\n",
       "      <td>157437</td>\n",
       "      <td>80730.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>88006</td>\n",
       "      <td>41044.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1092</td>\n",
       "      <td>48754</td>\n",
       "      <td>13429.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>31467</td>\n",
       "      <td>6342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>114</td>\n",
       "      <td>9465</td>\n",
       "      <td>4007.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_from_words                 \n",
       "                 min     max     mean\n",
       "n_chars                              \n",
       "1               8012  157437  80730.1\n",
       "2               2010   88006  41044.5\n",
       "3               1092   48754  13429.1\n",
       "4                 74   31467   6342.3\n",
       "5                114    9465   4007.4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_pos_df.columns = ['min_n_from_words', 'max_n_from_words', 'mean_n_from_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's aggregate by number of letters per word, and then join\n",
    "n_word_length_df = word_df['n_chars'].groupby(word_df['n_chars']).agg(np.size).to_frame()\n",
    "n_word_length_df.columns = ['n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos_df = pd.merge(left = n_word_length_df, right = agg_pos_df, left_index = True,\n",
    "                   right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos_df['n_tot_max_anagrams'] = n_pos_df['n_words'] * n_pos_df['max_n_from_words']\n",
    "n_pos_df['n_tot_mean_anagrams'] = n_pos_df['n_words'] * n_pos_df['mean_n_from_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the upper bound of anagrams as the midway point\n",
    "# between the mean and the max of the estimated number of anagrams\n",
    "n_possible_anagrams = (n_pos_df['n_tot_mean_anagrams'].sum() + n_pos_df['n_tot_max_anagrams'].sum()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round and convert to integer\n",
    "n_possible_anagrams = int(np.round(n_possible_anagrams, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308523509"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this number will be used to create an array that will hold the from/to pairs\n",
    "n_possible_anagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discover from/to word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...finding parent anagrams for 380 words that start with x\n",
      "...finding parent anagrams for x words took 0.05 seconds...\n",
      "...finding parent anagrams for 663 words that start with y\n",
      "...finding parent anagrams for y words took 0.83 seconds...\n",
      "...finding parent anagrams for 942 words that start with z\n",
      "...finding parent anagrams for z words took 0.16 seconds...\n",
      "...finding parent anagrams for 1,148 words that start with q\n",
      "...finding parent anagrams for q words took 0.11 seconds...\n",
      "...finding parent anagrams for 1,603 words that start with j\n",
      "...finding parent anagrams for j words took 0.11 seconds...\n",
      "...finding parent anagrams for 2,239 words that start with k\n",
      "...finding parent anagrams for k words took 0.45 seconds...\n",
      "...finding parent anagrams for 3,418 words that start with v\n",
      "...finding parent anagrams for v words took 0.96 seconds...\n",
      "...finding parent anagrams for 3,910 words that start with w\n",
      "...finding parent anagrams for w words took 0.56 seconds...\n",
      "...finding parent anagrams for 6,228 words that start with l\n",
      "...finding parent anagrams for l words took 8.06 seconds...\n",
      "...finding parent anagrams for 6,742 words that start with n\n",
      "...finding parent anagrams for n words took 7.24 seconds...\n",
      "...finding parent anagrams for 6,771 words that start with g\n",
      "...finding parent anagrams for g words took 3.68 seconds...\n",
      "...finding parent anagrams for 6,836 words that start with f\n",
      "...finding parent anagrams for f words took 1.65 seconds...\n",
      "...finding parent anagrams for 7,830 words that start with o\n",
      "...finding parent anagrams for o words took 6.29 seconds...\n",
      "...finding parent anagrams for 8,703 words that start with e\n",
      "...finding parent anagrams for e words took 7.51 seconds...\n",
      "...finding parent anagrams for 8,786 words that start with i\n",
      "...finding parent anagrams for i words took 7.34 seconds...\n",
      "...finding parent anagrams for 8,992 words that start with h\n",
      "...finding parent anagrams for h words took 4.8 seconds...\n",
      "...finding parent anagrams for 9,613 words that start with r\n",
      "...finding parent anagrams for r words took 11.71 seconds...\n",
      "...finding parent anagrams for 10,849 words that start with d\n",
      "...finding parent anagrams for d words took 5.67 seconds...\n",
      "...finding parent anagrams for 10,963 words that start with b\n",
      "...finding parent anagrams for b words took 4.28 seconds...\n",
      "...finding parent anagrams for 12,513 words that start with m\n",
      "...finding parent anagrams for m words took 8.51 seconds...\n",
      "...finding parent anagrams for 12,853 words that start with t\n",
      "...finding parent anagrams for t words took 16.43 seconds...\n",
      "...finding parent anagrams for 16,361 words that start with u\n",
      "...finding parent anagrams for u words took 6.65 seconds...\n",
      "...finding parent anagrams for 16,974 words that start with a\n",
      "...finding parent anagrams for a words took 18.26 seconds...\n",
      "...finding parent anagrams for 19,783 words that start with c\n",
      "...finding parent anagrams for c words took 16.96 seconds...\n",
      "...finding parent anagrams for 24,341 words that start with p\n",
      "...finding parent anagrams for p words took 16.03 seconds...\n",
      "...finding parent anagrams for 24,929 words that start with s\n",
      "...finding parent anagrams for s words took 20.86 seconds...\n"
     ]
    }
   ],
   "source": [
    "# initialize counters to count the number of to (child words) from a focal word.\n",
    "# we could do this in post-processing, but the data are already in memory and it's a simple \n",
    "# calculation to make.\n",
    "# we want to minimize the number of trips through our data.\n",
    "\n",
    "# the number of candidate words examined for each focal word\n",
    "\n",
    "# a list to hold the dataframes generated for each letter\n",
    "proc_time_df_list = []\n",
    "\n",
    "# subset the list of leters\n",
    "if letter_subset_list:\n",
    "    letters = letter_subset_list[:]\n",
    "else:\n",
    "    letters = sorted_first_letters\n",
    "\n",
    "anagram_pair_count = 0 \n",
    "# use numpy to pre-allocate an array that will be updated while enumerating. \n",
    "# this eliminates list.append() calls\n",
    "# note: I am guessing that there are 150M anagram pairs. \n",
    "\n",
    "output_list = np.full(shape = (n_possible_anagrams, 3), fill_value = -1,  dtype=np.int32)\n",
    "\n",
    "for i_cl, curr_letter in enumerate(letters):\n",
    "    # enumerate by each letter\n",
    "    # this isn't absolutely necessary, we could just enumerate by word id, \n",
    "    # but for testing and development, letters are a handy way to chunk up the data. \n",
    "\n",
    "    # this dictionary will store the calculations for each letter\n",
    "    proc_time_dict = {}    \n",
    "    \n",
    "    # the list of words that start with the focal letter     \n",
    "    curr_word_df = word_df.loc[word_df['first_letter'] == curr_letter, :]\n",
    "    \n",
    "    # sort the dataframe by n_chars and letter_selector, if it exists.\n",
    "    # this will cut down on dictionary lookups for matrix_extraction_types 3 and 4.    \n",
    "    if 'letter_selector' in word_df.columns.tolist():\n",
    "        curr_word_df = curr_word_df.sort_values(by = ['n_chars', 'letter_selector'])\n",
    "    else:\n",
    "        curr_word_df = curr_word_df.sort_values(by = ['n_chars'])\n",
    "        \n",
    "    curr_word_id_list = curr_word_df['word_id'].tolist()\n",
    "    \n",
    "    n_curr_words = '{:,}'.format(len(curr_word_df))    \n",
    "    print('...finding parent anagrams for', n_curr_words, 'words that start with', curr_letter)               \n",
    "    \n",
    "    # enumerate by word id, working with integers is faster than words    \n",
    "    for i_wi, word_id in enumerate(curr_word_id_list):            \n",
    "        # start timing to record processing for each word            \n",
    "        s_time = datetime.datetime.now()\n",
    "        \n",
    "        # get the current word length, from the word id\n",
    "        #to_word, to_word_length, curr_first_letter, clg, clgr = word_dict[word_id]   \n",
    "        to_word_length = word_dict[word_id][1]\n",
    "        \n",
    "        if matrix_extraction_option == 1:\n",
    "            outcome = char_matrix - char_matrix[word_id, ]\n",
    "            n_possible_words = char_matrix.shape[0]            \n",
    "\n",
    "        if matrix_extraction_option in (2, 3, 4):        \n",
    "            \n",
    "            # get the tuple associated with the word id\n",
    "            # much faster to look up stored values for the hash value than it is to \n",
    "            # only look up if the hash value has changed            \n",
    "            key_hash = word_id_n_char_matrix_dict[word_id]                \n",
    "            # get the possible candidate word_ids and char matrix\n",
    "            curr_word_id_index_list, curr_char_matrix = n_char_matrix_dict[key_hash]                                \n",
    "        \n",
    "            # how many candidates?\n",
    "            n_possible_words = len(curr_word_id_index_list)\n",
    "        \n",
    "            # subtract the curr_test_vector from every row in the matrix\n",
    "            # this produces a new matrix.        \n",
    "            new_word_id = curr_word_id_index_list == word_id            \n",
    "            outcome = curr_char_matrix - curr_char_matrix[new_word_id, ]\n",
    "                        \n",
    "        # compute the score by finding where rows, across all columns, are GTE 0\n",
    "        outcome_indices = np.all(outcome >= 0, axis = 1)\n",
    "        outcome = None        \n",
    "        \n",
    "        # extract anagrams based on same index values\n",
    "        if matrix_extraction_option == 1:\n",
    "            outcome_word_id_list = word_id_list[outcome_indices].tolist()\n",
    "        else:                \n",
    "            outcome_word_id_list = curr_word_id_index_list[outcome_indices].tolist()\n",
    "            \n",
    "        outcome_indices = None               \n",
    "        \n",
    "        # if the outcome is greater than or equal to zero, then the current word is an\n",
    "        # anagram of the other word    \n",
    "        # a value  >= 0 means that the current word contains the exact same number of focal letters\n",
    "        # mite --> time or miter --> time\n",
    "        # a value >= 1 means that current word contains at least the same number of focal letters\n",
    "        # terminator --> time\n",
    "        # a value of <=-1 means that the current word does not have the \n",
    "        # correct number of letters and is therefore not an anagram.\n",
    "        # trait <> time        \n",
    "\n",
    "        # number of parent words found\n",
    "        n_from_words = len(outcome_word_id_list)\n",
    "\n",
    "        if n_from_words > 1:\n",
    "            \n",
    "            # we have matches\n",
    "            # the focal word   \n",
    "                                    \n",
    "            # enumerate the from/parent words\n",
    "            # from word length\n",
    "            from_word_length_list = [word_dict[from_word_id][1] for from_word_id in outcome_word_id_list]\n",
    "            same_word_length_list = [1 if fwl == to_word_length else 0 for fwl in from_word_length_list]\n",
    "            \n",
    "            new_anagram_pair_count = anagram_pair_count + len(from_word_length_list)\n",
    "            # the from words\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, 0] = outcome_word_id_list        \n",
    "            # the to word\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, 1] = word_id                                            \n",
    "            # same length\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, 2] = same_word_length_list                                                                       \n",
    "            # set the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "                    \n",
    "                \n",
    "        del outcome_word_id_list\n",
    "            \n",
    "        # record the time for the word\n",
    "        e_time = datetime.datetime.now()\n",
    "        p_time = e_time - s_time    \n",
    "        p_time = p_time.total_seconds()\n",
    "\n",
    "        proc_time_dict[word_id] = (p_time, n_from_words, n_possible_words)       \n",
    "    \n",
    "    # create a dataframe from the proc_time_dict\n",
    "    proc_time_df = pd.DataFrame.from_dict(data=proc_time_dict, orient='index')\n",
    "    proc_time_df = proc_time_df.reset_index()\n",
    "    proc_time_df.columns = ['word_id', 'n_seconds', 'n_from_words', 'n_candidates']                \n",
    "    \n",
    "    # display processing time for the current letter\n",
    "    total_proc_time = round(proc_time_df['n_seconds'].sum(), 2)\n",
    "    print('...finding parent anagrams for', curr_letter, 'words took', total_proc_time, 'seconds...')\n",
    "    \n",
    "    proc_time_df_list.append(proc_time_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape and store output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate the output array to only include indices with a from/to word pair\n",
    "output_indices = np.all(output_list >= 0, axis = 1)\n",
    "output_list = output_list[output_indices, ]\n",
    "del output_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...total anagrams 123,759,277\n"
     ]
    }
   ],
   "source": [
    "# how many anagram pairs were found?\n",
    "n_total_anagrams = len(output_list)\n",
    "n_total_anagrams_formatted = '{:,}'.format(n_total_anagrams)\n",
    "print('...total anagrams', n_total_anagrams_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count the number of to words, same length to words, and different length to words for each word using counters\n",
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "# number of to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the count of to words\n",
    "to_word_counter = collections.Counter(output_list[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the count of same length to words\n",
    "curr_indices = output_list[:, 2] == 1\n",
    "curr_output_list = output_list[curr_indices, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt_word_counter = collections.Counter(curr_output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the count of different length to words\n",
    "# substract the counters from each other\n",
    "dlt_word_counter = to_word_counter - slt_word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create database connection objects\n",
    "db_conn = build_db_conn(db_path = db_path, db_name = db_name)\n",
    "db_cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write anagram pairs to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123759277"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the anagram pairs to the database\n",
    "if write_data:\n",
    "\n",
    "    # let's write to the SQLite database in chunks of 1M records\n",
    "    break_point_list = list(range(0, len(output_list), 1000000))\n",
    "    # add the last bit of records\n",
    "    if break_point_list[-1] < len(output_list):\n",
    "        break_point_list.append(len(output_list))\n",
    "    \n",
    "    # drop the anagrams table if it previously exists\n",
    "    sql = 'drop table if exists anagrams;'\n",
    "    \n",
    "    print('...dropping previous table...')\n",
    "    # send the sql statement to the database and commit the changes\n",
    "    db_cursor.execute(sql)\n",
    "    db_conn.commit()\n",
    "\n",
    "    # create the anagrams table\n",
    "    sql = 'create table anagrams ( from_word_id integer, to_word_id integer, same_word_length integer);'\n",
    "\n",
    "    # execute the statement and commit changes    \n",
    "    db_cursor.execute(sql)\n",
    "    db_conn.commit()\n",
    "        \n",
    "    # objects to record write time\n",
    "    db_write_time_list = []\n",
    "    db_write_time_start = datetime.datetime.now()\n",
    "    \n",
    "    # create a sql statement that we'll use to insert values.\n",
    "    print('...beginning to add anagram word pairs...')\n",
    "    base_sql = 'insert into anagrams values (?,?,?)'    \n",
    "    \n",
    "    insert_count = 0    \n",
    "    curr_db_write_time_start = datetime.datetime.now()\n",
    "    for i_bp, bp in enumerate(break_point_list[:-1]):\n",
    "        # slice the output list of word id pairs, convert to a python list\n",
    "        # the numpy.int data type is not compatable with sqlite.\n",
    "        # the cursor.executemany() is a quick way to write a lot of data.\n",
    "        next_bp = break_point_list[i_bp + 1]\n",
    "        \n",
    "        # converting the entire output_list to a python list adds too much overheard.\n",
    "        test_output_list = output_list[bp:next_bp, ].tolist()\n",
    "        \n",
    "        # use the executemany() function to write records\n",
    "        #https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.executemany\n",
    "        db_cursor.executemany(base_sql, test_output_list)\n",
    "        \n",
    "        # commit changes every 10M records        \n",
    "        if next_bp % 10000000 == 0:\n",
    "            print('...commiting changes:', '{:,}'.format(next_bp), 'records')\n",
    "            db_conn.commit()                       \n",
    "            curr_db_write_time_end = datetime.datetime.now()\n",
    "            curr_db_write_time_proc = curr_db_write_time_end - curr_db_write_time_start            \n",
    "            curr_db_write_time_proc = curr_db_write_time_proc.total_seconds()\n",
    "            curr_db_write_time_start = datetime.datetime.now()\n",
    "            db_write_time_list.append(curr_db_write_time_proc)                                      \n",
    "\n",
    "            # compute average write time, display after 1M writes\n",
    "            mean_write_time = np.mean(db_write_time_list)\n",
    "\n",
    "            # compute ETA            \n",
    "            n_seconds = (n_total_anagrams / 10000000) * mean_write_time\n",
    "            add_seconds = datetime.timedelta(seconds = n_seconds)\n",
    "            eta_write_complete = db_write_time_start + add_seconds            \n",
    "            eta_write_complete = eta_write_complete.strftime(format = \"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "            mean_write_time = round(mean_write_time, 3)\n",
    "            print('...average write time per 10M records:', mean_write_time, 'seconds...')\n",
    "            print('...estimated write complete time:', eta_write_complete)\n",
    "        \n",
    "    # commit the last round of changes\n",
    "    print('...commiting changes:', '{:,}'.format(len(test_output_list)), 'records')\n",
    "    db_conn.commit()\n",
    "    \n",
    "    # compute total write times\n",
    "    db_write_time_end = datetime.datetime.now()\n",
    "    db_write_time_proc = db_write_time_end - db_write_time_start\n",
    "    db_write_time_proc = db_write_time_proc.total_seconds() / 60\n",
    "    db_write_time_proc = round(db_write_time_proc, 2)\n",
    "    print('...writing to db took', db_write_time_proc, 'minutes')\n",
    "    \n",
    "    del test_output_list\n",
    "    \n",
    "# remove the list of from/to word pairs\n",
    "del output_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store number of from/to word pairs and time related to processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the processing times\n",
    "proc_time_df = pd.concat(proc_time_df_list)\n",
    "\n",
    "# drop columns related to data processing\n",
    "drop_col_names = ['letter_selector', 'word_id_n_char_matrix_key',\n",
    "                  'word_id_n_char_matrix_key_hash']\n",
    "curr_col_names = word_df.columns.tolist()\n",
    "for dcn in drop_col_names:    \n",
    "    if dcn in curr_col_names:\n",
    "        word_df = word_df.drop(dcn, axis = 1)\n",
    "\n",
    "# merge the word_df and the proc_time_df dataframes to get the processing time per word\n",
    "word_df = pd.merge(left=word_df, right = proc_time_df)\n",
    "\n",
    "# now, use the map function to get the number of from/to words and the number of\n",
    "# candidate words for each word\n",
    "word_df['n_to_words'] = word_df['word_id'].map(to_word_counter)\n",
    "word_df['n_slt_words'] = word_df['word_id'].map(slt_word_counter)\n",
    "word_df['n_dlt_words'] = word_df['word_id'].map(dlt_word_counter)\n",
    "#word_df['n_candidates'] = word_df['word_id'].map(n_possible_words_counter)\n",
    "\n",
    "# record the matrix extraction option\n",
    "word_df['matrix_extraction_option'] = matrix_extraction_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "col_names = ['word','lcase','n_chars','first_letter','word_id',\n",
    "             'word_group_id','letter_group','letter_group_ranked','n_seconds',\n",
    "             'n_from_words','n_to_words','n_slt_words','n_dlt_words','n_candidates',\n",
    "             'matrix_extraction_option']\n",
    "word_df = word_df[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output table name\n",
    "table_name = 'words_me_' + str(matrix_extraction_option).zfill(2)\n",
    "# write the processing option table\n",
    "word_df.to_sql(name=table_name, con=db_conn, if_exists='replace', index = False)    \n",
    "# write the words table\n",
    "word_df.to_sql(name='words_v1', con=db_conn, if_exists='replace', index = False)    \n",
    "    \n",
    "# close the connection\n",
    "db_cursor.close()\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_discovery_time = word_df['n_seconds'].sum()\n",
    "anagram_discovery_time = anagram_discovery_time / 60\n",
    "anagram_discovery_time = round(anagram_discovery_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...anagram discovery time: 2.92 minutes\n"
     ]
    }
   ],
   "source": [
    "print('...anagram discovery time:', anagram_discovery_time, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the total time\n",
    "total_time_end = datetime.datetime.now()\n",
    "total_time_proc = total_time_end - total_time_start\n",
    "total_time_proc = total_time_proc.total_seconds()\n",
    "total_time_proc = total_time_proc / 60\n",
    "total_time_proc = round(total_time_proc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...total processing time: 4.58 minutes\n"
     ]
    }
   ],
   "source": [
    "print('...total processing time:', total_time_proc, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
