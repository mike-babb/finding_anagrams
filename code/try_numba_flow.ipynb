{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we find parent/child word relationships faster\n",
    "# One way to achieve this is to use numba which pre-compiles code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa58d5-75a5-41ea-8943-ebae8f18d273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from time import perf_counter_ns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom libraries\n",
    "from _run_constants import *\n",
    "from part_00_file_db_utils import *\n",
    "from part_00_process_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbee031",
   "metadata": {},
   "source": [
    "# Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247235e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df, wg_df, letter_dict, char_matrix, \\\n",
    "    word_group_id_list, word_id_list, wchar_matrix = load_input_data(\n",
    "        db_path=rc.DB_PATH, db_name=rc.DB_NAME,\n",
    "        in_file_path=rc.IN_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff2e4d",
   "metadata": {},
   "source": [
    "# let's process 1000 rows using a single lookup on the full wchar_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b36966",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_anagrams = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25610500",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{n_possible_anagrams :,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed420657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[True, False, True], [True, True, True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d92686",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b822f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in arr:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def all_axis_0(arr):\n",
    "    outcome = np.zeros(shape = arr.shape[0],dtype=np.bool)\n",
    "    row_count = 0\n",
    "    for row in arr:        \n",
    "        if row.min() >= 0:\n",
    "            outcome[row_count] = 1\n",
    "        row_count += 1\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def all_axis_1(arr):\n",
    "    arr_t = arr.T\n",
    "    outcome = np.zeros(shape = arr_t.shape[0],dtype=np.bool)\n",
    "    row_count = 0\n",
    "    for row in arr_t:        \n",
    "        if row.min() >= 0:\n",
    "            outcome[row_count] = 1\n",
    "        row_count += 1\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_axis_0(arr=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_axis_1(arr=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this out with numba\n",
    "@numba.njit()\n",
    "def do_something_clever(wchar_matrix, word_group_id_list, n_sample_size = 10):\n",
    "    n_possible_anagrams = 1000000\n",
    "    sample_wg_id = np.random.randint(0, 215842, size=n_sample_size)\n",
    "\n",
    "    # create an output object\n",
    "    output_list = np.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=np.int64)\n",
    "\n",
    "    row_count = 0\n",
    "    anagram_pair_count = 0\n",
    "\n",
    "    for i_wg_id, wg_id in enumerate(sample_wg_id):\n",
    "        # identify parent words\n",
    "        outcome = wchar_matrix - wchar_matrix[wg_id, ]\n",
    "        \n",
    "        # compute the score by finding where rows, across all columns, are GTE 0\n",
    "        outcome_indices = all_axis_0(arr=outcome)\n",
    "        #outcome_indices = np.all(outcome >= 0, 1)    \n",
    "\n",
    "        n_from_words = outcome_indices.sum()\n",
    "\n",
    "        if n_from_words >= 1:\n",
    "            # extract anagrams based on index values    \n",
    "            outcome_word_id_list = word_group_id_list[outcome_indices]    \n",
    "\n",
    "            # we have matches\n",
    "            # the focal word\n",
    "            curr_output_list = np.zeros(shape=(n_from_words, 2), dtype=np.int64)\n",
    "\n",
    "            # update the output list with the word_id_list - these are from/parent words\n",
    "            curr_output_list[:, 0] = outcome_word_id_list\n",
    "\n",
    "            # update with the word_id - this is the to/child word\n",
    "            curr_output_list[:, 1] = wg_id\n",
    "\n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count,\n",
    "                        :] = curr_output_list\n",
    "\n",
    "            # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "            #intermediate_to_word_count.update(outcome_word_id_list.tolist())\n",
    "\n",
    "            # set the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "        \n",
    "        row_count += 1\n",
    "\n",
    "        if row_count % 100 == 0:\n",
    "            print(row_count)\n",
    "    print('truncating list')\n",
    "    #output_indices = np.all(output_list >= 0, axis=1)\n",
    "    output_indices = all_axis_0(arr = output_list)\n",
    "    output_list = output_list[output_indices,]    \n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff56db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = do_something_clever(wchar_matrix=wchar_matrix, word_group_id_list=word_group_id_list,\n",
    "                                  n_sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a46b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f806b2",
   "metadata": {},
   "source": [
    "# Using the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb82534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 1000 rows\n",
    "n_samples = 1000\n",
    "sample_wg_id = wg_df['word_group_id'].sample(n = n_samples, random_state = 42).to_list()\n",
    "\n",
    "if 746 not in sample_wg_id:\n",
    "    sample_wg_id.append(746)\n",
    "    \n",
    "\n",
    "# create an output object\n",
    "output_list = np.full(shape=(n_possible_anagrams, 2),\n",
    "                          fill_value=-1, dtype=int)\n",
    "\n",
    "row_count = 0\n",
    "anagram_pair_count = 0\n",
    "\n",
    "for i_wg_id, wg_id in enumerate(sample_wg_id):\n",
    "    # identify parent words\n",
    "    outcome = wchar_matrix - wchar_matrix[wg_id, ]\n",
    "    \n",
    "    # compute the score by finding where rows, across all columns, are GTE 0\n",
    "    outcome_indices = np.all(outcome >= 0, axis=1)    \n",
    "\n",
    "    n_from_words = outcome_indices.sum()\n",
    "\n",
    "    if n_from_words >= 1:\n",
    "        # extract anagrams based on index values    \n",
    "        outcome_word_id_list = word_group_id_list[outcome_indices]    \n",
    "\n",
    "        # we have matches\n",
    "        # the focal word\n",
    "        curr_output_list = np.zeros(shape=(n_from_words, 2), dtype=int)\n",
    "\n",
    "        # update the output list with the word_id_list - these are from/parent words\n",
    "        curr_output_list[:, 0] = outcome_word_id_list\n",
    "\n",
    "        # update with the word_id - this is the to/child word\n",
    "        curr_output_list[:, 1] = wg_id\n",
    "\n",
    "        # enumerate the from/parent words\n",
    "        new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "\n",
    "        output_list[anagram_pair_count:new_anagram_pair_count,\n",
    "                    :] = curr_output_list\n",
    "\n",
    "        # n_to_word_counter = collections.Counter(output_list[:, 0])\n",
    "        #intermediate_to_word_count.update(outcome_word_id_list.tolist())\n",
    "\n",
    "        # set the anagram pair count\n",
    "        anagram_pair_count = new_anagram_pair_count\n",
    "    \n",
    "    row_count += 1\n",
    "\n",
    "    if row_count % 100 == 0:\n",
    "        print(row_count)\n",
    "print('truncating list')\n",
    "output_indices = np.all(output_list >= 0, axis=1)\n",
    "output_list = output_list[output_indices,]\n",
    "del output_indices\n",
    "output_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_word_counter = collections.Counter(output_list[:,1])\n",
    "to_word_counter = collections.Counter(output_list[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7663cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of from word groups\n",
    "from_word_counter[746]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412a91e",
   "metadata": {},
   "source": [
    "# build a selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248af44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the matrix, gather the values for each split, and then combine\n",
    "n_subset_letters = 3\n",
    "wg_df[\"letter_selector\"] = wg_df[\"letter_group_ranked\"].str[:n_subset_letters]\n",
    "\n",
    "letter_selector_list = wg_df[\"letter_selector\"].unique()\n",
    "letter_selector_list.sort()\n",
    "letter_selector_id_dict = {ls: i_ls for i_ls, ls in enumerate(letter_selector_list)}\n",
    "\n",
    "wg_df[\"letter_selector_id\"] = wg_df[\"letter_selector\"].map(letter_selector_id_dict)\n",
    "# here's the thing: I need to be able to identify on a single matrix the rows that match various conditions.\n",
    "# I can't step through it and create objects at abandon. \n",
    "# so, given our wchar_matrix: what are the rows that match to such and such?\n",
    "# we can add three columns to track this... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load letter ranks\n",
    "sql = 'select letter, total_letter_rank from letter_count;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = query_db(sql = sql, db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09152a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dict = {l:r for l, r in zip(lr_df['letter'], lr_df['total_letter_rank'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d678aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_df['n_records'] = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a891d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['letter_selector_id', 'letter_selector', 'n_records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ac54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = wg_df[col_names].groupby(col_names[:-1]).agg(ls_count = ('n_records', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79512a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df['ls_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df['ls_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ls_index(ls:str):\n",
    "    return [letter_dict[l] for l in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46577b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is effectively a column selector\n",
    "ls_df['ls_index'] = ls_df['letter_selector'].map(get_ls_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_anagrams = load_possible_anagrams(db_path=rc.DB_PATH, db_name=rc.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d160c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def get_ls_wchar_matrix(wchar_matrix:np.ndarray, ls_id_index:np.ndarray, \n",
    "                        word_group_id_list:np.ndarray):\n",
    "    outcome_indices = np.all(wchar_matrix[:, ls_id_index] >= 1, 1)\n",
    "    \n",
    "    # this is the sub-matrix from which to query\n",
    "    ls_wchar_matrix = wchar_matrix[outcome_indices, :]\n",
    "        \n",
    "    # this is the list of word group ids that correspond to the word group ids\n",
    "    # in the ls_wchar_matrix\n",
    "    temp_wg_id_list = word_group_id_list[outcome_indices]\n",
    "\n",
    "    return ls_wchar_matrix, temp_wg_id_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output list\n",
    "output_list = np.full(shape = (n_possible_anagrams, 2), fill_value=-1)\n",
    "output_time_list = []\n",
    "\n",
    "# start counting\n",
    "anagram_pair_count = 0\n",
    "\n",
    "#for ls_id_index in range(0, 10):\n",
    "for ls_row_id, ls_row in ls_df.iloc[:None].iterrows():    \n",
    "    if ls_row_id % 100 == 0:\n",
    "        print(ls_row_id)\n",
    "    start_time = perf_counter_ns()\n",
    "    \n",
    "    # get letter selector id information\n",
    "    ls_id = ls_row['letter_selector_id']\n",
    "    ls_id_index = np.array(ls_row['ls_index'])    \n",
    "\n",
    "    ##\n",
    "    # BUILD A COLUMN SELECTOR\n",
    "    ##\n",
    "    # make sure that only values GTE 0 are selected so that the right number of\n",
    "    # columns are return.\n",
    "    #curr_ls_id = ls_id_index[ls_id_index >= 0]\n",
    "    \n",
    "    ##\n",
    "    # SUBSET THE wchar_matrix by column selector\n",
    "    ##\n",
    "     \n",
    "    ls_wchar_matrix, temp_wg_id_list = get_ls_wchar_matrix(wchar_matrix = wchar_matrix, \n",
    "                                                           ls_id_index = ls_id_index,\n",
    "                                                           word_group_id_list = word_group_id_list)    \n",
    "\n",
    "    # this is the number of word groups that meet certain criteria. \n",
    "    # for example, words that feature the letters: 'bro'    \n",
    "    n_search_space = temp_wg_id_list.shape[0]\n",
    "        \n",
    "    #def my_func(row):\n",
    "    #    return temp_wg_id_list[np.all(a = (ls_wchar_matrix - ls_wchar_matrix[row, :]) >= 0, axis = 1)]\n",
    "\n",
    "    #for ii in range(0, ls_wchar_matrix.shape[0]):    \n",
    "    #for i_curr_wg_id, curr_wg_id in enumerate(temp_wg_id_list):\n",
    "    # the current list of words featuring the set of least common letters.\n",
    "    # these are the words have the least common letters of 'bro'    \n",
    "    curr_wg_id_list = wg_df.loc[wg_df['letter_selector_id'] == ls_id, 'word_group_id'].to_numpy()\n",
    "    # n_lookups = curr_wg_id_list.shape[0]\n",
    "    # n_search_space >= n_lookups, always. \n",
    "    for i_curr_wg_id, curr_wg_id in enumerate(curr_wg_id_list):\n",
    "    \n",
    "        \n",
    "        #temp_wg_id = wg_id_dict[curr_wg_id]\n",
    "        temp_wg_id = np.where(temp_wg_id_list == curr_wg_id)[0][0]\n",
    "        #print(curr_wg_id, temp_wg_id)\n",
    "\n",
    "        #outcome_word_id_list = my_func(row = temp_wg_id)\n",
    "        outcome_word_id_list = temp_wg_id_list[np.all(a = (ls_wchar_matrix - ls_wchar_matrix[temp_wg_id, :]) >= 0, axis = 1)]\n",
    "                \n",
    "        n_from_words = outcome_word_id_list.shape[0]\n",
    "        \n",
    "        if n_from_words > 0:\n",
    "            outcome_word_id_list = format_output_list(outcome_word_id_list=outcome_word_id_list, wg_id=curr_wg_id)\n",
    "            #print(outcome_word_id_list.shape)\n",
    "            \n",
    "            # enumerate the from/parent words\n",
    "            new_anagram_pair_count = anagram_pair_count + n_from_words\n",
    "            #print(anagram_pair_count, new_anagram_pair_count)\n",
    "\n",
    "            output_list[anagram_pair_count:new_anagram_pair_count, :] = outcome_word_id_list\n",
    "\n",
    "            # update the anagram pair count\n",
    "            anagram_pair_count = new_anagram_pair_count\n",
    "\n",
    "    curr_time = calc_time(time_start=start_time, round_digits=8)\n",
    "    output_time_list.append([ls_id, n_search_space, curr_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59105ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timing_and_output_objects(output_time_list:list, ls_df:pd.DataFrame):\n",
    "    \n",
    "    col_names =['letter_selector_id', 'n_search_space', 'curr_time']\n",
    "    time_df = pd.DataFrame(data = output_time_list, columns=col_names)\n",
    "    get_hms(seconds = time_df['curr_time'].sum(),round_seconds_digits=4)\n",
    "    # join in the other information\n",
    "    time_df = pd.merge(left = time_df, right = ls_df)\n",
    "\n",
    "    time_df['avg_lookup_time'] = time_df['curr_time'] / (time_df['ls_count'] * time_df['n_search_space'])\n",
    "\n",
    "    return time_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = build_timing_and_output_objects(output_time_list=output_time_list,\n",
    "                                          ls_df = ls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['n_search_space'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['ls_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['avg_lookup_time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...truncating output list...')\n",
    "output_indices = np.all(output_list >= 0, axis=1)\n",
    "output_list = output_list[output_indices,]\n",
    "output_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6071d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('...building output counters...')\n",
    "from_word_counter = collections.Counter(output_list[:,1])\n",
    "to_word_counter = collections.Counter(output_list[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfacedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the word 'acanthology', with word_group_id 746 is in the counter\n",
    "print(from_word_counter[746])\n",
    "print(to_word_counter[746])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dba3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
